wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:50, 16.72s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:52, 17.60s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:52, 17.52s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:52, 17.55s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:55, 18.45s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:52, 17.42s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:52, 17.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:52, 17.65s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:32<00:31, 15.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:33<00:33, 16.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:34<00:34, 17.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:33<00:33, 16.71s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:33<00:33, 16.74s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:33<00:33, 16.88s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:33<00:33, 16.76s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:33<00:33, 16.66s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:46<00:14, 14.73s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:47<00:15, 15.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:47<00:15, 15.32s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:47<00:15, 15.25s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:48<00:15, 15.45s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:47<00:15, 15.42s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:47<00:15, 15.27s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:47<00:15, 15.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:47<00:00,  9.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:47<00:00, 11.94s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00,  9.62s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:49<00:00,  9.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00,  9.67s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:49<00:00, 12.26s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.04s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00,  9.71s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.04s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00,  9.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.04s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00,  9.60s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.02s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00,  9.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.01s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [00:45<15:03, 45.19s/it]  5%|▍         | 1/21 [00:45<15:06, 45.35s/it]  5%|▍         | 1/21 [00:45<15:01, 45.07s/it]  5%|▍         | 1/21 [00:41<13:54, 41.72s/it]  5%|▍         | 1/21 [00:45<15:05, 45.29s/it]  5%|▍         | 1/21 [00:45<15:03, 45.17s/it]  5%|▍         | 1/21 [00:44<14:58, 44.95s/it]  5%|▍         | 1/21 [00:41<13:47, 41.39s/it] 10%|▉         | 2/21 [01:11<10:42, 33.84s/it] 10%|▉         | 2/21 [01:11<10:42, 33.81s/it] 10%|▉         | 2/21 [01:10<10:40, 33.72s/it] 10%|▉         | 2/21 [01:10<10:41, 33.77s/it] 10%|▉         | 2/21 [01:10<10:39, 33.67s/it] 10%|▉         | 2/21 [01:07<10:14, 32.34s/it] 10%|▉         | 2/21 [01:10<10:41, 33.76s/it] 10%|▉         | 2/21 [01:07<10:11, 32.21s/it] 14%|█▍        | 3/21 [01:35<08:55, 29.74s/it] 14%|█▍        | 3/21 [01:35<08:54, 29.70s/it] 14%|█▍        | 3/21 [01:32<08:40, 28.92s/it] 14%|█▍        | 3/21 [01:35<08:54, 29.67s/it] 14%|█▍        | 3/21 [01:35<08:54, 29.70s/it] 14%|█▍        | 3/21 [01:35<08:53, 29.65s/it] 14%|█▍        | 3/21 [01:32<08:39, 28.85s/it] 14%|█▍        | 3/21 [01:35<08:55, 29.72s/it] 19%|█▉        | 4/21 [02:12<09:11, 32.43s/it] 19%|█▉        | 4/21 [02:12<09:11, 32.45s/it] 19%|█▉        | 4/21 [02:12<09:11, 32.43s/it] 19%|█▉        | 4/21 [02:08<09:03, 31.96s/it] 19%|█▉        | 4/21 [02:12<09:11, 32.41s/it] 19%|█▉        | 4/21 [02:12<09:10, 32.40s/it] 19%|█▉        | 4/21 [02:12<09:11, 32.44s/it] 19%|█▉        | 4/21 [02:08<09:02, 31.91s/it] 24%|██▍       | 5/21 [02:47<08:54, 33.38s/it] 24%|██▍       | 5/21 [02:44<08:49, 33.09s/it] 24%|██▍       | 5/21 [02:47<08:54, 33.39s/it] 24%|██▍       | 5/21 [02:47<08:53, 33.37s/it] 24%|██▍       | 5/21 [02:47<08:54, 33.41s/it] 24%|██▍       | 5/21 [02:47<08:54, 33.39s/it] 24%|██▍       | 5/21 [02:43<08:49, 33.06s/it] 24%|██▍       | 5/21 [02:47<08:54, 33.40s/it] 29%|██▊       | 6/21 [03:30<09:11, 36.78s/it] 29%|██▊       | 6/21 [03:30<09:11, 36.79s/it] 29%|██▊       | 6/21 [03:30<09:11, 36.79s/it] 29%|██▊       | 6/21 [03:27<09:08, 36.60s/it] 29%|██▊       | 6/21 [03:30<09:11, 36.79s/it] 29%|██▊       | 6/21 [03:31<09:12, 36.80s/it] 29%|██▊       | 6/21 [03:27<09:08, 36.58s/it] 29%|██▊       | 6/21 [03:31<09:12, 36.80s/it] 33%|███▎      | 7/21 [04:07<08:46, 37.62s/it] 33%|███▎      | 7/21 [04:10<08:48, 37.75s/it] 33%|███▎      | 7/21 [04:10<08:48, 37.75s/it] 33%|███▎      | 7/21 [04:10<08:48, 37.76s/it] 33%|███▎      | 7/21 [04:10<08:48, 37.76s/it] 33%|███▎      | 7/21 [04:06<08:46, 37.61s/it] 33%|███▎      | 7/21 [04:10<08:48, 37.76s/it] 33%|███▎      | 7/21 [04:10<08:48, 37.76s/it] 38%|███▊      | 8/21 [04:56<08:46, 40.48s/it] 38%|███▊      | 8/21 [04:56<08:46, 40.48s/it] 38%|███▊      | 8/21 [04:56<08:46, 40.48s/it] 38%|███▊      | 8/21 [04:53<08:45, 40.39s/it] 38%|███▊      | 8/21 [04:57<08:46, 40.49s/it] 38%|███▊      | 8/21 [04:57<08:46, 40.49s/it] 38%|███▊      | 8/21 [04:56<08:46, 40.48s/it] 38%|███▊      | 8/21 [04:53<08:44, 40.38s/it] 43%|████▎     | 9/21 [05:27<07:41, 38.42s/it] 43%|████▎     | 9/21 [05:31<07:41, 38.48s/it] 43%|████▎     | 9/21 [05:31<07:41, 38.49s/it] 43%|████▎     | 9/21 [05:30<07:41, 38.48s/it] 43%|████▎     | 9/21 [05:30<07:41, 38.48s/it] 43%|████▎     | 9/21 [05:31<07:41, 38.49s/it] 43%|████▎     | 9/21 [05:27<07:41, 38.42s/it] 43%|████▎     | 9/21 [05:31<07:41, 38.49s/it] 48%|████▊     | 10/21 [06:01<06:37, 36.14s/it] 48%|████▊     | 10/21 [06:02<06:37, 36.14s/it] 48%|████▊     | 10/21 [06:01<06:37, 36.14s/it] 48%|████▊     | 10/21 [05:58<06:37, 36.10s/it] 48%|████▊     | 10/21 [06:01<06:37, 36.14s/it] 48%|████▊     | 10/21 [06:01<06:37, 36.14s/it] 48%|████▊     | 10/21 [06:02<06:37, 36.14s/it] 48%|████▊     | 10/21 [05:58<06:37, 36.09s/it] 52%|█████▏    | 11/21 [06:33<05:49, 34.91s/it] 52%|█████▏    | 11/21 [06:34<05:49, 34.91s/it] 52%|█████▏    | 11/21 [06:34<05:49, 34.91s/it] 52%|█████▏    | 11/21 [06:34<05:49, 34.91s/it] 52%|█████▏    | 11/21 [06:33<05:49, 34.91s/it] 52%|█████▏    | 11/21 [06:30<05:48, 34.88s/it] 52%|█████▏    | 11/21 [06:34<05:49, 34.91s/it] 52%|█████▏    | 11/21 [06:30<05:48, 34.88s/it] 57%|█████▋    | 12/21 [07:11<05:21, 35.77s/it] 57%|█████▋    | 12/21 [07:11<05:21, 35.77s/it] 57%|█████▋    | 12/21 [07:11<05:21, 35.77s/it] 57%|█████▋    | 12/21 [07:08<05:21, 35.75s/it] 57%|█████▋    | 12/21 [07:11<05:21, 35.77s/it] 57%|█████▋    | 12/21 [07:11<05:21, 35.77s/it] 57%|█████▋    | 12/21 [07:08<05:21, 35.75s/it] 57%|█████▋    | 12/21 [07:11<05:21, 35.77s/it] 62%|██████▏   | 13/21 [08:06<05:32, 41.58s/it] 62%|██████▏   | 13/21 [08:06<05:32, 41.58s/it] 62%|██████▏   | 13/21 [08:06<05:32, 41.58s/it] 62%|██████▏   | 13/21 [08:03<05:32, 41.56s/it] 62%|██████▏   | 13/21 [08:06<05:32, 41.58s/it] 62%|██████▏   | 13/21 [08:06<05:32, 41.58s/it] 62%|██████▏   | 13/21 [08:06<05:32, 41.58s/it] 62%|██████▏   | 13/21 [08:02<05:32, 41.56s/it] 67%|██████▋   | 14/21 [08:53<05:03, 43.29s/it] 67%|██████▋   | 14/21 [08:53<05:03, 43.29s/it] 67%|██████▋   | 14/21 [08:54<05:03, 43.29s/it] 67%|██████▋   | 14/21 [08:54<05:03, 43.29s/it] 67%|██████▋   | 14/21 [08:50<05:02, 43.28s/it] 67%|██████▋   | 14/21 [08:54<05:03, 43.29s/it] 67%|██████▋   | 14/21 [08:50<05:02, 43.28s/it] 67%|██████▋   | 14/21 [08:54<05:03, 43.29s/it] 71%|███████▏  | 15/21 [09:21<03:51, 38.54s/it] 71%|███████▏  | 15/21 [09:21<03:51, 38.54s/it] 71%|███████▏  | 15/21 [09:21<03:51, 38.54s/it] 71%|███████▏  | 15/21 [09:18<03:51, 38.54s/it] 71%|███████▏  | 15/21 [09:21<03:51, 38.54s/it] 71%|███████▏  | 15/21 [09:21<03:51, 38.54s/it] 71%|███████▏  | 15/21 [09:21<03:51, 38.54s/it] 71%|███████▏  | 15/21 [09:17<03:51, 38.54s/it] 76%|███████▌  | 16/21 [10:08<03:25, 41.07s/it] 76%|███████▌  | 16/21 [10:08<03:25, 41.07s/it] 76%|███████▌  | 16/21 [10:08<03:25, 41.07s/it] 76%|███████▌  | 16/21 [10:05<03:25, 41.06s/it] 76%|███████▌  | 16/21 [10:08<03:25, 41.07s/it] 76%|███████▌  | 16/21 [10:08<03:25, 41.07s/it] 76%|███████▌  | 16/21 [10:04<03:25, 41.06s/it] 76%|███████▌  | 16/21 [10:08<03:25, 41.07s/it] 81%|████████  | 17/21 [10:41<02:34, 38.63s/it] 81%|████████  | 17/21 [10:37<02:34, 38.62s/it] 81%|████████  | 17/21 [10:41<02:34, 38.63s/it] 81%|████████  | 17/21 [10:41<02:34, 38.63s/it] 81%|████████  | 17/21 [10:41<02:34, 38.63s/it] 81%|████████  | 17/21 [10:41<02:34, 38.63s/it] 81%|████████  | 17/21 [10:41<02:34, 38.63s/it] 81%|████████  | 17/21 [10:37<02:34, 38.62s/it] 86%|████████▌ | 18/21 [11:20<01:56, 38.78s/it] 86%|████████▌ | 18/21 [11:17<01:56, 38.78s/it] 86%|████████▌ | 18/21 [11:20<01:56, 38.78s/it] 86%|████████▌ | 18/21 [11:20<01:56, 38.78s/it] 86%|████████▌ | 18/21 [11:20<01:56, 38.78s/it] 86%|████████▌ | 18/21 [11:20<01:56, 38.78s/it] 86%|████████▌ | 18/21 [11:16<01:56, 38.78s/it] 86%|████████▌ | 18/21 [11:20<01:56, 38.78s/it] 90%|█████████ | 19/21 [12:01<01:19, 39.51s/it] 90%|█████████ | 19/21 [12:01<01:19, 39.51s/it] 90%|█████████ | 19/21 [11:58<01:19, 39.50s/it] 90%|█████████ | 19/21 [12:01<01:19, 39.51s/it] 90%|█████████ | 19/21 [12:01<01:19, 39.51s/it] 90%|█████████ | 19/21 [12:01<01:19, 39.51s/it] 90%|█████████ | 19/21 [11:57<01:19, 39.50s/it] 90%|█████████ | 19/21 [12:01<01:19, 39.51s/it] 95%|█████████▌| 20/21 [12:48<00:41, 41.82s/it] 95%|█████████▌| 20/21 [12:48<00:41, 41.82s/it] 95%|█████████▌| 20/21 [12:45<00:41, 41.82s/it] 95%|█████████▌| 20/21 [12:48<00:41, 41.82s/it] 95%|█████████▌| 20/21 [12:48<00:41, 41.82s/it] 95%|█████████▌| 20/21 [12:49<00:41, 41.82s/it] 95%|█████████▌| 20/21 [12:49<00:41, 41.82s/it] 95%|█████████▌| 20/21 [12:45<00:41, 41.82s/it]100%|██████████| 21/21 [13:35<00:00, 43.23s/it]100%|██████████| 21/21 [13:35<00:00, 43.23s/it]100%|██████████| 21/21 [13:32<00:00, 43.23s/it]100%|██████████| 21/21 [13:35<00:00, 43.23s/it]100%|██████████| 21/21 [13:35<00:00, 43.23s/it]100%|██████████| 21/21 [13:35<00:00, 43.23s/it]100%|██████████| 21/21 [13:31<00:00, 43.23s/it]100%|██████████| 21/21 [13:35<00:00, 43.23s/it]22it [14:07, 39.97s/it]                        22it [14:07, 39.97s/it]                        22it [14:07, 39.97s/it]                        22it [14:07, 39.97s/it]                        22it [14:08, 39.97s/it]                        22it [14:04, 39.97s/it]                        22it [14:07, 39.97s/it]                        22it [14:04, 39.97s/it]                        23it [14:57, 42.95s/it]23it [14:57, 42.95s/it]23it [14:54, 42.95s/it]23it [14:57, 42.95s/it]23it [14:57, 42.95s/it]23it [14:57, 42.95s/it]23it [14:57, 42.95s/it]23it [14:53, 42.95s/it]24it [15:32, 40.58s/it]24it [15:32, 40.58s/it]24it [15:32, 40.58s/it]24it [15:32, 40.58s/it]24it [15:33, 40.58s/it]24it [15:29, 40.58s/it]24it [15:32, 40.58s/it]24it [15:29, 40.58s/it]25it [16:04, 39.05s/it]25it [16:08, 39.05s/it]25it [16:08, 39.05s/it]25it [16:08, 39.05s/it]25it [16:08, 39.05s/it]25it [16:08, 39.05s/it]25it [16:08, 39.05s/it]25it [16:04, 39.05s/it]26it [16:44, 38.32s/it]26it [16:45, 38.32s/it]26it [16:44, 38.32s/it]26it [16:44, 38.32s/it]26it [16:41, 38.32s/it]26it [16:44, 38.32s/it]26it [16:45, 38.32s/it]26it [16:41, 38.32s/it]27it [17:05, 34.14s/it]27it [17:09, 34.14s/it]27it [17:09, 34.14s/it]27it [17:09, 34.14s/it]27it [17:09, 34.14s/it]27it [17:09, 34.14s/it]27it [17:05, 34.14s/it]27it [17:09, 34.14s/it]28it [17:34, 31.60s/it]28it [17:35, 31.60s/it]28it [17:35, 31.60s/it]28it [17:34, 31.60s/it]28it [17:34, 31.60s/it]28it [17:31, 31.60s/it]28it [17:31, 31.60s/it]28it [17:35, 31.60s/it]29it [17:58, 30.35s/it]29it [18:02, 30.35s/it]29it [18:02, 30.35s/it]29it [18:02, 30.35s/it]29it [18:02, 30.35s/it]29it [18:02, 30.35s/it]29it [18:02, 30.35s/it]29it [17:58, 30.35s/it]30it [18:35, 31.31s/it]30it [18:36, 31.31s/it]30it [18:35, 31.31s/it]30it [18:32, 31.31s/it]30it [18:35, 31.31s/it]30it [18:36, 31.31s/it]30it [18:32, 31.31s/it]30it [18:35, 31.31s/it]31it [19:11, 32.50s/it]31it [19:11, 32.50s/it]31it [19:11, 32.50s/it]31it [19:10, 32.50s/it]31it [19:07, 32.50s/it]31it [19:11, 32.50s/it]31it [19:11, 32.50s/it]31it [19:07, 32.50s/it]32it [19:43, 32.53s/it]32it [19:43, 32.53s/it]32it [19:43, 32.53s/it]32it [19:40, 32.53s/it]32it [19:43, 32.53s/it]32it [19:43, 32.53s/it]32it [19:40, 32.53s/it]32it [19:43, 32.53s/it]33it [20:15, 33.21s/it]33it [20:18, 33.21s/it]33it [20:18, 33.21s/it]33it [20:18, 33.21s/it]33it [20:18, 33.21s/it]33it [20:18, 33.21s/it]33it [20:14, 33.21s/it]33it [20:18, 33.21s/it]34it [20:50, 32.92s/it]34it [20:50, 32.92s/it]34it [20:47, 32.92s/it]34it [20:50, 32.92s/it]34it [20:51, 32.92s/it]34it [20:47, 32.92s/it]34it [20:50, 32.92s/it]34it [20:50, 32.92s/it]35it [22:02, 44.52s/it]35it [22:02, 44.52s/it]35it [21:59, 44.52s/it]35it [22:02, 44.52s/it]35it [22:02, 44.52s/it]35it [21:58, 44.52s/it]35it [22:02, 44.52s/it]35it [22:02, 44.52s/it]36it [22:41, 42.76s/it]36it [22:41, 42.76s/it]36it [22:41, 42.76s/it]36it [22:41, 42.76s/it]36it [22:37, 42.76s/it]36it [22:40, 42.76s/it]36it [22:37, 42.76s/it]36it [22:41, 42.76s/it]37it [23:17, 40.95s/it]37it [23:17, 40.95s/it]37it [23:18, 40.95s/it]37it [23:14, 40.95s/it]37it [23:14, 40.95s/it]37it [23:17, 40.95s/it]37it [23:17, 40.95s/it]37it [23:17, 40.95s/it]38it [23:46, 37.31s/it]38it [23:46, 37.31s/it]38it [23:46, 37.31s/it]38it [23:43, 37.31s/it]38it [23:46, 37.31s/it]38it [23:42, 37.31s/it]38it [23:46, 37.31s/it]38it [23:46, 37.31s/it]39it [24:20, 36.20s/it]39it [24:20, 36.20s/it]39it [24:20, 36.20s/it]39it [24:20, 36.20s/it]39it [24:16, 36.20s/it]39it [24:20, 36.20s/it]39it [24:16, 36.20s/it]39it [24:20, 36.20s/it]40it [24:51, 34.73s/it]40it [24:51, 34.73s/it]40it [24:51, 34.73s/it]40it [24:48, 34.73s/it]40it [24:51, 34.73s/it]40it [24:51, 34.73s/it]40it [24:47, 34.73s/it]40it [24:51, 34.73s/it]41it [25:27, 35.14s/it]41it [25:27, 35.14s/it]41it [25:27, 35.14s/it]41it [25:24, 35.14s/it]41it [25:27, 35.14s/it]41it [25:27, 35.14s/it]41it [25:27, 35.14s/it]41it [25:27, 37.26s/it]
41it [25:27, 37.26s/it]41it [25:24, 37.18s/it]41it [25:27, 37.25s/it]

41it [25:27, 37.26s/it]

41it [25:27, 37.26s/it]41it [25:23, 35.14s/it]
41it [25:27, 37.26s/it]
41it [25:23, 37.17s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
