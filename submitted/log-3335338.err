wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.92s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.55s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.56s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.34s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.62s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.61s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 26.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 29.69s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 26.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 30.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 26.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 26.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 30.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 30.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 26.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 30.43s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 26.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 30.05s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 32.00s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 28.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.05s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [01:13<24:39, 73.97s/it]  5%|▍         | 1/21 [01:14<24:43, 74.17s/it]  5%|▍         | 1/21 [01:14<24:40, 74.02s/it]  5%|▍         | 1/21 [01:13<24:36, 73.82s/it]  5%|▍         | 1/21 [00:48<16:10, 48.54s/it]  5%|▍         | 1/21 [01:13<24:39, 73.96s/it]  5%|▍         | 1/21 [00:48<16:10, 48.51s/it]  5%|▍         | 1/21 [01:14<24:46, 74.33s/it] 10%|▉         | 2/21 [01:46<15:41, 49.56s/it] 10%|▉         | 2/21 [01:46<15:41, 49.58s/it] 10%|▉         | 2/21 [01:46<15:40, 49.50s/it] 10%|▉         | 2/21 [01:21<12:22, 39.08s/it] 10%|▉         | 2/21 [01:46<15:44, 49.70s/it] 10%|▉         | 2/21 [01:46<15:43, 49.64s/it] 10%|▉         | 2/21 [01:20<12:22, 39.07s/it] 10%|▉         | 2/21 [01:46<15:41, 49.55s/it] 14%|█▍        | 3/21 [02:17<12:21, 41.18s/it] 14%|█▍        | 3/21 [02:17<12:21, 41.22s/it] 14%|█▍        | 3/21 [01:52<10:39, 35.52s/it] 14%|█▍        | 3/21 [02:17<12:22, 41.23s/it] 14%|█▍        | 3/21 [01:52<10:39, 35.53s/it] 14%|█▍        | 3/21 [02:18<12:23, 41.30s/it] 14%|█▍        | 3/21 [02:17<12:22, 41.26s/it] 14%|█▍        | 3/21 [02:17<12:21, 41.22s/it] 19%|█▉        | 4/21 [02:54<11:09, 39.38s/it] 19%|█▉        | 4/21 [02:28<10:10, 35.91s/it] 19%|█▉        | 4/21 [02:28<10:10, 35.90s/it] 19%|█▉        | 4/21 [02:54<11:08, 39.33s/it] 19%|█▉        | 4/21 [02:54<11:08, 39.35s/it] 19%|█▉        | 4/21 [02:54<11:08, 39.35s/it] 19%|█▉        | 4/21 [02:54<11:09, 39.40s/it] 19%|█▉        | 4/21 [02:54<11:09, 39.36s/it] 24%|██▍       | 5/21 [03:25<09:45, 36.58s/it] 24%|██▍       | 5/21 [03:25<09:45, 36.58s/it] 24%|██▍       | 5/21 [03:26<09:45, 36.61s/it] 24%|██▍       | 5/21 [03:26<09:45, 36.59s/it] 24%|██▍       | 5/21 [03:25<09:45, 36.56s/it] 24%|██▍       | 5/21 [03:00<09:09, 34.37s/it] 24%|██▍       | 5/21 [03:00<09:09, 34.37s/it] 24%|██▍       | 5/21 [03:25<09:45, 36.58s/it] 29%|██▊       | 6/21 [04:01<09:04, 36.28s/it] 29%|██▊       | 6/21 [04:01<09:04, 36.29s/it] 29%|██▊       | 6/21 [03:36<08:42, 34.83s/it] 29%|██▊       | 6/21 [04:01<09:04, 36.31s/it] 29%|██▊       | 6/21 [03:36<08:42, 34.83s/it] 29%|██▊       | 6/21 [04:01<09:04, 36.29s/it] 29%|██▊       | 6/21 [04:01<09:04, 36.30s/it] 29%|██▊       | 6/21 [04:01<09:04, 36.29s/it] 33%|███▎      | 7/21 [04:37<08:26, 36.16s/it] 33%|███▎      | 7/21 [04:37<08:26, 36.17s/it] 33%|███▎      | 7/21 [04:37<08:26, 36.17s/it] 33%|███▎      | 7/21 [04:37<08:26, 36.18s/it] 33%|███▎      | 7/21 [04:12<08:12, 35.19s/it] 33%|███▎      | 7/21 [04:12<08:12, 35.19s/it] 33%|███▎      | 7/21 [04:37<08:26, 36.17s/it] 33%|███▎      | 7/21 [04:37<08:26, 36.18s/it] 38%|███▊      | 8/21 [05:08<07:26, 34.37s/it] 38%|███▊      | 8/21 [05:08<07:26, 34.38s/it] 38%|███▊      | 8/21 [05:08<07:26, 34.38s/it] 38%|███▊      | 8/21 [05:08<07:26, 34.37s/it] 38%|███▊      | 8/21 [05:07<07:26, 34.37s/it] 38%|███▊      | 8/21 [04:42<07:18, 33.70s/it] 38%|███▊      | 8/21 [04:42<07:18, 33.70s/it] 38%|███▊      | 8/21 [05:08<07:26, 34.37s/it] 43%|████▎     | 9/21 [05:44<07:00, 35.02s/it] 43%|████▎     | 9/21 [05:44<07:00, 35.02s/it] 43%|████▎     | 9/21 [05:44<07:00, 35.02s/it] 43%|████▎     | 9/21 [05:44<07:00, 35.03s/it] 43%|████▎     | 9/21 [05:19<06:54, 34.56s/it] 43%|████▎     | 9/21 [05:44<07:00, 35.03s/it] 43%|████▎     | 9/21 [05:19<06:54, 34.56s/it] 43%|████▎     | 9/21 [05:44<07:00, 35.02s/it] 48%|████▊     | 10/21 [05:50<06:09, 33.63s/it] 48%|████▊     | 10/21 [06:15<06:13, 33.94s/it] 48%|████▊     | 10/21 [06:16<06:13, 33.94s/it] 48%|████▊     | 10/21 [06:16<06:13, 33.94s/it] 48%|████▊     | 10/21 [06:16<06:13, 33.95s/it] 48%|████▊     | 10/21 [06:16<06:13, 33.94s/it] 48%|████▊     | 10/21 [05:50<06:09, 33.63s/it] 48%|████▊     | 10/21 [06:16<06:13, 33.95s/it] 52%|█████▏    | 11/21 [06:45<05:26, 32.65s/it] 52%|█████▏    | 11/21 [06:46<05:26, 32.66s/it] 52%|█████▏    | 11/21 [06:45<05:26, 32.65s/it] 52%|█████▏    | 11/21 [06:45<05:26, 32.66s/it] 52%|█████▏    | 11/21 [06:20<05:24, 32.43s/it] 52%|█████▏    | 11/21 [06:45<05:26, 32.65s/it] 52%|█████▏    | 11/21 [06:20<05:24, 32.43s/it] 52%|█████▏    | 11/21 [06:45<05:26, 32.65s/it] 57%|█████▋    | 12/21 [07:19<04:58, 33.15s/it] 57%|█████▋    | 12/21 [07:20<04:58, 33.16s/it] 57%|█████▋    | 12/21 [07:20<04:58, 33.16s/it] 57%|█████▋    | 12/21 [07:20<04:58, 33.16s/it] 57%|█████▋    | 12/21 [07:20<04:58, 33.16s/it] 57%|█████▋    | 12/21 [06:54<04:57, 33.00s/it] 57%|█████▋    | 12/21 [06:54<04:57, 33.00s/it] 57%|█████▋    | 12/21 [07:20<04:58, 33.16s/it] 62%|██████▏   | 13/21 [07:27<04:24, 33.11s/it] 62%|██████▏   | 13/21 [07:53<04:25, 33.21s/it] 62%|██████▏   | 13/21 [07:53<04:25, 33.21s/it] 62%|██████▏   | 13/21 [07:53<04:25, 33.21s/it] 62%|██████▏   | 13/21 [07:27<04:24, 33.11s/it] 62%|██████▏   | 13/21 [07:53<04:25, 33.22s/it] 62%|██████▏   | 13/21 [07:53<04:25, 33.21s/it] 62%|██████▏   | 13/21 [07:53<04:25, 33.21s/it] 67%|██████▋   | 14/21 [08:24<03:47, 32.47s/it] 67%|██████▋   | 14/21 [08:24<03:47, 32.47s/it] 67%|██████▋   | 14/21 [08:24<03:47, 32.47s/it] 67%|██████▋   | 14/21 [08:24<03:47, 32.47s/it] 67%|██████▋   | 14/21 [07:58<03:46, 32.39s/it] 67%|██████▋   | 14/21 [08:24<03:47, 32.47s/it] 67%|██████▋   | 14/21 [08:24<03:47, 32.47s/it] 67%|██████▋   | 14/21 [07:58<03:46, 32.39s/it] 71%|███████▏  | 15/21 [09:00<03:21, 33.53s/it] 71%|███████▏  | 15/21 [08:59<03:21, 33.53s/it] 71%|███████▏  | 15/21 [08:34<03:20, 33.48s/it] 71%|███████▏  | 15/21 [09:00<03:21, 33.53s/it] 71%|███████▏  | 15/21 [08:34<03:20, 33.48s/it] 71%|███████▏  | 15/21 [09:00<03:21, 33.53s/it] 71%|███████▏  | 15/21 [09:00<03:21, 33.53s/it] 71%|███████▏  | 15/21 [09:00<03:21, 33.53s/it] 76%|███████▌  | 16/21 [09:07<02:46, 33.35s/it] 76%|███████▌  | 16/21 [09:07<02:46, 33.35s/it] 76%|███████▌  | 16/21 [09:33<02:46, 33.39s/it] 76%|███████▌  | 16/21 [09:33<02:46, 33.39s/it] 76%|███████▌  | 16/21 [09:33<02:46, 33.39s/it] 76%|███████▌  | 16/21 [09:33<02:46, 33.39s/it] 76%|███████▌  | 16/21 [09:33<02:46, 33.39s/it] 76%|███████▌  | 16/21 [09:33<02:46, 33.39s/it] 81%|████████  | 17/21 [09:59<02:04, 31.20s/it] 81%|████████  | 17/21 [09:59<02:04, 31.20s/it] 81%|████████  | 17/21 [09:33<02:04, 31.18s/it] 81%|████████  | 17/21 [09:59<02:04, 31.20s/it] 81%|████████  | 17/21 [09:59<02:04, 31.20s/it] 81%|████████  | 17/21 [09:33<02:04, 31.18s/it] 81%|████████  | 17/21 [09:59<02:04, 31.20s/it] 81%|████████  | 17/21 [09:59<02:04, 31.20s/it] 86%|████████▌ | 18/21 [10:29<01:32, 30.90s/it] 86%|████████▌ | 18/21 [10:04<01:32, 30.88s/it] 86%|████████▌ | 18/21 [10:29<01:32, 30.90s/it] 86%|████████▌ | 18/21 [10:29<01:32, 30.90s/it] 86%|████████▌ | 18/21 [10:29<01:32, 30.90s/it] 86%|████████▌ | 18/21 [10:29<01:32, 30.90s/it] 86%|████████▌ | 18/21 [10:29<01:32, 30.90s/it] 86%|████████▌ | 18/21 [10:04<01:32, 30.88s/it] 90%|█████████ | 19/21 [10:59<01:01, 30.75s/it] 90%|█████████ | 19/21 [10:59<01:01, 30.75s/it] 90%|█████████ | 19/21 [10:34<01:01, 30.74s/it] 90%|█████████ | 19/21 [10:59<01:01, 30.75s/it] 90%|█████████ | 19/21 [11:00<01:01, 30.75s/it] 90%|█████████ | 19/21 [11:00<01:01, 30.75s/it] 90%|█████████ | 19/21 [10:34<01:01, 30.74s/it] 90%|█████████ | 19/21 [10:59<01:01, 30.75s/it] 95%|█████████▌| 20/21 [11:24<00:28, 28.70s/it] 95%|█████████▌| 20/21 [11:23<00:28, 28.70s/it] 95%|█████████▌| 20/21 [11:23<00:28, 28.70s/it] 95%|█████████▌| 20/21 [11:24<00:28, 28.70s/it] 95%|█████████▌| 20/21 [10:58<00:28, 28.69s/it] 95%|█████████▌| 20/21 [11:23<00:28, 28.70s/it] 95%|█████████▌| 20/21 [10:58<00:28, 28.69s/it] 95%|█████████▌| 20/21 [11:23<00:28, 28.70s/it]100%|██████████| 21/21 [12:02<00:00, 31.70s/it]100%|██████████| 21/21 [12:02<00:00, 31.70s/it]100%|██████████| 21/21 [12:02<00:00, 31.70s/it]100%|██████████| 21/21 [11:37<00:00, 31.69s/it]100%|██████████| 21/21 [12:02<00:00, 31.70s/it]100%|██████████| 21/21 [11:37<00:00, 31.69s/it]100%|██████████| 21/21 [12:02<00:00, 31.70s/it]100%|██████████| 21/21 [12:02<00:00, 31.70s/it]22it [12:29, 30.17s/it]                        22it [12:29, 30.17s/it]                        22it [12:03, 30.17s/it]                        22it [12:29, 30.17s/it]                        22it [12:29, 30.17s/it]                        22it [12:29, 30.17s/it]                        22it [12:03, 30.17s/it]                        22it [12:29, 30.17s/it]                        23it [13:02, 31.21s/it]23it [13:02, 31.21s/it]23it [12:37, 31.21s/it]23it [13:02, 31.21s/it]23it [13:03, 31.21s/it]23it [13:02, 31.21s/it]23it [13:02, 31.21s/it]23it [12:37, 31.21s/it]24it [13:23, 27.95s/it]24it [13:23, 27.95s/it]24it [13:23, 27.95s/it]24it [13:23, 27.95s/it]24it [12:57, 27.95s/it]24it [12:57, 27.95s/it]24it [13:23, 27.95s/it]24it [13:22, 27.95s/it]25it [13:56, 29.70s/it]25it [13:56, 29.70s/it]25it [13:31, 29.70s/it]25it [13:31, 29.70s/it]25it [13:57, 29.70s/it]25it [13:56, 29.70s/it]25it [13:57, 29.70s/it]25it [13:56, 29.70s/it]26it [14:28, 30.17s/it]26it [14:28, 30.17s/it]26it [14:28, 30.17s/it]26it [14:02, 30.16s/it]26it [14:28, 30.17s/it]26it [14:28, 30.17s/it]26it [14:02, 30.16s/it]26it [14:28, 30.17s/it]27it [15:02, 31.47s/it]27it [15:02, 31.47s/it]27it [15:02, 31.47s/it]27it [14:37, 31.47s/it]27it [15:02, 31.47s/it]27it [15:02, 31.47s/it]27it [14:37, 31.47s/it]27it [15:03, 31.47s/it]28it [15:29, 30.12s/it]28it [15:04, 30.12s/it]28it [15:04, 30.12s/it]28it [15:29, 30.12s/it]28it [15:29, 30.12s/it]28it [15:29, 30.12s/it]28it [15:29, 30.12s/it]28it [15:29, 30.12s/it]29it [16:00, 30.41s/it]29it [16:00, 30.41s/it]29it [16:01, 30.41s/it]29it [16:00, 30.41s/it]29it [16:00, 30.41s/it]29it [15:35, 30.41s/it]29it [16:00, 30.41s/it]29it [15:35, 30.41s/it]30it [16:27, 29.32s/it]30it [16:27, 29.32s/it]30it [16:27, 29.32s/it]30it [16:02, 29.32s/it]30it [16:02, 29.32s/it]30it [16:27, 29.32s/it]30it [16:27, 29.32s/it]30it [16:27, 29.32s/it]31it [16:53, 28.37s/it]31it [16:53, 28.37s/it]31it [16:53, 28.37s/it]31it [16:53, 28.37s/it]31it [16:53, 28.37s/it]31it [16:53, 28.37s/it]31it [16:28, 28.37s/it]31it [16:28, 28.37s/it]32it [17:12, 25.54s/it]32it [17:12, 25.54s/it]32it [17:12, 25.54s/it]32it [17:12, 25.54s/it]32it [17:12, 25.54s/it]32it [16:47, 25.54s/it]32it [17:12, 25.54s/it]32it [16:47, 25.54s/it]33it [17:25, 29.49s/it]33it [17:25, 29.49s/it]33it [17:51, 29.49s/it]33it [17:51, 29.49s/it]33it [17:51, 29.49s/it]33it [17:51, 29.49s/it]33it [17:51, 29.49s/it]33it [17:51, 29.49s/it]34it [18:23, 30.17s/it]34it [18:22, 30.17s/it]34it [18:23, 30.17s/it]34it [17:57, 30.17s/it]34it [18:23, 30.17s/it]34it [18:23, 30.17s/it]34it [17:57, 30.17s/it]34it [18:23, 30.17s/it]35it [18:58, 31.84s/it]35it [18:58, 31.84s/it]35it [18:33, 31.84s/it]35it [18:33, 31.84s/it]35it [18:58, 31.84s/it]35it [18:58, 31.84s/it]35it [18:59, 31.84s/it]35it [18:58, 31.84s/it]36it [19:25, 30.34s/it]36it [19:25, 30.34s/it]36it [19:25, 30.34s/it]36it [19:25, 30.34s/it]36it [19:00, 30.34s/it]36it [19:25, 30.34s/it]36it [19:00, 30.34s/it]36it [19:25, 30.34s/it]37it [19:57, 30.73s/it]37it [19:31, 30.73s/it]37it [19:57, 30.73s/it]37it [19:31, 30.73s/it]37it [19:57, 30.73s/it]37it [19:57, 30.73s/it]37it [19:57, 30.73s/it]37it [19:57, 30.73s/it]38it [20:29, 31.24s/it]38it [20:29, 31.24s/it]38it [20:30, 31.24s/it]38it [20:29, 31.24s/it]38it [20:29, 31.24s/it]38it [20:29, 31.24s/it]38it [20:04, 31.24s/it]38it [20:04, 31.24s/it]39it [21:03, 32.14s/it]39it [21:03, 32.14s/it]39it [20:38, 32.14s/it]39it [21:03, 32.14s/it]39it [21:04, 32.14s/it]39it [20:38, 32.14s/it]39it [21:04, 32.14s/it]39it [21:03, 32.14s/it]40it [21:05, 30.68s/it]40it [21:05, 30.68s/it]40it [21:31, 30.68s/it]40it [21:31, 30.68s/it]40it [21:31, 30.68s/it]40it [21:31, 30.68s/it]40it [21:31, 30.68s/it]40it [21:31, 30.68s/it]41it [22:08, 32.58s/it]41it [22:08, 32.58s/it]41it [22:08, 32.58s/it]41it [22:08, 32.58s/it]41it [22:08, 32.58s/it]41it [22:08, 32.58s/it]41it [21:42, 32.58s/it]41it [21:42, 32.58s/it]41it [22:08, 32.39s/it]
41it [22:08, 32.40s/it]
41it [22:08, 32.40s/it]41it [22:08, 32.40s/it]41it [22:08, 32.40s/it]

41it [22:08, 32.40s/it]

41it [21:42, 31.78s/it]
41it [21:42, 31.77s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
