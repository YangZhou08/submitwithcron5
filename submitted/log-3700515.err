Already on 'yangexppp'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-08-06:13:23:36,803 INFO     [main.py:288] Verbosity set to INFO
2024-08-06:13:23:46,421 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-08-06:13:23:46,422 INFO     [main.py:378] Selected Tasks: ['mmlu_flan_cot_fewshot']
2024-08-06:13:23:46,453 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-08-06:13:23:46,453 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-70B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1500, 'kernel_size': 16, 'thr': 0.05}
2024-08-06:13:23:46,462 INFO     [xhuggingface.py:177] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:05<02:44,  5.67s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:11<02:37,  5.63s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:17<02:37,  5.84s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:23<02:35,  5.96s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:29<02:26,  5.87s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:34<02:18,  5.76s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:40<02:09,  5.65s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:46<02:06,  5.77s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:53<02:08,  6.13s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:58<01:58,  5.93s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [01:03<01:49,  5.75s/it]Loading checkpoint shards:  40%|████      | 12/30 [01:09<01:44,  5.78s/it]