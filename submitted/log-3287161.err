fatal: Unable to create '/fsx-storygen/beidic/yang/GRIFFIN2/.git/index.lock': File exists.

Another git process seems to be running in this repository, e.g.
an editor opened by 'git commit'. Please make sure all processes
are terminated then try again. If it still fails, a git process
may have crashed in this repository earlier:
remove the file manually to continue.
Already on 'yangexp2threee'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-07:00:36:40,032 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:40,032 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:40,032 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:40,032 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:40,032 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:40,032 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:40,033 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:40,039 INFO     [main.py:288] Verbosity set to INFO
2024-07-07:00:36:49,039 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,039 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,039 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,039 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,039 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,040 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,041 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,041 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,041 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,041 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,041 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,041 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,064 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,064 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,064 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,064 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,064 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,064 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,064 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
2024-07-07:00:36:49,064 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
2024-07-07:00:36:49,064 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
2024-07-07:00:36:49,064 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
2024-07-07:00:36:49,064 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
2024-07-07:00:36:49,064 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
2024-07-07:00:36:49,175 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,176 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,183 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,183 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
2024-07-07:00:36:49,193 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-07:00:36:49,194 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-07:00:36:49,200 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-07:00:36:49,201 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 12, 'spr': 0.3, 'thr': 0.0005, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:45, 15.15s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:50, 16.77s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:48, 16.32s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:48, 16.32s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:49, 16.34s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:49, 16.38s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:48, 16.30s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:49, 16.60s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:29<00:28, 14.45s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.12s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.12s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.13s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:31, 15.55s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:41<00:13, 13.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:13, 13.93s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:13, 13.93s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:14, 14.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:13, 13.96s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:13, 13.96s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:13, 13.97s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:14, 14.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:43<00:00,  8.80s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:43<00:00, 10.91s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00,  9.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00, 11.15s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00,  9.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00, 11.16s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00,  9.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00, 11.13s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00,  9.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00, 11.15s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00,  9.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:44<00:00, 11.17s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:45<00:00,  9.28s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:45<00:00, 11.35s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:45<00:00,  9.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:45<00:00, 11.46s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-07:00:38:26,736 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/50 [00:00<?, ?it/s]2024-07-07:00:38:26,828 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/49 [00:00<?, ?it/s] 38%|███▊      | 19/50 [00:00<00:00, 188.26it/s] 41%|████      | 20/49 [00:00<00:00, 190.24it/s] 78%|███████▊  | 39/50 [00:00<00:00, 189.72it/s]100%|██████████| 50/50 [00:00<00:00, 189.85it/s]
 82%|████████▏ | 40/49 [00:00<00:00, 191.14it/s]2024-07-07:00:38:27,057 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/49 [00:00<?, ?it/s]100%|██████████| 49/49 [00:00<00:00, 191.14it/s]
 41%|████      | 20/49 [00:00<00:00, 190.50it/s] 82%|████████▏ | 40/49 [00:00<00:00, 192.02it/s]2024-07-07:00:38:27,308 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/49 [00:00<?, ?it/s]100%|██████████| 49/49 [00:00<00:00, 192.04it/s]
2024-07-07:00:38:27,336 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/50 [00:00<?, ?it/s] 41%|████      | 20/49 [00:00<00:00, 190.67it/s] 38%|███▊      | 19/50 [00:00<00:00, 189.87it/s] 82%|████████▏ | 40/49 [00:00<00:00, 192.18it/s] 78%|███████▊  | 39/50 [00:00<00:00, 191.66it/s]100%|██████████| 49/49 [00:00<00:00, 192.12it/s]
100%|██████████| 50/50 [00:00<00:00, 191.10it/s]
2024-07-07:00:38:27,791 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/50 [00:00<?, ?it/s] 40%|████      | 20/50 [00:00<00:00, 190.60it/s] 80%|████████  | 40/50 [00:00<00:00, 191.88it/s]100%|██████████| 50/50 [00:00<00:00, 191.92it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-07:00:38:54,612 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-07:00:38:55,804 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/49 [00:00<?, ?it/s]2024-07-07:00:38:55,909 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
 24%|██▍       | 12/49 [00:00<00:00, 115.06it/s]  0%|          | 0/50 [00:00<?, ?it/s] 12%|█▏        | 6/50 [00:00<00:00, 59.05it/s] 49%|████▉     | 24/49 [00:00<00:00, 71.54it/s]  24%|██▍       | 12/50 [00:00<00:00, 55.75it/s] 36%|███▌      | 18/50 [00:00<00:00, 54.24it/s] 67%|██████▋   | 33/49 [00:00<00:00, 62.92it/s] 48%|████▊     | 24/50 [00:00<00:00, 53.84it/s] 82%|████████▏ | 40/49 [00:00<00:00, 59.05it/s] 60%|██████    | 30/50 [00:00<00:00, 53.48it/s] 96%|█████████▌| 47/49 [00:00<00:00, 56.62it/s] 72%|███████▏  | 36/50 [00:00<00:00, 53.17it/s]100%|██████████| 49/49 [00:00<00:00, 61.49it/s]
 84%|████████▍ | 42/50 [00:00<00:00, 53.56it/s] 96%|█████████▌| 48/50 [00:00<00:00, 45.29it/s]100%|██████████| 50/50 [00:01<00:00, 49.38it/s]
2024-07-07:00:39:12,671 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-07:00:39:12,671 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-07:00:39:12,671 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-07:00:39:12,671 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-07:00:39:12,671 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-07:00:39:12,672 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-07:00:39:12,672 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-07:00:39:12,672 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/50 [00:00<?, ?it/s]Running generate_until requests:   2%|▏         | 1/50 [00:08<06:45,  8.28s/it]Running generate_until requests:   4%|▍         | 2/50 [00:21<08:54, 11.13s/it]Running generate_until requests:   6%|▌         | 3/50 [00:32<08:34, 10.95s/it]Running generate_until requests:   8%|▊         | 4/50 [00:46<09:20, 12.18s/it]Running generate_until requests:  10%|█         | 5/50 [00:53<07:44, 10.32s/it]Running generate_until requests:  12%|█▏        | 6/50 [01:10<09:11, 12.53s/it]Running generate_until requests:  14%|█▍        | 7/50 [01:18<08:00, 11.17s/it]Running generate_until requests:  16%|█▌        | 8/50 [01:32<08:28, 12.11s/it]Running generate_until requests:  18%|█▊        | 9/50 [02:00<11:40, 17.08s/it]Running generate_until requests:  20%|██        | 10/50 [02:13<10:29, 15.73s/it]Running generate_until requests:  22%|██▏       | 11/50 [02:22<08:57, 13.79s/it]Running generate_until requests:  24%|██▍       | 12/50 [02:33<08:06, 12.81s/it]Running generate_until requests:  26%|██▌       | 13/50 [03:00<10:40, 17.30s/it]Running generate_until requests:  28%|██▊       | 14/50 [03:27<12:04, 20.12s/it]Running generate_until requests:  30%|███       | 15/50 [03:33<09:14, 15.85s/it]Running generate_until requests:  32%|███▏      | 16/50 [03:42<07:52, 13.90s/it]Running generate_until requests:  34%|███▍      | 17/50 [03:49<06:30, 11.84s/it]Running generate_until requests:  36%|███▌      | 18/50 [04:00<06:06, 11.45s/it]Running generate_until requests:  38%|███▊      | 19/50 [04:08<05:24, 10.46s/it]Running generate_until requests:  40%|████      | 20/50 [04:28<06:37, 13.24s/it]Running generate_until requests:  42%|████▏     | 21/50 [04:36<05:39, 11.72s/it]Running generate_until requests:  44%|████▍     | 22/50 [04:43<04:48, 10.30s/it]Running generate_until requests:  46%|████▌     | 23/50 [04:50<04:11,  9.31s/it]Running generate_until requests:  48%|████▊     | 24/50 [05:15<06:07, 14.15s/it]Running generate_until requests:  50%|█████     | 25/50 [05:24<05:09, 12.37s/it]Running generate_until requests:  52%|█████▏    | 26/50 [05:33<04:34, 11.46s/it]Running generate_until requests:  54%|█████▍    | 27/50 [05:45<04:24, 11.50s/it]Running generate_until requests:  56%|█████▌    | 28/50 [05:55<04:06, 11.19s/it]Running generate_until requests:  58%|█████▊    | 29/50 [06:23<05:39, 16.15s/it]Running generate_until requests:  60%|██████    | 30/50 [06:31<04:35, 13.76s/it]Running generate_until requests:  62%|██████▏   | 31/50 [06:56<05:27, 17.26s/it]Running generate_until requests:  64%|██████▍   | 32/50 [07:11<04:58, 16.59s/it]Running generate_until requests:  66%|██████▌   | 33/50 [07:21<04:04, 14.41s/it]Running generate_until requests:  68%|██████▊   | 34/50 [07:29<03:20, 12.56s/it]Running generate_until requests:  70%|███████   | 35/50 [07:37<02:48, 11.23s/it]Running generate_until requests:  72%|███████▏  | 36/50 [08:03<03:37, 15.51s/it]Running generate_until requests:  74%|███████▍  | 37/50 [08:06<02:35, 11.92s/it]Running generate_until requests:  76%|███████▌  | 38/50 [08:32<03:11, 15.99s/it]Running generate_until requests:  78%|███████▊  | 39/50 [08:47<02:52, 15.70s/it]Running generate_until requests:  80%|████████  | 40/50 [08:52<02:07, 12.74s/it]Running generate_until requests:  82%|████████▏ | 41/50 [09:01<01:42, 11.37s/it]Running generate_until requests:  84%|████████▍ | 42/50 [09:06<01:17,  9.71s/it]Running generate_until requests:  86%|████████▌ | 43/50 [09:23<01:21, 11.67s/it]Running generate_until requests:  88%|████████▊ | 44/50 [09:31<01:03, 10.63s/it]Running generate_until requests:  90%|█████████ | 45/50 [09:39<00:49,  9.88s/it]Running generate_until requests:  92%|█████████▏| 46/50 [09:48<00:38,  9.69s/it]Running generate_until requests:  94%|█████████▍| 47/50 [09:55<00:25,  8.66s/it]Running generate_until requests:  96%|█████████▌| 48/50 [10:01<00:15,  7.94s/it]Running generate_until requests:  98%|█████████▊| 49/50 [10:20<00:11, 11.41s/it]Running generate_until requests: 100%|██████████| 50/50 [10:24<00:00,  9.09s/it]Running generate_until requests: 100%|██████████| 50/50 [10:24<00:00, 12.49s/it]
