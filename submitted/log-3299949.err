Already on 'addinggriffin'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:49, 16.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.06s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:55, 18.59s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.20s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.02s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.17s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:52, 17.57s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:53, 17.69s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:28, 14.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.30s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.39s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.36s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:32<00:31, 15.56s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:31, 15.61s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.25s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:43<00:13, 13.70s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:14, 14.46s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:44<00:14, 14.36s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:44<00:14, 14.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:44<00:14, 14.53s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:44<00:14, 14.41s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:44<00:14, 14.31s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:44<00:14, 14.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:45<00:00,  9.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:45<00:00, 11.30s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.55s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.57s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.60s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.70s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.60s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.53s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.53s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  3%|▎         | 1/32 [00:32<16:34, 32.07s/it]  3%|▎         | 1/32 [00:32<16:51, 32.63s/it]  3%|▎         | 1/32 [00:33<17:29, 33.84s/it]  3%|▎         | 1/32 [00:34<17:42, 34.26s/it]  3%|▎         | 1/32 [00:34<17:35, 34.06s/it]  3%|▎         | 1/32 [00:35<18:33, 35.92s/it]  3%|▎         | 1/32 [00:48<25:15, 48.90s/it]  3%|▎         | 1/32 [00:53<27:42, 53.62s/it]  6%|▋         | 2/32 [01:03<15:55, 31.85s/it]  6%|▋         | 2/32 [01:06<16:47, 33.57s/it]  6%|▋         | 2/32 [01:06<16:29, 32.99s/it]  6%|▋         | 2/32 [01:07<16:47, 33.58s/it]  6%|▋         | 2/32 [01:08<17:03, 34.12s/it]  6%|▋         | 2/32 [01:14<18:58, 37.96s/it]  9%|▉         | 3/32 [01:36<15:29, 32.06s/it]  9%|▉         | 3/32 [01:37<15:37, 32.32s/it]  9%|▉         | 3/32 [01:38<15:35, 32.25s/it]  9%|▉         | 3/32 [01:37<15:35, 32.25s/it]  9%|▉         | 3/32 [01:39<15:54, 32.91s/it]  6%|▋         | 2/32 [01:40<25:15, 50.50s/it]  6%|▋         | 2/32 [01:43<25:39, 51.32s/it]  9%|▉         | 3/32 [01:54<18:49, 38.97s/it] 12%|█▎        | 4/32 [02:10<15:08, 32.46s/it] 12%|█▎        | 4/32 [02:11<15:32, 33.30s/it] 12%|█▎        | 4/32 [02:12<15:19, 32.84s/it] 12%|█▎        | 4/32 [02:13<15:45, 33.77s/it] 12%|█▎        | 4/32 [02:14<15:42, 33.66s/it] 12%|█▎        | 4/32 [02:33<18:12, 39.01s/it]  9%|▉         | 3/32 [02:33<24:59, 51.71s/it]  9%|▉         | 3/32 [02:40<26:10, 54.15s/it] 16%|█▌        | 5/32 [02:42<14:39, 32.57s/it] 16%|█▌        | 5/32 [02:43<14:43, 32.72s/it] 16%|█▌        | 5/32 [02:44<14:37, 32.50s/it] 16%|█▌        | 5/32 [02:45<14:47, 32.87s/it] 16%|█▌        | 5/32 [02:45<14:45, 32.80s/it] 19%|█▉        | 6/32 [03:12<13:42, 31.64s/it] 19%|█▉        | 6/32 [03:14<13:43, 31.66s/it] 16%|█▌        | 5/32 [03:15<17:56, 39.86s/it] 19%|█▉        | 6/32 [03:16<14:18, 33.01s/it] 19%|█▉        | 6/32 [03:16<13:57, 32.21s/it] 19%|█▉        | 6/32 [03:17<14:09, 32.66s/it] 12%|█▎        | 4/32 [03:29<24:58, 53.53s/it] 12%|█▎        | 4/32 [03:39<26:08, 56.01s/it] 22%|██▏       | 7/32 [03:42<12:56, 31.06s/it] 22%|██▏       | 7/32 [03:45<13:06, 31.46s/it] 22%|██▏       | 7/32 [03:48<13:24, 32.19s/it] 22%|██▏       | 7/32 [03:48<13:24, 32.18s/it] 22%|██▏       | 7/32 [03:51<13:57, 33.50s/it] 19%|█▉        | 6/32 [03:55<17:19, 39.98s/it] 25%|██▌       | 8/32 [04:15<12:25, 31.07s/it] 25%|██▌       | 8/32 [04:17<12:53, 32.21s/it] 25%|██▌       | 8/32 [04:21<12:54, 32.25s/it] 16%|█▌        | 5/32 [04:21<23:45, 52.81s/it] 25%|██▌       | 8/32 [04:22<13:04, 32.69s/it] 25%|██▌       | 8/32 [04:21<12:57, 32.39s/it] 16%|█▌        | 5/32 [04:33<24:55, 55.38s/it] 22%|██▏       | 7/32 [04:36<16:51, 40.45s/it] 28%|██▊       | 9/32 [04:46<11:53, 31.04s/it] 28%|██▊       | 9/32 [04:48<12:10, 31.78s/it] 28%|██▊       | 9/32 [04:52<12:14, 31.93s/it] 28%|██▊       | 9/32 [04:52<12:13, 31.87s/it] 28%|██▊       | 9/32 [04:54<12:31, 32.67s/it] 19%|█▉        | 6/32 [05:14<22:55, 52.92s/it] 31%|███▏      | 10/32 [05:16<11:15, 30.71s/it] 31%|███▏      | 10/32 [05:17<11:25, 31.17s/it] 31%|███▏      | 10/32 [05:22<11:30, 31.41s/it] 31%|███▏      | 10/32 [05:22<11:33, 31.51s/it] 19%|█▉        | 6/32 [05:25<23:24, 54.02s/it] 25%|██▌       | 8/32 [05:25<17:15, 43.14s/it] 31%|███▏      | 10/32 [05:31<12:24, 33.86s/it] 34%|███▍      | 11/32 [05:48<10:53, 31.10s/it] 34%|███▍      | 11/32 [05:49<10:59, 31.40s/it] 34%|███▍      | 11/32 [05:53<10:58, 31.35s/it] 34%|███▍      | 11/32 [05:57<11:21, 32.46s/it] 34%|███▍      | 11/32 [06:02<11:36, 33.18s/it] 28%|██▊       | 9/32 [06:04<16:01, 41.82s/it] 22%|██▏       | 7/32 [06:04<21:39, 51.98s/it] 22%|██▏       | 7/32 [06:16<22:08, 53.12s/it] 38%|███▊      | 12/32 [06:18<10:14, 30.74s/it] 38%|███▊      | 12/32 [06:19<10:19, 30.99s/it] 38%|███▊      | 12/32 [06:24<10:25, 31.29s/it] 38%|███▊      | 12/32 [06:28<10:38, 31.92s/it] 38%|███▊      | 12/32 [06:35<11:00, 33.03s/it] 31%|███▏      | 10/32 [06:44<15:09, 41.33s/it] 41%|████      | 13/32 [06:49<09:44, 30.78s/it] 41%|████      | 13/32 [06:51<09:54, 31.30s/it] 25%|██▌       | 8/32 [06:56<20:45, 51.89s/it] 41%|████      | 13/32 [06:56<09:53, 31.25s/it] 41%|████      | 13/32 [06:59<10:04, 31.84s/it] 41%|████      | 13/32 [07:07<10:19, 32.62s/it] 25%|██▌       | 8/32 [07:11<21:26, 53.59s/it] 44%|████▍     | 14/32 [07:22<09:22, 31.23s/it] 44%|████▍     | 14/32 [07:23<09:29, 31.66s/it] 34%|███▍      | 11/32 [07:26<14:27, 41.33s/it] 44%|████▍     | 14/32 [07:27<09:22, 31.27s/it] 44%|████▍     | 14/32 [07:30<09:28, 31.59s/it] 44%|████▍     | 14/32 [07:38<09:38, 32.13s/it] 28%|██▊       | 9/32 [07:48<19:54, 51.92s/it] 47%|████▋     | 15/32 [07:53<08:46, 30.95s/it] 47%|████▋     | 15/32 [07:56<09:03, 32.00s/it] 47%|████▋     | 15/32 [07:59<08:56, 31.53s/it] 28%|██▊       | 9/32 [08:02<20:15, 52.86s/it] 38%|███▊      | 12/32 [08:06<13:39, 40.99s/it] 47%|████▋     | 15/32 [08:05<09:12, 32.51s/it] 47%|████▋     | 15/32 [08:11<09:10, 32.39s/it] 50%|█████     | 16/32 [08:24<08:16, 31.05s/it] 50%|█████     | 16/32 [08:28<08:32, 32.05s/it] 50%|█████     | 16/32 [08:30<08:19, 31.19s/it] 50%|█████     | 16/32 [08:38<08:42, 32.67s/it] 31%|███▏      | 10/32 [08:43<19:22, 52.84s/it] 50%|█████     | 16/32 [08:46<08:50, 33.16s/it] 41%|████      | 13/32 [08:46<12:54, 40.75s/it] 31%|███▏      | 10/32 [08:55<19:23, 52.91s/it] 53%|█████▎    | 17/32 [08:55<07:46, 31.13s/it] 53%|█████▎    | 17/32 [08:59<07:58, 31.91s/it] 53%|█████▎    | 17/32 [09:02<07:51, 31.45s/it] 53%|█████▎    | 17/32 [09:11<08:13, 32.91s/it] 53%|█████▎    | 17/32 [09:16<08:05, 32.39s/it] 56%|█████▋    | 18/32 [09:28<07:23, 31.69s/it] 44%|████▍     | 14/32 [09:30<12:29, 41.64s/it] 56%|█████▋    | 18/32 [09:31<07:26, 31.86s/it] 56%|█████▋    | 18/32 [09:33<07:20, 31.44s/it] 34%|███▍      | 11/32 [09:36<18:31, 52.91s/it] 56%|█████▋    | 18/32 [09:44<07:39, 32.82s/it] 56%|█████▋    | 18/32 [09:47<07:26, 31.91s/it] 34%|███▍      | 11/32 [09:52<18:59, 54.27s/it] 59%|█████▉    | 19/32 [10:01<06:56, 32.07s/it] 59%|█████▉    | 19/32 [10:02<06:49, 31.50s/it] 59%|█████▉    | 19/32 [10:03<06:44, 31.10s/it] 47%|████▋     | 15/32 [10:10<11:40, 41.22s/it] 59%|█████▉    | 19/32 [10:18<06:50, 31.58s/it] 59%|█████▉    | 19/32 [10:19<07:13, 33.34s/it] 62%|██████▎   | 20/32 [10:32<06:12, 31.05s/it] 38%|███▊      | 12/32 [10:32<17:59, 53.96s/it] 62%|██████▎   | 20/32 [10:33<06:25, 32.11s/it] 62%|██████▎   | 20/32 [10:34<06:10, 30.88s/it] 38%|███▊      | 12/32 [10:44<17:47, 53.38s/it] 62%|██████▎   | 20/32 [10:49<06:15, 31.33s/it] 62%|██████▎   | 20/32 [10:49<06:30, 32.56s/it] 50%|█████     | 16/32 [10:52<11:00, 41.27s/it] 66%|██████▌   | 21/32 [11:04<05:49, 31.81s/it] 66%|██████▌   | 21/32 [11:06<05:52, 32.08s/it] 66%|██████▌   | 21/32 [11:08<05:50, 31.83s/it] 66%|██████▌   | 21/32 [11:21<05:55, 32.29s/it] 66%|██████▌   | 21/32 [11:22<05:52, 32.01s/it] 41%|████      | 13/32 [11:25<16:59, 53.68s/it] 53%|█████▎    | 17/32 [11:30<10:07, 40.53s/it] 69%|██████▉   | 22/32 [11:37<05:19, 31.91s/it] 69%|██████▉   | 22/32 [11:38<05:19, 31.96s/it] 41%|████      | 13/32 [11:40<17:08, 54.13s/it] 69%|██████▉   | 22/32 [11:40<05:19, 31.93s/it] 69%|██████▉   | 22/32 [11:54<05:26, 32.65s/it] 69%|██████▉   | 22/32 [11:57<05:27, 32.75s/it] 72%|███████▏  | 23/32 [12:08<04:44, 31.64s/it] 72%|███████▏  | 23/32 [12:10<04:46, 31.85s/it] 56%|█████▋    | 18/32 [12:11<09:26, 40.45s/it] 72%|███████▏  | 23/32 [12:12<04:47, 31.94s/it] 44%|████▍     | 14/32 [12:15<15:46, 52.57s/it] 72%|███████▏  | 23/32 [12:26<04:51, 32.36s/it] 72%|███████▏  | 23/32 [12:28<04:51, 32.44s/it] 44%|████▍     | 14/32 [12:31<15:58, 53.23s/it] 78%|███████▊  | 25/32 [12:39<02:49, 24.23s/it] 75%|███████▌  | 24/32 [12:40<04:12, 31.55s/it] 75%|███████▌  | 24/32 [12:43<04:13, 31.72s/it] 59%|█████▉    | 19/32 [12:51<08:44, 40.37s/it] 75%|███████▌  | 24/32 [12:59<04:15, 31.90s/it] 75%|███████▌  | 24/32 [12:59<04:19, 32.42s/it] 47%|████▋     | 15/32 [13:05<14:39, 51.76s/it] 81%|████████▏ | 26/32 [13:10<02:35, 25.92s/it] 78%|███████▊  | 25/32 [13:10<03:37, 31.07s/it] 78%|███████▊  | 25/32 [13:16<03:44, 32.11s/it] 47%|████▋     | 15/32 [13:20<14:46, 52.12s/it] 62%|██████▎   | 20/32 [13:31<08:03, 40.31s/it] 78%|███████▊  | 25/32 [13:30<03:43, 31.96s/it] 78%|███████▊  | 25/32 [13:31<03:43, 31.88s/it] 84%|████████▍ | 27/32 [13:40<02:15, 27.10s/it] 81%|████████▏ | 26/32 [13:41<03:05, 30.96s/it] 81%|████████▏ | 26/32 [13:47<03:11, 31.85s/it] 50%|█████     | 16/32 [13:55<13:39, 51.21s/it] 81%|████████▏ | 26/32 [14:00<03:09, 31.58s/it] 81%|████████▏ | 26/32 [14:02<03:09, 31.52s/it] 50%|█████     | 16/32 [14:10<13:43, 51.46s/it] 84%|████████▍ | 27/32 [14:13<02:35, 31.14s/it] 88%|████████▊ | 28/32 [14:13<01:54, 28.70s/it] 66%|██████▌   | 21/32 [14:13<07:30, 40.96s/it] 84%|████████▍ | 27/32 [14:21<02:41, 32.26s/it] 84%|████████▍ | 27/32 [14:31<02:36, 31.32s/it] 84%|████████▍ | 27/32 [14:32<02:36, 31.28s/it] 88%|████████▊ | 28/32 [14:43<02:04, 31.03s/it] 91%|█████████ | 29/32 [14:48<01:31, 30.47s/it] 88%|████████▊ | 28/32 [14:51<02:06, 31.66s/it] 53%|█████▎    | 17/32 [14:51<13:10, 52.72s/it] 69%|██████▉   | 22/32 [14:52<06:43, 40.37s/it] 53%|█████▎    | 17/32 [15:00<12:44, 50.96s/it] 88%|████████▊ | 28/32 [15:02<02:04, 31.13s/it] 88%|████████▊ | 28/32 [15:05<02:06, 31.65s/it] 91%|█████████ | 29/32 [15:14<01:32, 30.92s/it] 91%|█████████ | 29/32 [15:22<01:34, 31.50s/it] 94%|█████████▍| 30/32 [15:24<01:04, 32.01s/it] 72%|███████▏  | 23/32 [15:33<06:02, 40.30s/it] 91%|█████████ | 29/32 [15:33<01:33, 31.30s/it] 91%|█████████ | 29/32 [15:36<01:34, 31.38s/it] 94%|█████████▍| 30/32 [15:44<01:01, 30.62s/it] 56%|█████▋    | 18/32 [15:46<12:27, 53.36s/it] 56%|█████▋    | 18/32 [15:51<11:54, 51.03s/it] 94%|█████████▍| 30/32 [15:53<01:02, 31.42s/it] 97%|█████████▋| 31/32 [15:54<00:31, 31.49s/it] 94%|█████████▍| 30/32 [16:04<01:02, 31.12s/it] 94%|█████████▍| 30/32 [16:09<01:04, 32.03s/it] 97%|█████████▋| 31/32 [16:15<00:30, 30.64s/it] 75%|███████▌  | 24/32 [16:18<05:33, 41.72s/it] 97%|█████████▋| 31/32 [16:24<00:31, 31.39s/it]100%|██████████| 32/32 [16:26<00:00, 31.68s/it]100%|██████████| 32/32 [16:26<00:00, 30.84s/it]
 59%|█████▉    | 19/32 [16:38<11:27, 52.85s/it] 97%|█████████▋| 31/32 [16:39<00:32, 32.14s/it] 97%|█████████▋| 31/32 [16:41<00:31, 31.92s/it] 59%|█████▉    | 19/32 [16:44<11:10, 51.58s/it]100%|██████████| 32/32 [16:44<00:00, 30.37s/it]100%|██████████| 32/32 [16:44<00:00, 31.41s/it]
100%|██████████| 32/32 [16:56<00:00, 31.55s/it]100%|██████████| 32/32 [16:56<00:00, 31.78s/it]
 78%|███████▊  | 25/32 [17:00<04:53, 41.93s/it]100%|██████████| 32/32 [17:10<00:00, 31.94s/it]100%|██████████| 32/32 [17:10<00:00, 32.20s/it]
100%|██████████| 32/32 [17:11<00:00, 31.47s/it]100%|██████████| 32/32 [17:11<00:00, 32.24s/it]
 62%|██████▎   | 20/32 [17:28<10:23, 51.99s/it] 62%|██████▎   | 20/32 [17:34<10:12, 51.03s/it] 81%|████████▏ | 26/32 [17:42<04:12, 42.07s/it] 66%|██████▌   | 21/32 [18:18<09:25, 51.40s/it] 84%|████████▍ | 27/32 [18:23<03:28, 41.73s/it] 66%|██████▌   | 21/32 [18:25<09:22, 51.10s/it] 88%|████████▊ | 28/32 [19:03<02:44, 41.11s/it] 69%|██████▉   | 22/32 [19:11<08:39, 51.96s/it] 69%|██████▉   | 22/32 [19:21<08:45, 52.53s/it] 91%|█████████ | 29/32 [19:44<02:03, 41.09s/it] 72%|███████▏  | 23/32 [20:03<07:46, 51.84s/it] 72%|███████▏  | 23/32 [20:14<07:53, 52.62s/it] 94%|█████████▍| 30/32 [20:23<01:20, 40.34s/it] 75%|███████▌  | 24/32 [20:54<06:54, 51.80s/it] 97%|█████████▋| 31/32 [21:01<00:39, 39.83s/it] 75%|███████▌  | 24/32 [21:04<06:54, 51.79s/it] 78%|███████▊  | 25/32 [21:44<05:59, 51.29s/it]100%|██████████| 32/32 [21:48<00:00, 42.01s/it]100%|██████████| 32/32 [21:48<00:00, 40.90s/it]
 78%|███████▊  | 25/32 [21:57<06:05, 52.23s/it] 81%|████████▏ | 26/32 [22:36<05:08, 51.47s/it] 81%|████████▏ | 26/32 [22:48<05:11, 51.94s/it] 84%|████████▍ | 27/32 [23:28<04:17, 51.52s/it] 84%|████████▍ | 27/32 [23:39<04:18, 51.76s/it] 88%|████████▊ | 28/32 [24:21<03:28, 52.05s/it] 88%|████████▊ | 28/32 [24:31<03:26, 51.66s/it] 94%|█████████▍| 30/32 [25:14<01:20, 40.30s/it] 91%|█████████ | 29/32 [25:21<02:33, 51.08s/it] 97%|█████████▋| 31/32 [26:06<00:43, 43.12s/it] 94%|█████████▍| 30/32 [26:12<01:42, 51.18s/it][rank6]:[E ProcessGroupNCCL.cpp:523] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600319 milliseconds before timing out.
[rank6]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank6]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.
[rank6]:[E ProcessGroupNCCL.cpp:1182] [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600319 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7feaeb015d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7feaec1bd6e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7feaec1c0c3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7feaec1c1839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7feb35ed4df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7feb372c3609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7feb3708e353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600319 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7feaeb015d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7feaec1bd6e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7feaec1c0c3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7feaec1c1839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7feb35ed4df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7feb372c3609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7feb3708e353 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1186 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7feaeb015d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xdf6b11 (0x7feaebf17b11 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd6df4 (0x7feb35ed4df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7feb372c3609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7feb3708e353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank4]:[E ProcessGroupNCCL.cpp:523] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600851 milliseconds before timing out.
[rank4]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E ProcessGroupNCCL.cpp:1182] [Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600851 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff4b0503d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7ff4b16ab6e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7ff4b16aec3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7ff4b16af839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7ff4fb3c2df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7ff4fc7b1609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7ff4fc57c353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600851 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff4b0503d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7ff4b16ab6e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7ff4b16aec3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7ff4b16af839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7ff4fb3c2df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7ff4fc7b1609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7ff4fc57c353 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1186 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff4b0503d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xdf6b11 (0x7ff4b1405b11 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd6df4 (0x7ff4fb3c2df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7ff4fc7b1609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7ff4fc57c353 in /lib/x86_64-linux-gnu/libc.so.6)

100%|██████████| 32/32 [26:56<00:00, 44.96s/it]100%|██████████| 32/32 [26:56<00:00, 50.52s/it]
 97%|█████████▋| 31/32 [27:03<00:51, 51.12s/it][rank2]:[E ProcessGroupNCCL.cpp:523] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600502 milliseconds before timing out.
[rank0]:[E ProcessGroupNCCL.cpp:523] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=54, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 614693 milliseconds before timing out.
[rank1]:[E ProcessGroupNCCL.cpp:523] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=54, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600760 milliseconds before timing out.
[rank1]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E ProcessGroupNCCL.cpp:1182] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=54, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600760 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f85ec421d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f85ed5c96e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f85ed5ccc3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f85ed5cd839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7f86372e0df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f86386cf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f863849a353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=54, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600760 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f85ec421d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f85ed5c96e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f85ed5ccc3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f85ed5cd839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7f86372e0df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f86386cf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f863849a353 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1186 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f85ec421d87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xdf6b11 (0x7f85ed323b11 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd6df4 (0x7f86372e0df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7f86386cf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7f863849a353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E ProcessGroupNCCL.cpp:1182] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600502 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f49ccf3ad87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f49ce0e26e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f49ce0e5c3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f49ce0e6839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7f4a17df9df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f4a191e8609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f4a18fb3353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=53, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600502 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f49ccf3ad87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f49ce0e26e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f49ce0e5c3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f49ce0e6839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7f4a17df9df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f4a191e8609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f4a18fb3353 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1186 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f49ccf3ad87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xdf6b11 (0x7f49cde3cb11 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd6df4 (0x7f4a17df9df4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7f4a191e8609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7f4a18fb3353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank0]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.
[rank0]:[E ProcessGroupNCCL.cpp:1182] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=54, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 614693 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff96bb9fd87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7ff96cd476e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7ff96cd4ac3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7ff96cd4b839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7ff9b6a5edf4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7ff9b7e4d609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7ff9b7c18353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=54, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 614693 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff96bb9fd87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7ff96cd476e6 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7ff96cd4ac3d in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7ff96cd4b839 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd6df4 (0x7ff9b6a5edf4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7ff9b7e4d609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7ff9b7c18353 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1186 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff96bb9fd87 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xdf6b11 (0x7ff96caa1b11 in /fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd6df4 (0x7ff9b6a5edf4 in /lib/x86_64-linux-gnu/libstdc++.so.6)
frame #3: <unknown function> + 0x8609 (0x7ff9b7e4d609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #4: clone + 0x43 (0x7ff9b7c18353 in /lib/x86_64-linux-gnu/libc.so.6)

[2024-07-09 15:46:40,381] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2489110 closing signal SIGTERM
[2024-07-09 15:46:40,387] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2489111 closing signal SIGTERM
[2024-07-09 15:46:40,388] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2489112 closing signal SIGTERM
[2024-07-09 15:46:40,388] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2489113 closing signal SIGTERM
[2024-07-09 15:46:40,388] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2489115 closing signal SIGTERM
[2024-07-09 15:46:40,388] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2489116 closing signal SIGTERM
[2024-07-09 15:46:40,388] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2489117 closing signal SIGTERM
[2024-07-09 15:46:49,418] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 4 (pid: 2489114) of binary: /fsx-storygen/beidic/anaconda3/envs/griffin/bin/python3.9
Traceback (most recent call last):
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
main.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-09_15:46:40
  host      : a100-st-p4de24xlarge-864.fair-a100.hpcaas
  rank      : 4 (local_rank: 4)
  exitcode  : -6 (pid: 2489114)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 2489114
========================================================
