Already on 'yangexppp'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-08-04:23:30:27,180 INFO     [main.py:288] Verbosity set to INFO
2024-08-04:23:30:36,838 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-08-04:23:30:36,872 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-08-04:23:30:36,872 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-70B-Instruct', 'cats': True, 'check': True, 'contextlength': 1500, 'kernel_size': 16, 'thr': 0.1}
2024-08-04:23:30:36,881 INFO     [xhuggingface.py:176] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:05<02:49,  5.84s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:11<02:40,  5.75s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:17<02:38,  5.88s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:23<02:34,  5.95s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:29<02:24,  5.80s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:34<02:16,  5.71s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:40<02:11,  5.70s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:46<02:08,  5.85s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:52<02:04,  5.91s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:58<01:56,  5.85s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [01:04<01:50,  5.81s/it]Loading checkpoint shards:  40%|████      | 12/30 [01:09<01:42,  5.69s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [01:15<01:37,  5.71s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [01:20<01:31,  5.70s/it]Loading checkpoint shards:  50%|█████     | 15/30 [01:26<01:23,  5.59s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [01:31<01:17,  5.56s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [01:37<01:11,  5.49s/it]Loading checkpoint shards:  60%|██████    | 18/30 [01:42<01:06,  5.54s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [01:48<01:01,  5.58s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [01:53<00:55,  5.54s/it]Loading checkpoint shards:  70%|███████   | 21/30 [01:59<00:49,  5.51s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [02:04<00:43,  5.50s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [02:10<00:39,  5.58s/it]Loading checkpoint shards:  80%|████████  | 24/30 [02:16<00:33,  5.62s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [02:21<00:27,  5.53s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [02:26<00:21,  5.47s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [02:32<00:16,  5.45s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [02:37<00:11,  5.53s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [02:43<00:05,  5.55s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:46<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:46<00:00,  5.54s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-08-04:23:39:53,676 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-04:23:39:53,676 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-04:23:39:53,758 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 0...
  0%|          | 0/1319 [00:00<?, ?it/s] 13%|█▎        | 169/1319 [00:00<00:00, 1683.47it/s] 26%|██▌       | 339/1319 [00:00<00:00, 1689.36it/s] 39%|███▊      | 509/1319 [00:00<00:00, 1690.73it/s] 51%|█████▏    | 679/1319 [00:00<00:00, 1690.36it/s] 64%|██████▍   | 849/1319 [00:00<00:00, 1690.36it/s] 77%|███████▋  | 1019/1319 [00:00<00:00, 1674.98it/s] 90%|█████████ | 1189/1319 [00:00<00:00, 1681.84it/s]100%|██████████| 1319/1319 [00:00<00:00, 1686.04it/s]
2024-08-04:23:39:54,572 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 1/1319 [00:45<16:36:04, 45.35s/it]Running generate_until requests:   0%|          | 2/1319 [01:17<13:38:59, 37.31s/it]Running generate_until requests:   0%|          | 3/1319 [01:58<14:16:24, 39.05s/it]Running generate_until requests:   0%|          | 4/1319 [02:40<14:42:04, 40.25s/it]Running generate_until requests:   0%|          | 5/1319 [03:57<19:33:11, 53.57s/it]Running generate_until requests:   0%|          | 6/1319 [04:53<19:50:21, 54.40s/it]Running generate_until requests:   1%|          | 7/1319 [05:29<17:35:24, 48.27s/it]Running generate_until requests:   1%|          | 8/1319 [06:14<17:17:07, 47.47s/it]Running generate_until requests:   1%|          | 9/1319 [06:50<15:57:07, 43.84s/it]Running generate_until requests:   1%|          | 10/1319 [07:41<16:42:54, 45.97s/it]Running generate_until requests:   1%|          | 11/1319 [08:22<16:08:13, 44.41s/it]Running generate_until requests:   1%|          | 12/1319 [09:23<17:57:06, 49.45s/it]Running generate_until requests:   1%|          | 13/1319 [10:04<16:59:09, 46.82s/it]