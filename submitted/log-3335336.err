wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.62s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.51s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.84s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.41s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.71s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.65s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.72s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.18s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.46s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.31s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.45s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.42s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 34.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.52s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.36s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 34.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.71s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [01:10<23:29, 70.46s/it]  5%|▍         | 1/21 [01:00<20:09, 60.49s/it]  5%|▍         | 1/21 [01:10<23:22, 70.13s/it]  5%|▍         | 1/21 [01:11<23:41, 71.06s/it]  5%|▍         | 1/21 [01:10<23:32, 70.63s/it]  5%|▍         | 1/21 [01:11<23:42, 71.11s/it]  5%|▍         | 1/21 [01:11<23:44, 71.22s/it]  5%|▍         | 1/21 [00:58<19:33, 58.69s/it] 10%|▉         | 2/21 [02:04<19:10, 60.55s/it] 10%|▉         | 2/21 [02:04<19:14, 60.75s/it] 10%|▉         | 2/21 [02:03<19:09, 60.48s/it] 10%|▉         | 2/21 [02:04<19:13, 60.73s/it] 10%|▉         | 2/21 [02:04<19:15, 60.80s/it] 10%|▉         | 2/21 [01:52<17:37, 55.63s/it] 10%|▉         | 2/21 [02:03<19:06, 60.35s/it] 10%|▉         | 2/21 [01:53<17:51, 56.38s/it] 14%|█▍        | 3/21 [02:42<15:11, 50.64s/it] 14%|█▍        | 3/21 [02:43<15:15, 50.84s/it] 14%|█▍        | 3/21 [02:43<15:15, 50.88s/it] 14%|█▍        | 3/21 [02:43<15:15, 50.85s/it] 14%|█▍        | 3/21 [02:43<15:12, 50.71s/it] 14%|█▍        | 3/21 [02:33<14:32, 48.48s/it] 14%|█▍        | 3/21 [02:43<15:13, 50.75s/it] 14%|█▍        | 3/21 [02:31<14:25, 48.08s/it] 19%|█▉        | 4/21 [03:30<13:54, 49.08s/it] 19%|█▉        | 4/21 [03:29<13:53, 49.00s/it] 19%|█▉        | 4/21 [03:30<13:54, 49.09s/it] 19%|█▉        | 4/21 [03:29<13:52, 48.96s/it] 19%|█▉        | 4/21 [03:19<13:30, 47.65s/it] 19%|█▉        | 4/21 [03:29<13:53, 49.03s/it] 19%|█▉        | 4/21 [03:30<13:54, 49.11s/it] 19%|█▉        | 4/21 [03:17<13:25, 47.41s/it] 24%|██▍       | 5/21 [04:07<12:02, 45.18s/it] 24%|██▍       | 5/21 [04:08<12:03, 45.25s/it] 24%|██▍       | 5/21 [04:08<12:03, 45.24s/it] 24%|██▍       | 5/21 [04:07<12:03, 45.19s/it] 24%|██▍       | 5/21 [04:08<12:03, 45.23s/it] 24%|██▍       | 5/21 [04:07<12:02, 45.15s/it] 24%|██▍       | 5/21 [03:57<11:49, 44.32s/it] 24%|██▍       | 5/21 [03:56<11:46, 44.16s/it] 29%|██▊       | 6/21 [04:51<11:07, 44.48s/it] 29%|██▊       | 6/21 [04:51<11:07, 44.50s/it] 29%|██▊       | 6/21 [04:51<11:07, 44.51s/it] 29%|██▊       | 6/21 [04:50<11:06, 44.45s/it] 29%|██▊       | 6/21 [04:50<11:07, 44.47s/it] 29%|██▊       | 6/21 [04:51<11:07, 44.50s/it] 29%|██▊       | 6/21 [04:40<10:58, 43.90s/it] 29%|██▊       | 6/21 [04:39<10:56, 43.80s/it] 33%|███▎      | 7/21 [05:54<11:52, 50.91s/it] 33%|███▎      | 7/21 [05:55<11:53, 50.95s/it] 33%|███▎      | 7/21 [05:55<11:53, 50.95s/it] 33%|███▎      | 7/21 [05:55<11:53, 50.95s/it] 33%|███▎      | 7/21 [05:55<11:53, 50.93s/it] 33%|███▎      | 7/21 [05:55<11:52, 50.93s/it] 33%|███▎      | 7/21 [05:45<11:47, 50.54s/it] 33%|███▎      | 7/21 [05:43<11:46, 50.47s/it] 38%|███▊      | 8/21 [06:57<11:47, 54.46s/it] 38%|███▊      | 8/21 [06:56<11:47, 54.43s/it] 38%|███▊      | 8/21 [06:57<11:47, 54.46s/it] 38%|███▊      | 8/21 [06:57<11:47, 54.44s/it] 38%|███▊      | 8/21 [06:57<11:47, 54.44s/it] 38%|███▊      | 8/21 [06:57<11:47, 54.46s/it] 38%|███▊      | 8/21 [06:47<11:44, 54.18s/it] 38%|███▊      | 8/21 [06:45<11:43, 54.13s/it] 43%|████▎     | 9/21 [07:33<09:44, 48.71s/it] 43%|████▎     | 9/21 [07:33<09:44, 48.70s/it] 43%|████▎     | 9/21 [07:33<09:44, 48.69s/it] 43%|████▎     | 9/21 [07:33<09:44, 48.70s/it] 43%|████▎     | 9/21 [07:32<09:44, 48.69s/it] 43%|████▎     | 9/21 [07:33<09:44, 48.70s/it] 43%|████▎     | 9/21 [07:21<09:41, 48.48s/it] 43%|████▎     | 9/21 [07:23<09:42, 48.51s/it]