wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:14, 24.93s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.61s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.64s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.64s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:18, 26.02s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:17, 25.88s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.63s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:44<00:43, 21.59s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:44, 22.11s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:43, 21.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:44, 22.04s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:44, 22.03s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:44, 22.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:44, 22.04s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:44, 22.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:03<00:20, 20.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:04<00:20, 20.60s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:04<00:20, 20.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:04<00:20, 20.60s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:04<00:20, 20.78s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:04<00:20, 20.72s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:04<00:20, 20.71s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:04<00:20, 20.67s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 13.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.30s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 13.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.39s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 13.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.40s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 13.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.48s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 13.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.40s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 13.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.45s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 13.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.44s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 13.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 16.55s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [00:17<05:55, 17.76s/it]  5%|▍         | 1/21 [00:17<05:56, 17.84s/it]  5%|▍         | 1/21 [00:17<05:57, 17.88s/it]  5%|▍         | 1/21 [00:17<05:57, 17.88s/it]  5%|▍         | 1/21 [00:17<05:55, 17.78s/it]  5%|▍         | 1/21 [00:17<05:50, 17.52s/it]  5%|▍         | 1/21 [00:17<05:44, 17.23s/it]  5%|▍         | 1/21 [00:17<05:52, 17.64s/it] 10%|▉         | 2/21 [00:18<02:27,  7.78s/it] 10%|▉         | 2/21 [00:18<02:27,  7.78s/it] 10%|▉         | 2/21 [00:18<02:27,  7.76s/it] 10%|▉         | 2/21 [00:18<02:26,  7.73s/it] 10%|▉         | 2/21 [00:18<02:27,  7.74s/it] 10%|▉         | 2/21 [00:18<02:25,  7.68s/it] 10%|▉         | 2/21 [00:18<02:24,  7.63s/it] 10%|▉         | 2/21 [00:17<02:22,  7.51s/it] 14%|█▍        | 3/21 [00:35<03:38, 12.15s/it] 14%|█▍        | 3/21 [00:35<03:38, 12.14s/it] 14%|█▍        | 3/21 [00:35<03:38, 12.14s/it] 14%|█▍        | 3/21 [00:35<03:38, 12.16s/it] 14%|█▍        | 3/21 [00:35<03:37, 12.11s/it] 14%|█▍        | 3/21 [00:35<03:38, 12.16s/it] 14%|█▍        | 3/21 [00:35<03:36, 12.02s/it] 14%|█▍        | 3/21 [00:35<03:37, 12.08s/it] 19%|█▉        | 4/21 [00:38<02:21,  8.32s/it] 19%|█▉        | 4/21 [00:38<02:21,  8.31s/it] 19%|█▉        | 4/21 [00:38<02:21,  8.31s/it] 19%|█▉        | 4/21 [00:38<02:21,  8.32s/it] 19%|█▉        | 4/21 [00:38<02:20,  8.27s/it] 19%|█▉        | 4/21 [00:37<02:19,  8.23s/it] 19%|█▉        | 4/21 [00:38<02:20,  8.29s/it] 19%|█▉        | 4/21 [00:38<02:21,  8.32s/it] 24%|██▍       | 5/21 [00:40<01:35,  5.96s/it] 24%|██▍       | 5/21 [00:40<01:35,  5.97s/it] 24%|██▍       | 5/21 [00:40<01:35,  5.97s/it] 24%|██▍       | 5/21 [00:39<01:35,  5.95s/it] 24%|██▍       | 5/21 [00:40<01:35,  5.96s/it] 24%|██▍       | 5/21 [00:40<01:35,  5.97s/it] 24%|██▍       | 5/21 [00:39<01:35,  5.94s/it] 24%|██▍       | 5/21 [00:39<01:34,  5.92s/it] 29%|██▊       | 6/21 [00:41<01:05,  4.39s/it] 29%|██▊       | 6/21 [00:41<01:05,  4.39s/it] 29%|██▊       | 6/21 [00:41<01:05,  4.39s/it] 29%|██▊       | 6/21 [00:41<01:05,  4.39s/it] 29%|██▊       | 6/21 [00:41<01:05,  4.39s/it] 29%|██▊       | 6/21 [00:41<01:05,  4.38s/it] 29%|██▊       | 6/21 [00:41<01:05,  4.37s/it] 29%|██▊       | 6/21 [00:40<01:05,  4.36s/it] 33%|███▎      | 7/21 [00:44<00:54,  3.87s/it] 33%|███▎      | 7/21 [00:44<00:53,  3.86s/it] 33%|███▎      | 7/21 [00:44<00:54,  3.87s/it] 33%|███▎      | 7/21 [00:44<00:54,  3.86s/it] 33%|███▎      | 7/21 [00:44<00:54,  3.86s/it] 33%|███▎      | 7/21 [00:44<00:54,  3.86s/it] 33%|███▎      | 7/21 [00:43<00:53,  3.84s/it] 33%|███▎      | 7/21 [00:43<00:53,  3.85s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.07s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.08s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.08s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.07s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.08s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.07s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.07s/it] 38%|███▊      | 8/21 [00:45<00:39,  3.06s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.89s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.89s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.89s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.89s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.89s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.89s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.89s/it] 43%|████▎     | 9/21 [00:57<01:10,  5.88s/it] 48%|████▊     | 10/21 [01:03<01:04,  5.87s/it] 48%|████▊     | 10/21 [01:03<01:04,  5.87s/it] 48%|████▊     | 10/21 [01:03<01:04,  5.87s/it] 48%|████▊     | 10/21 [01:03<01:04,  5.87s/it] 48%|████▊     | 10/21 [01:03<01:04,  5.87s/it] 48%|████▊     | 10/21 [01:02<01:04,  5.86s/it] 48%|████▊     | 10/21 [01:03<01:04,  5.87s/it] 48%|████▊     | 10/21 [01:03<01:04,  5.87s/it] 52%|█████▏    | 11/21 [01:06<00:49,  4.98s/it] 52%|█████▏    | 11/21 [01:06<00:49,  4.98s/it] 52%|█████▏    | 11/21 [01:06<00:49,  4.98s/it] 52%|█████▏    | 11/21 [01:06<00:49,  4.98s/it] 52%|█████▏    | 11/21 [01:06<00:49,  4.98s/it] 52%|█████▏    | 11/21 [01:06<00:49,  4.98s/it] 52%|█████▏    | 11/21 [01:06<00:49,  4.98s/it] 52%|█████▏    | 11/21 [01:05<00:49,  4.98s/it] 57%|█████▋    | 12/21 [01:10<00:42,  4.69s/it] 57%|█████▋    | 12/21 [01:10<00:42,  4.69s/it] 57%|█████▋    | 12/21 [01:10<00:42,  4.69s/it] 57%|█████▋    | 12/21 [01:10<00:42,  4.69s/it] 57%|█████▋    | 12/21 [01:10<00:42,  4.69s/it] 57%|█████▋    | 12/21 [01:09<00:42,  4.68s/it] 57%|█████▋    | 12/21 [01:10<00:42,  4.69s/it] 57%|█████▋    | 12/21 [01:10<00:42,  4.68s/it] 62%|██████▏   | 13/21 [01:12<00:30,  3.80s/it] 62%|██████▏   | 13/21 [01:12<00:30,  3.80s/it] 62%|██████▏   | 13/21 [01:12<00:30,  3.80s/it] 62%|██████▏   | 13/21 [01:12<00:30,  3.80s/it] 62%|██████▏   | 13/21 [01:12<00:30,  3.80s/it] 62%|██████▏   | 13/21 [01:12<00:30,  3.80s/it] 62%|██████▏   | 13/21 [01:11<00:30,  3.80s/it] 62%|██████▏   | 13/21 [01:11<00:30,  3.80s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 67%|██████▋   | 14/21 [01:13<00:21,  3.09s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 71%|███████▏  | 15/21 [01:16<00:18,  3.04s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 76%|███████▌  | 16/21 [01:18<00:13,  2.78s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 81%|████████  | 17/21 [01:20<00:10,  2.54s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 86%|████████▌ | 18/21 [01:25<00:09,  3.31s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 90%|█████████ | 19/21 [01:27<00:05,  2.84s/it] 95%|█████████▌| 20/21 [01:38<00:05,  5.12s/it] 95%|█████████▌| 20/21 [01:38<00:05,  5.12s/it] 95%|█████████▌| 20/21 [01:38<00:05,  5.12s/it] 95%|█████████▌| 20/21 [01:37<00:05,  5.12s/it] 95%|█████████▌| 20/21 [01:38<00:05,  5.12s/it] 95%|█████████▌| 20/21 [01:38<00:05,  5.12s/it] 95%|█████████▌| 20/21 [01:37<00:05,  5.12s/it] 95%|█████████▌| 20/21 [01:37<00:05,  5.12s/it]100%|██████████| 21/21 [01:43<00:00,  5.09s/it]100%|██████████| 21/21 [01:43<00:00,  5.09s/it]100%|██████████| 21/21 [01:43<00:00,  5.09s/it]100%|██████████| 21/21 [01:43<00:00,  5.09s/it]100%|██████████| 21/21 [01:42<00:00,  5.09s/it]100%|██████████| 21/21 [01:43<00:00,  5.09s/it]100%|██████████| 21/21 [01:42<00:00,  5.09s/it]100%|██████████| 21/21 [01:42<00:00,  5.09s/it]22it [01:44,  4.04s/it]                        22it [01:44,  4.04s/it]                        22it [01:44,  4.04s/it]                        22it [01:44,  4.04s/it]                        22it [01:44,  4.04s/it]                        22it [01:44,  4.04s/it]                        22it [01:44,  4.04s/it]                        22it [01:44,  4.04s/it]                        23it [01:45,  3.21s/it]23it [01:46,  3.21s/it]23it [01:46,  3.21s/it]23it [01:45,  3.21s/it]23it [01:46,  3.21s/it]23it [01:45,  3.21s/it]23it [01:45,  3.21s/it]23it [01:45,  3.21s/it]24it [01:49,  3.22s/it]24it [01:49,  3.22s/it]24it [01:49,  3.22s/it]24it [01:49,  3.22s/it]24it [01:49,  3.22s/it]24it [01:48,  3.22s/it]24it [01:49,  3.22s/it]24it [01:48,  3.22s/it]25it [01:50,  2.74s/it]25it [01:50,  2.74s/it]25it [01:50,  2.74s/it]25it [01:50,  2.74s/it]25it [01:50,  2.74s/it]25it [01:50,  2.74s/it]25it [01:50,  2.74s/it]25it [01:50,  2.74s/it]26it [01:53,  2.63s/it]26it [01:53,  2.63s/it]26it [01:53,  2.63s/it]26it [01:53,  2.63s/it]26it [01:53,  2.63s/it]26it [01:53,  2.63s/it]26it [01:52,  2.63s/it]26it [01:52,  2.63s/it]27it [01:56,  2.70s/it]27it [01:55,  2.70s/it]27it [01:56,  2.70s/it]27it [01:56,  2.70s/it]27it [01:56,  2.70s/it]27it [01:55,  2.70s/it]27it [01:55,  2.70s/it]27it [01:56,  2.70s/it]28it [01:58,  2.49s/it]28it [01:58,  2.49s/it]28it [01:58,  2.49s/it]28it [01:58,  2.49s/it]28it [01:57,  2.49s/it]28it [01:58,  2.49s/it]28it [01:57,  2.49s/it]28it [01:57,  2.49s/it]29it [02:05,  4.06s/it]29it [02:05,  4.06s/it]29it [02:05,  4.06s/it]29it [02:05,  4.06s/it]29it [02:05,  4.06s/it]29it [02:05,  4.06s/it]29it [02:05,  4.06s/it]29it [02:05,  4.06s/it]30it [02:08,  3.59s/it]30it [02:08,  3.59s/it]30it [02:08,  3.59s/it]30it [02:08,  3.59s/it]30it [02:08,  3.59s/it]30it [02:07,  3.59s/it]30it [02:08,  3.59s/it]30it [02:08,  3.59s/it]31it [02:09,  2.95s/it]31it [02:09,  2.95s/it]31it [02:09,  2.95s/it]31it [02:09,  2.95s/it]31it [02:09,  2.95s/it]31it [02:09,  2.95s/it]31it [02:09,  2.95s/it]31it [02:09,  2.95s/it]32it [02:18,  4.80s/it]32it [02:18,  4.80s/it]32it [02:18,  4.80s/it]32it [02:18,  4.80s/it]32it [02:18,  4.80s/it]32it [02:18,  4.80s/it]32it [02:18,  4.80s/it]32it [02:18,  4.80s/it]33it [02:24,  4.88s/it]33it [02:23,  4.88s/it]33it [02:24,  4.88s/it]33it [02:23,  4.88s/it]33it [02:23,  4.88s/it]33it [02:23,  4.88s/it]33it [02:23,  4.88s/it]33it [02:23,  4.88s/it]34it [02:24,  3.75s/it]34it [02:25,  3.75s/it]34it [02:25,  3.75s/it]34it [02:25,  3.75s/it]34it [02:25,  3.75s/it]34it [02:24,  3.75s/it]34it [02:24,  3.75s/it]34it [02:25,  3.75s/it]35it [02:29,  4.08s/it]35it [02:29,  4.08s/it]35it [02:29,  4.08s/it]35it [02:29,  4.08s/it]35it [02:29,  4.08s/it]35it [02:29,  4.08s/it]35it [02:29,  4.08s/it]35it [02:29,  4.08s/it]36it [02:33,  3.83s/it]36it [02:33,  3.83s/it]36it [02:33,  3.83s/it]36it [02:33,  3.83s/it]36it [02:33,  3.83s/it]36it [02:32,  3.83s/it]36it [02:32,  3.83s/it]36it [02:32,  3.83s/it]37it [02:36,  3.71s/it]37it [02:36,  3.71s/it]37it [02:36,  3.71s/it]37it [02:36,  3.71s/it]37it [02:36,  3.71s/it]37it [02:36,  3.71s/it]37it [02:36,  3.71s/it]37it [02:36,  3.71s/it]38it [02:40,  3.83s/it]38it [02:40,  3.83s/it]38it [02:40,  3.83s/it]38it [02:40,  3.83s/it]38it [02:40,  3.83s/it]38it [02:40,  3.83s/it]38it [02:40,  3.83s/it]38it [02:40,  3.83s/it]39it [02:42,  3.33s/it]39it [02:42,  3.33s/it]39it [02:42,  3.33s/it]39it [02:42,  3.33s/it]39it [02:42,  3.33s/it]39it [02:42,  3.33s/it]39it [02:42,  3.33s/it]39it [02:42,  3.33s/it]40it [02:44,  2.70s/it]40it [02:43,  2.70s/it]40it [02:44,  2.70s/it]40it [02:44,  2.70s/it]40it [02:44,  2.70s/it]40it [02:44,  2.70s/it]40it [02:43,  2.70s/it]40it [02:43,  2.70s/it]41it [02:44,  2.19s/it]41it [02:45,  2.19s/it]41it [02:45,  2.19s/it]41it [02:45,  2.19s/it]41it [02:45,  2.19s/it]41it [02:45,  2.19s/it]41it [02:44,  2.19s/it]41it [02:44,  2.19s/it]41it [02:45,  4.03s/it]41it [02:45,  4.03s/it]41it [02:44,  4.02s/it]41it [02:45,  4.03s/it]41it [02:45,  4.03s/it]




41it [02:45,  4.03s/it]
41it [02:44,  4.01s/it]41it [02:44,  4.02s/it]

/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
