wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:08<01:08, 68.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.19s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.21s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.36s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.43s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.80s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.32s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 39.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 44.14s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:29<00:00, 39.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 39.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:29<00:00, 44.52s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 44.41s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:29<00:00, 40.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:29<00:00, 44.70s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 39.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 44.44s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 39.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 44.48s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 39.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 44.44s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 39.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:28<00:00, 44.48s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [00:45<15:13, 45.66s/it]  5%|▍         | 1/21 [00:45<15:14, 45.75s/it]  5%|▍         | 1/21 [00:45<15:09, 45.48s/it]  5%|▍         | 1/21 [00:44<14:54, 44.71s/it]  5%|▍         | 1/21 [00:45<15:07, 45.39s/it]  5%|▍         | 1/21 [00:45<15:15, 45.75s/it]  5%|▍         | 1/21 [00:30<10:06, 30.30s/it]  5%|▍         | 1/21 [00:29<09:56, 29.80s/it] 10%|▉         | 2/21 [00:49<06:35, 20.83s/it] 10%|▉         | 2/21 [00:49<06:35, 20.80s/it] 10%|▉         | 2/21 [00:48<06:33, 20.72s/it] 10%|▉         | 2/21 [00:48<06:27, 20.41s/it] 10%|▉         | 2/21 [00:33<04:31, 14.27s/it] 10%|▉         | 2/21 [00:33<04:34, 14.47s/it] 10%|▉         | 2/21 [00:49<06:35, 20.84s/it] 10%|▉         | 2/21 [00:48<06:33, 20.69s/it] 14%|█▍        | 3/21 [00:54<04:07, 13.74s/it] 14%|█▍        | 3/21 [00:54<04:08, 13.80s/it] 14%|█▍        | 3/21 [00:54<04:08, 13.80s/it] 14%|█▍        | 3/21 [00:54<04:08, 13.78s/it] 14%|█▍        | 3/21 [00:53<04:04, 13.57s/it] 14%|█▍        | 3/21 [00:54<04:06, 13.72s/it] 14%|█▍        | 3/21 [00:38<03:04, 10.23s/it] 14%|█▍        | 3/21 [00:39<03:06, 10.34s/it] 19%|█▉        | 4/21 [00:58<02:49,  9.99s/it] 19%|█▉        | 4/21 [00:58<02:49,  9.98s/it] 19%|█▉        | 4/21 [00:57<02:47,  9.85s/it] 19%|█▉        | 4/21 [00:58<02:49,  9.99s/it] 19%|█▉        | 4/21 [00:58<02:49,  9.96s/it] 19%|█▉        | 4/21 [00:43<02:14,  7.90s/it] 19%|█▉        | 4/21 [00:42<02:13,  7.83s/it] 19%|█▉        | 4/21 [00:58<02:49,  9.94s/it] 24%|██▍       | 5/21 [01:10<02:52, 10.75s/it] 24%|██▍       | 5/21 [01:10<02:53, 10.83s/it] 24%|██▍       | 5/21 [01:11<02:53, 10.84s/it] 24%|██▍       | 5/21 [01:10<02:53, 10.82s/it] 24%|██▍       | 5/21 [01:11<02:53, 10.84s/it] 24%|██▍       | 5/21 [00:55<02:32,  9.50s/it] 24%|██▍       | 5/21 [01:10<02:52, 10.81s/it] 24%|██▍       | 5/21 [00:55<02:31,  9.46s/it] 29%|██▊       | 6/21 [01:19<02:27,  9.86s/it] 29%|██▊       | 6/21 [01:19<02:27,  9.86s/it] 29%|██▊       | 6/21 [01:18<02:27,  9.85s/it] 29%|██▊       | 6/21 [01:18<02:27,  9.84s/it] 29%|██▊       | 6/21 [01:17<02:26,  9.80s/it] 29%|██▊       | 6/21 [01:18<02:27,  9.84s/it] 29%|██▊       | 6/21 [01:03<02:14,  8.94s/it] 29%|██▊       | 6/21 [01:03<02:14,  8.97s/it] 33%|███▎      | 7/21 [01:21<01:45,  7.54s/it] 33%|███▎      | 7/21 [01:20<01:44,  7.50s/it] 33%|███▎      | 7/21 [01:21<01:45,  7.54s/it] 33%|███▎      | 7/21 [01:21<01:45,  7.54s/it] 33%|███▎      | 7/21 [01:21<01:45,  7.53s/it] 33%|███▎      | 7/21 [01:06<01:37,  6.94s/it] 33%|███▎      | 7/21 [01:21<01:45,  7.53s/it] 33%|███▎      | 7/21 [01:05<01:36,  6.93s/it] 38%|███▊      | 8/21 [01:41<02:31, 11.63s/it] 38%|███▊      | 8/21 [01:42<02:31, 11.66s/it] 38%|███▊      | 8/21 [01:42<02:31, 11.65s/it] 38%|███▊      | 8/21 [01:42<02:31, 11.66s/it] 38%|███▊      | 8/21 [01:42<02:31, 11.66s/it] 38%|███▊      | 8/21 [01:41<02:31, 11.65s/it] 38%|███▊      | 8/21 [01:26<02:26, 11.26s/it] 38%|███▊      | 8/21 [01:26<02:26, 11.24s/it] 43%|████▎     | 9/21 [01:46<01:53,  9.47s/it] 43%|████▎     | 9/21 [01:46<01:53,  9.47s/it] 43%|████▎     | 9/21 [01:46<01:53,  9.47s/it] 43%|████▎     | 9/21 [01:46<01:53,  9.47s/it] 43%|████▎     | 9/21 [01:45<01:53,  9.46s/it] 43%|████▎     | 9/21 [01:30<01:50,  9.19s/it] 43%|████▎     | 9/21 [01:46<01:53,  9.47s/it] 43%|████▎     | 9/21 [01:31<01:50,  9.20s/it] 48%|████▊     | 10/21 [01:53<01:33,  8.49s/it] 48%|████▊     | 10/21 [01:52<01:33,  8.48s/it] 48%|████▊     | 10/21 [01:52<01:33,  8.47s/it] 48%|████▊     | 10/21 [01:53<01:33,  8.49s/it] 48%|████▊     | 10/21 [01:53<01:33,  8.49s/it] 48%|████▊     | 10/21 [01:52<01:33,  8.48s/it] 48%|████▊     | 10/21 [01:37<01:31,  8.29s/it] 48%|████▊     | 10/21 [01:37<01:31,  8.30s/it] 52%|█████▏    | 11/21 [01:59<01:20,  8.02s/it] 52%|█████▏    | 11/21 [02:00<01:20,  8.02s/it] 52%|█████▏    | 11/21 [02:00<01:20,  8.02s/it] 52%|█████▏    | 11/21 [02:00<01:20,  8.02s/it] 52%|█████▏    | 11/21 [01:59<01:20,  8.02s/it] 52%|█████▏    | 11/21 [01:59<01:20,  8.01s/it] 52%|█████▏    | 11/21 [01:44<01:18,  7.88s/it] 52%|█████▏    | 11/21 [01:44<01:18,  7.89s/it] 57%|█████▋    | 12/21 [02:10<01:19,  8.86s/it] 57%|█████▋    | 12/21 [02:10<01:19,  8.86s/it] 57%|█████▋    | 12/21 [02:10<01:19,  8.86s/it] 57%|█████▋    | 12/21 [02:10<01:19,  8.86s/it] 57%|█████▋    | 12/21 [02:09<01:19,  8.85s/it] 57%|█████▋    | 12/21 [01:55<01:18,  8.76s/it] 57%|█████▋    | 12/21 [02:10<01:19,  8.86s/it] 57%|█████▋    | 12/21 [01:55<01:18,  8.77s/it] 62%|██████▏   | 13/21 [02:13<00:55,  6.94s/it] 62%|██████▏   | 13/21 [02:13<00:55,  6.94s/it] 62%|██████▏   | 13/21 [02:13<00:55,  6.94s/it] 62%|██████▏   | 13/21 [02:13<00:55,  6.94s/it] 62%|██████▏   | 13/21 [02:12<00:55,  6.94s/it] 62%|██████▏   | 13/21 [01:57<00:55,  6.88s/it] 62%|██████▏   | 13/21 [01:58<00:55,  6.88s/it] 62%|██████▏   | 13/21 [02:13<00:55,  6.94s/it] 67%|██████▋   | 14/21 [02:17<00:41,  5.97s/it] 67%|██████▋   | 14/21 [02:17<00:41,  5.97s/it] 67%|██████▋   | 14/21 [02:16<00:41,  5.97s/it] 67%|██████▋   | 14/21 [02:16<00:41,  5.97s/it] 67%|██████▋   | 14/21 [02:01<00:41,  5.93s/it] 67%|██████▋   | 14/21 [02:17<00:41,  5.97s/it] 67%|██████▋   | 14/21 [02:16<00:41,  5.97s/it] 67%|██████▋   | 14/21 [02:01<00:41,  5.93s/it] 71%|███████▏  | 15/21 [02:40<01:07, 11.25s/it] 71%|███████▏  | 15/21 [02:40<01:07, 11.24s/it] 71%|███████▏  | 15/21 [02:39<01:07, 11.24s/it] 71%|███████▏  | 15/21 [02:40<01:07, 11.24s/it] 71%|███████▏  | 15/21 [02:40<01:07, 11.25s/it] 71%|███████▏  | 15/21 [02:25<01:07, 11.21s/it] 71%|███████▏  | 15/21 [02:40<01:07, 11.25s/it] 71%|███████▏  | 15/21 [02:24<01:07, 11.21s/it] 76%|███████▌  | 16/21 [02:58<01:06, 13.28s/it] 76%|███████▌  | 16/21 [02:58<01:06, 13.28s/it] 76%|███████▌  | 16/21 [02:58<01:06, 13.28s/it] 76%|███████▌  | 16/21 [02:58<01:06, 13.28s/it] 76%|███████▌  | 16/21 [02:58<01:06, 13.28s/it] 76%|███████▌  | 16/21 [02:57<01:06, 13.28s/it] 76%|███████▌  | 16/21 [02:43<01:06, 13.26s/it] 76%|███████▌  | 16/21 [02:42<01:06, 13.26s/it] 81%|████████  | 17/21 [03:02<00:42, 10.53s/it] 81%|████████  | 17/21 [03:01<00:42, 10.53s/it] 81%|████████  | 17/21 [03:02<00:42, 10.53s/it] 81%|████████  | 17/21 [03:02<00:42, 10.53s/it] 81%|████████  | 17/21 [03:02<00:42, 10.53s/it] 81%|████████  | 17/21 [03:02<00:42, 10.53s/it] 81%|████████  | 17/21 [02:46<00:42, 10.51s/it] 81%|████████  | 17/21 [02:47<00:42, 10.52s/it] 86%|████████▌ | 18/21 [03:07<00:26,  8.94s/it] 86%|████████▌ | 18/21 [03:08<00:26,  8.94s/it] 86%|████████▌ | 18/21 [03:07<00:26,  8.94s/it] 86%|████████▌ | 18/21 [03:08<00:26,  8.94s/it] 86%|████████▌ | 18/21 [03:07<00:26,  8.94s/it] 86%|████████▌ | 18/21 [02:52<00:26,  8.93s/it] 86%|████████▌ | 18/21 [03:07<00:26,  8.94s/it] 86%|████████▌ | 18/21 [02:52<00:26,  8.92s/it] 90%|█████████ | 19/21 [03:25<00:22, 11.44s/it] 90%|█████████ | 19/21 [03:24<00:22, 11.44s/it] 90%|█████████ | 19/21 [03:25<00:22, 11.44s/it] 90%|█████████ | 19/21 [03:24<00:22, 11.44s/it] 90%|█████████ | 19/21 [03:25<00:22, 11.44s/it] 90%|█████████ | 19/21 [03:25<00:22, 11.44s/it] 90%|█████████ | 19/21 [03:09<00:22, 11.44s/it] 90%|█████████ | 19/21 [03:09<00:22, 11.43s/it] 95%|█████████▌| 20/21 [03:44<00:13, 13.75s/it] 95%|█████████▌| 20/21 [03:44<00:13, 13.75s/it] 95%|█████████▌| 20/21 [03:44<00:13, 13.75s/it] 95%|█████████▌| 20/21 [03:43<00:13, 13.75s/it] 95%|█████████▌| 20/21 [03:44<00:13, 13.75s/it] 95%|█████████▌| 20/21 [03:44<00:13, 13.75s/it] 95%|█████████▌| 20/21 [03:28<00:13, 13.75s/it] 95%|█████████▌| 20/21 [03:29<00:13, 13.75s/it]100%|██████████| 21/21 [04:08<00:00, 17.17s/it]100%|██████████| 21/21 [04:09<00:00, 17.17s/it]100%|██████████| 21/21 [04:09<00:00, 17.17s/it]100%|██████████| 21/21 [04:09<00:00, 17.17s/it]100%|██████████| 21/21 [04:09<00:00, 17.17s/it]100%|██████████| 21/21 [03:54<00:00, 17.16s/it]100%|██████████| 21/21 [04:09<00:00, 17.17s/it]100%|██████████| 21/21 [03:53<00:00, 17.16s/it]22it [04:22, 15.86s/it]                        22it [04:06, 15.86s/it]                        22it [04:22, 15.86s/it]                        22it [04:22, 15.86s/it]                        22it [04:22, 15.86s/it]                        22it [04:21, 15.86s/it]                        22it [04:22, 15.86s/it]                        22it [04:06, 15.86s/it]                        23it [04:41, 16.89s/it]23it [04:41, 16.89s/it]23it [04:41, 16.89s/it]23it [04:41, 16.89s/it]23it [04:40, 16.89s/it]23it [04:41, 16.89s/it]23it [04:26, 16.89s/it]23it [04:25, 16.89s/it]24it [04:45, 13.07s/it]24it [04:45, 13.07s/it]24it [04:45, 13.07s/it]24it [04:45, 13.07s/it]24it [04:44, 13.07s/it]24it [04:45, 13.07s/it]24it [04:30, 13.06s/it]24it [04:29, 13.06s/it]25it [05:08, 15.95s/it]25it [05:08, 15.95s/it]25it [05:07, 15.95s/it]25it [05:08, 15.95s/it]25it [05:08, 15.95s/it]25it [04:52, 15.95s/it]25it [04:53, 15.95s/it]25it [05:08, 15.95s/it]26it [05:18, 14.12s/it]26it [05:18, 14.12s/it]26it [05:18, 14.12s/it]26it [05:18, 14.12s/it]26it [05:02, 14.12s/it]26it [05:18, 14.12s/it]26it [05:17, 14.12s/it]26it [05:02, 14.12s/it]27it [05:23, 11.47s/it]27it [05:23, 11.47s/it]27it [05:22, 11.47s/it]27it [05:23, 11.47s/it]27it [05:23, 11.47s/it]27it [05:08, 11.47s/it]27it [05:23, 11.47s/it]27it [05:07, 11.47s/it]28it [05:27,  9.22s/it]28it [05:27,  9.22s/it]28it [05:27,  9.22s/it]28it [05:27,  9.22s/it]28it [05:27,  9.22s/it]28it [05:26,  9.22s/it]28it [05:12,  9.22s/it]28it [05:11,  9.22s/it]29it [05:37,  9.43s/it]29it [05:37,  9.43s/it]29it [05:37,  9.43s/it]29it [05:36,  9.43s/it]29it [05:37,  9.43s/it]29it [05:22,  9.43s/it]29it [05:37,  9.43s/it]29it [05:21,  9.43s/it]30it [05:47,  9.63s/it]30it [05:47,  9.63s/it]30it [05:47,  9.63s/it]30it [05:46,  9.63s/it]30it [05:32,  9.63s/it]30it [05:47,  9.63s/it]30it [05:47,  9.63s/it]30it [05:31,  9.63s/it]31it [05:51,  7.90s/it]31it [05:51,  7.90s/it]31it [05:50,  7.90s/it]31it [05:51,  7.90s/it]31it [05:51,  7.90s/it]31it [05:51,  7.90s/it]31it [05:36,  7.90s/it]31it [05:35,  7.90s/it]32it [06:06,  9.91s/it]32it [06:05,  9.91s/it]32it [06:06,  9.91s/it]32it [05:50,  9.91s/it]32it [06:06,  9.91s/it]32it [06:05,  9.91s/it]32it [06:05,  9.91s/it]32it [05:50,  9.91s/it]33it [06:10,  8.20s/it]33it [06:10,  8.20s/it]33it [06:09,  8.20s/it]33it [06:10,  8.20s/it]33it [06:09,  8.20s/it]33it [05:54,  8.20s/it]33it [06:10,  8.20s/it]33it [05:54,  8.20s/it]34it [06:14,  6.98s/it]34it [06:14,  6.98s/it]34it [06:14,  6.98s/it]34it [06:14,  6.98s/it]34it [06:13,  6.98s/it]34it [06:14,  6.98s/it]34it [05:59,  6.98s/it]34it [05:58,  6.98s/it]35it [06:27,  8.84s/it]35it [06:26,  8.84s/it]35it [06:27,  8.84s/it]35it [06:27,  8.84s/it]35it [06:27,  8.84s/it]35it [06:27,  8.84s/it]35it [06:12,  8.84s/it]35it [06:11,  8.84s/it]36it [06:45, 11.59s/it]36it [06:45, 11.59s/it]36it [06:45, 11.59s/it]36it [06:44, 11.59s/it]36it [06:30, 11.59s/it]36it [06:45, 11.59s/it]36it [06:45, 11.59s/it]36it [06:29, 11.59s/it]37it [07:00, 12.45s/it]37it [07:00, 12.45s/it]37it [07:00, 12.45s/it]37it [06:59, 12.45s/it]37it [06:44, 12.45s/it]37it [06:59, 12.45s/it]37it [06:59, 12.45s/it]37it [06:44, 12.45s/it]38it [07:15, 13.41s/it]38it [07:15, 13.41s/it]38it [07:15, 13.41s/it]38it [07:14, 13.41s/it]38it [07:00, 13.41s/it]38it [07:15, 13.41s/it]38it [07:15, 13.41s/it]38it [06:59, 13.41s/it]39it [07:29, 13.57s/it]39it [07:28, 13.57s/it]39it [07:29, 13.57s/it]39it [07:29, 13.57s/it]39it [07:29, 13.57s/it]39it [07:29, 13.57s/it]39it [07:14, 13.57s/it]39it [07:13, 13.57s/it]40it [07:33, 10.64s/it]40it [07:33, 10.64s/it]40it [07:33, 10.64s/it]40it [07:33, 10.64s/it]40it [07:33, 10.64s/it]40it [07:32, 10.64s/it]40it [07:18, 10.64s/it]40it [07:17, 10.64s/it]41it [07:37,  8.62s/it]41it [07:37,  8.62s/it]41it [07:37,  8.62s/it]41it [07:37,  8.62s/it]41it [07:37,  8.62s/it]41it [07:36,  8.62s/it]41it [07:21,  8.62s/it]41it [07:37, 11.16s/it]41it [07:37, 11.16s/it]41it [07:21,  8.62s/it]

41it [07:37, 11.15s/it]41it [07:37, 11.15s/it]

41it [07:37, 11.15s/it]
41it [07:36, 11.13s/it]
41it [07:21, 10.78s/it]
41it [07:21, 10.77s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
