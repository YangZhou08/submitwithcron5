Already on 'addinggriffin'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:57, 19.23s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:01, 20.34s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:59, 19.99s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:59, 19.71s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:59, 19.84s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:00, 20.04s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:00, 20.08s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:00, 20.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:36, 18.46s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:38, 19.14s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:38, 19.00s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.88s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.93s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:38, 19.02s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:38, 19.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:52<00:17, 17.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.46s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.46s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.52s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.46s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.60s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:54<00:17, 17.54s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.84s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.82s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.90s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.91s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.25s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.91s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 11.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 14.01s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.91s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.41s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.92s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  1%|          | 1/153 [00:07<19:20,  7.63s/it]  1%|          | 1/153 [00:07<19:29,  7.69s/it]  1%|          | 1/153 [00:08<22:37,  8.93s/it]  1%|          | 1/153 [00:10<25:45, 10.17s/it]  1%|          | 1/153 [00:10<26:36, 10.50s/it]  1%|          | 1/153 [00:09<23:45,  9.38s/it]  1%|          | 1/153 [00:12<32:52, 12.98s/it]  1%|▏         | 2/153 [00:12<15:33,  6.18s/it]  1%|          | 1/153 [00:13<33:39, 13.29s/it]  1%|▏         | 2/153 [00:13<16:38,  6.61s/it]  1%|▏         | 2/153 [00:14<17:29,  6.95s/it]  1%|▏         | 2/153 [00:17<20:48,  8.27s/it]  2%|▏         | 3/153 [00:17<13:57,  5.58s/it]  1%|▏         | 2/153 [00:16<20:47,  8.26s/it]  1%|▏         | 2/153 [00:19<22:40,  9.01s/it]  2%|▏         | 3/153 [00:21<16:38,  6.66s/it]  2%|▏         | 3/153 [00:21<16:22,  6.55s/it]  2%|▏         | 3/153 [00:21<18:28,  7.39s/it]  1%|▏         | 2/153 [00:21<27:50, 11.06s/it]  2%|▏         | 3/153 [00:23<17:35,  7.03s/it]  2%|▏         | 3/153 [00:22<18:11,  7.28s/it]  1%|▏         | 2/153 [00:24<30:56, 12.29s/it]  3%|▎         | 4/153 [00:26<14:18,  5.76s/it]  3%|▎         | 4/153 [00:26<15:14,  6.13s/it]  3%|▎         | 4/153 [00:27<16:12,  6.53s/it]  3%|▎         | 4/153 [00:27<17:45,  7.15s/it]  2%|▏         | 3/153 [00:28<22:34,  9.03s/it]  3%|▎         | 5/153 [00:30<13:55,  5.64s/it]  3%|▎         | 4/153 [00:31<17:47,  7.16s/it]  3%|▎         | 5/153 [00:31<14:40,  5.95s/it]  3%|▎         | 4/153 [00:32<20:24,  8.22s/it]  3%|▎         | 5/153 [00:34<16:30,  6.69s/it]  3%|▎         | 5/153 [00:35<17:10,  6.96s/it]  3%|▎         | 5/153 [00:36<15:34,  6.32s/it]  4%|▍         | 6/153 [00:36<13:52,  5.67s/it]  4%|▍         | 6/153 [00:37<14:24,  5.88s/it]  3%|▎         | 5/153 [00:38<17:51,  7.24s/it]  4%|▍         | 6/153 [00:39<15:22,  6.27s/it]  3%|▎         | 4/153 [00:40<25:33, 10.29s/it]  4%|▍         | 6/153 [00:41<15:02,  6.14s/it]  4%|▍         | 6/153 [00:42<17:24,  7.11s/it]  2%|▏         | 3/153 [00:42<37:20, 14.94s/it]  5%|▍         | 7/153 [00:43<14:48,  6.09s/it]  5%|▍         | 7/153 [00:43<14:56,  6.14s/it]  5%|▌         | 8/153 [00:47<13:20,  5.52s/it]  4%|▍         | 6/153 [00:46<18:44,  7.65s/it]  5%|▍         | 7/153 [00:48<16:47,  6.90s/it]  5%|▌         | 8/153 [00:47<13:11,  5.46s/it]  5%|▍         | 7/153 [00:48<15:42,  6.45s/it]  5%|▍         | 7/153 [00:49<16:56,  6.97s/it]  3%|▎         | 5/153 [00:48<23:45,  9.63s/it]  5%|▌         | 8/153 [00:52<14:28,  5.99s/it]  5%|▍         | 7/153 [00:51<16:15,  6.68s/it]  6%|▌         | 9/153 [00:52<12:44,  5.31s/it]  6%|▌         | 9/153 [00:53<12:55,  5.39s/it]  5%|▌         | 8/153 [00:54<15:01,  6.22s/it]  5%|▌         | 8/153 [00:56<14:48,  6.13s/it]  3%|▎         | 4/153 [00:57<36:29, 14.69s/it]  6%|▌         | 9/153 [01:00<16:22,  6.82s/it]  6%|▌         | 9/153 [01:00<14:44,  6.15s/it]  7%|▋         | 10/153 [01:00<14:21,  6.02s/it]  7%|▋         | 10/153 [01:00<14:54,  6.25s/it]  5%|▌         | 8/153 [01:01<20:39,  8.55s/it]  6%|▌         | 9/153 [01:00<13:37,  5.68s/it]  4%|▍         | 6/153 [01:03<27:28, 11.22s/it]  7%|▋         | 11/153 [01:05<13:52,  5.86s/it]  7%|▋         | 10/153 [01:06<15:16,  6.41s/it]  7%|▋         | 11/153 [01:06<14:07,  5.97s/it]  7%|▋         | 10/153 [01:05<13:03,  5.48s/it]  7%|▋         | 10/153 [01:08<15:40,  6.58s/it]  3%|▎         | 5/153 [01:08<33:26, 13.56s/it]  6%|▌         | 9/153 [01:09<20:29,  8.53s/it]  7%|▋         | 11/153 [01:10<13:31,  5.72s/it]  8%|▊         | 12/153 [01:10<12:57,  5.51s/it]  5%|▍         | 7/153 [01:10<24:28, 10.06s/it]  8%|▊         | 12/153 [01:12<13:49,  5.89s/it]  7%|▋         | 11/153 [01:14<15:34,  6.58s/it]  7%|▋         | 11/153 [01:13<14:37,  6.18s/it]  8%|▊         | 13/153 [01:15<12:37,  5.41s/it]  8%|▊         | 12/153 [01:18<15:02,  6.40s/it]  7%|▋         | 10/153 [01:18<20:43,  8.69s/it]  4%|▍         | 6/153 [01:19<30:31, 12.46s/it]  8%|▊         | 13/153 [01:20<15:24,  6.61s/it]  8%|▊         | 12/153 [01:21<15:17,  6.51s/it]  9%|▉         | 14/153 [01:20<12:32,  5.42s/it]  8%|▊         | 12/153 [01:21<15:44,  6.70s/it]  8%|▊         | 13/153 [01:24<14:39,  6.28s/it]  8%|▊         | 13/153 [01:24<13:13,  5.67s/it]  5%|▌         | 8/153 [01:24<26:47, 11.09s/it] 10%|▉         | 15/153 [01:25<11:44,  5.10s/it]  7%|▋         | 11/153 [01:27<20:31,  8.67s/it]  9%|▉         | 14/153 [01:28<16:39,  7.19s/it]  8%|▊         | 13/153 [01:28<16:06,  6.91s/it]  5%|▍         | 7/153 [01:30<29:15, 12.02s/it] 10%|█         | 16/153 [01:31<12:30,  5.48s/it] 10%|▉         | 15/153 [01:32<13:47,  5.99s/it]  9%|▉         | 14/153 [01:32<16:03,  6.93s/it]  8%|▊         | 12/153 [01:34<19:09,  8.15s/it]  6%|▌         | 9/153 [01:34<25:47, 10.75s/it]  9%|▉         | 14/153 [01:34<14:50,  6.41s/it]  9%|▉         | 14/153 [01:36<17:03,  7.36s/it] 10%|█         | 16/153 [01:38<13:48,  6.05s/it] 10%|▉         | 15/153 [01:39<15:51,  6.89s/it]  5%|▌         | 8/153 [01:39<27:07, 11.23s/it] 11%|█         | 17/153 [01:40<14:50,  6.55s/it]  8%|▊         | 13/153 [01:41<18:20,  7.86s/it] 10%|▉         | 15/153 [01:42<16:02,  6.98s/it] 10%|▉         | 15/153 [01:41<15:22,  6.68s/it] 11%|█         | 17/153 [01:42<12:32,  5.53s/it]  7%|▋         | 10/153 [01:44<25:19, 10.63s/it] 10%|█         | 16/153 [01:46<15:51,  6.95s/it] 12%|█▏        | 18/153 [01:46<14:23,  6.40s/it] 10%|█         | 16/153 [01:47<14:26,  6.32s/it] 10%|█         | 16/153 [01:48<15:13,  6.66s/it]  9%|▉         | 14/153 [01:49<18:17,  7.90s/it] 12%|█▏        | 18/153 [01:49<13:17,  5.91s/it] 11%|█         | 17/153 [01:51<14:33,  6.42s/it]  6%|▌         | 9/153 [01:52<27:56, 11.64s/it] 12%|█▏        | 19/153 [01:53<11:39,  5.22s/it] 11%|█         | 17/153 [01:53<14:20,  6.33s/it] 12%|█▏        | 19/153 [01:53<14:49,  6.64s/it]  7%|▋         | 11/153 [01:54<24:48, 10.49s/it] 11%|█         | 17/153 [01:54<14:56,  6.59s/it] 10%|▉         | 15/153 [01:58<18:35,  8.09s/it] 13%|█▎        | 20/153 [01:58<11:37,  5.24s/it] 13%|█▎        | 20/153 [01:59<13:53,  6.27s/it] 12%|█▏        | 18/153 [02:00<15:38,  6.95s/it] 12%|█▏        | 18/153 [01:58<13:18,  5.91s/it] 12%|█▏        | 18/153 [02:00<14:41,  6.53s/it]  7%|▋         | 10/153 [02:00<25:28, 10.69s/it] 10%|█         | 16/153 [02:04<17:07,  7.50s/it] 12%|█▏        | 19/153 [02:04<13:01,  5.83s/it] 14%|█▎        | 21/153 [02:05<13:30,  6.14s/it] 14%|█▎        | 21/153 [02:05<12:47,  5.82s/it] 12%|█▏        | 19/153 [02:08<16:23,  7.34s/it] 11%|█         | 17/153 [02:09<15:37,  6.90s/it] 13%|█▎        | 20/153 [02:09<12:30,  5.64s/it] 12%|█▏        | 19/153 [02:08<15:49,  7.09s/it]  8%|▊         | 12/153 [02:09<27:49, 11.84s/it] 14%|█▍        | 22/153 [02:10<12:22,  5.67s/it] 13%|█▎        | 20/153 [02:11<13:38,  6.15s/it] 14%|█▍        | 22/153 [02:13<14:35,  6.68s/it] 14%|█▎        | 21/153 [02:13<11:11,  5.09s/it]  7%|▋         | 11/153 [02:14<27:26, 11.60s/it] 13%|█▎        | 20/153 [02:15<15:22,  6.94s/it]  8%|▊         | 13/153 [02:16<24:08, 10.34s/it] 14%|█▎        | 21/153 [02:18<14:10,  6.44s/it] 12%|█▏        | 18/153 [02:19<17:28,  7.76s/it] 15%|█▌        | 23/153 [02:19<14:03,  6.49s/it] 15%|█▌        | 23/153 [02:20<14:41,  6.78s/it] 16%|█▌        | 24/153 [02:22<11:36,  5.40s/it] 14%|█▍        | 22/153 [02:23<14:06,  6.46s/it]  8%|▊         | 12/153 [02:24<25:55, 11.03s/it] 14%|█▍        | 22/153 [02:25<14:12,  6.51s/it] 14%|█▎        | 21/153 [02:26<17:51,  8.12s/it] 16%|█▋        | 25/153 [02:27<11:39,  5.46s/it] 16%|█▌        | 24/153 [02:27<15:11,  7.06s/it] 12%|█▏        | 19/153 [02:28<18:16,  8.18s/it] 15%|█▌        | 23/153 [02:28<13:26,  6.21s/it]  9%|▉         | 14/153 [02:28<25:15, 10.90s/it] 15%|█▌        | 23/153 [02:32<14:35,  6.74s/it] 17%|█▋        | 26/153 [02:32<11:15,  5.32s/it] 14%|█▍        | 22/153 [02:32<16:27,  7.54s/it] 16%|█▋        | 25/153 [02:33<14:24,  6.75s/it]  8%|▊         | 13/153 [02:34<25:26, 10.90s/it] 13%|█▎        | 20/153 [02:35<17:21,  7.83s/it] 16%|█▌        | 24/153 [02:36<14:21,  6.68s/it] 18%|█▊        | 27/153 [02:38<11:46,  5.61s/it] 16%|█▋        | 25/153 [02:39<11:53,  5.58s/it] 16%|█▌        | 24/153 [02:40<14:46,  6.87s/it] 15%|█▌        | 23/153 [02:39<16:18,  7.53s/it] 17%|█▋        | 26/153 [02:41<14:35,  6.89s/it] 10%|▉         | 15/153 [02:41<26:33, 11.55s/it] 17%|█▋        | 26/153 [02:44<11:03,  5.22s/it] 18%|█▊        | 28/153 [02:44<11:42,  5.62s/it] 14%|█▎        | 21/153 [02:45<18:41,  8.50s/it] 18%|█▊        | 27/153 [02:47<14:03,  6.69s/it] 16%|█▋        | 25/153 [02:47<15:22,  7.20s/it]  9%|▉         | 14/153 [02:47<26:39, 11.51s/it] 16%|█▌        | 24/153 [02:47<16:32,  7.69s/it] 18%|█▊        | 27/153 [02:50<11:56,  5.68s/it] 19%|█▉        | 29/153 [02:51<12:16,  5.94s/it] 18%|█▊        | 28/153 [02:54<13:57,  6.70s/it] 10%|█         | 16/153 [02:53<26:51, 11.76s/it] 16%|█▋        | 25/153 [02:53<15:12,  7.13s/it] 17%|█▋        | 26/153 [02:55<15:14,  7.20s/it] 10%|▉         | 15/153 [02:56<24:26, 10.63s/it] 18%|█▊        | 28/153 [02:57<12:44,  6.12s/it] 19%|█▉        | 29/153 [02:57<11:59,  5.80s/it] 20%|█▉        | 30/153 [02:58<13:01,  6.36s/it] 17%|█▋        | 26/153 [02:59<14:15,  6.74s/it] 14%|█▍        | 22/153 [03:01<23:06, 10.59s/it] 19%|█▉        | 29/153 [03:02<11:47,  5.71s/it] 18%|█▊        | 27/153 [03:02<15:26,  7.35s/it] 20%|█▉        | 30/153 [03:03<11:33,  5.64s/it] 11%|█         | 17/153 [03:05<26:26, 11.66s/it] 10%|█         | 16/153 [03:06<24:13, 10.61s/it] 20%|██        | 31/153 [03:07<14:28,  7.12s/it] 20%|██        | 31/153 [03:08<11:04,  5.44s/it] 15%|█▌        | 23/153 [03:09<21:13,  9.80s/it] 20%|█▉        | 30/153 [03:09<12:04,  5.89s/it] 18%|█▊        | 27/153 [03:10<16:35,  7.90s/it] 18%|█▊        | 28/153 [03:12<16:51,  8.09s/it] 21%|██        | 32/153 [03:13<13:59,  6.94s/it] 20%|██        | 31/153 [03:15<12:15,  6.03s/it] 21%|██        | 32/153 [03:15<12:23,  6.14s/it] 18%|█▊        | 28/153 [03:15<14:57,  7.18s/it] 11%|█         | 17/153 [03:17<23:49, 10.51s/it] 16%|█▌        | 24/153 [03:18<20:44,  9.64s/it] 19%|█▉        | 29/153 [03:19<15:56,  7.72s/it] 21%|██        | 32/153 [03:20<11:28,  5.69s/it] 22%|██▏       | 33/153 [03:20<13:51,  6.93s/it] 22%|██▏       | 33/153 [03:22<12:46,  6.38s/it] 12%|█▏        | 18/153 [03:22<29:59, 13.33s/it] 20%|█▉        | 30/153 [03:24<13:54,  6.78s/it] 19%|█▉        | 29/153 [03:22<14:50,  7.18s/it] 16%|█▋        | 25/153 [03:27<20:01,  9.39s/it] 22%|██▏       | 34/153 [03:26<11:22,  5.74s/it] 12%|█▏        | 18/153 [03:27<23:45, 10.56s/it] 22%|██▏       | 33/153 [03:28<12:41,  6.34s/it] 20%|█▉        | 30/153 [03:27<12:58,  6.33s/it] 22%|██▏       | 34/153 [03:28<14:07,  7.12s/it] 20%|██        | 31/153 [03:31<14:19,  7.04s/it] 22%|██▏       | 34/153 [03:32<11:35,  5.84s/it] 12%|█▏        | 19/153 [03:32<27:28, 12.30s/it] 23%|██▎       | 35/153 [03:33<12:39,  6.44s/it] 23%|██▎       | 35/153 [03:33<11:54,  6.05s/it] 17%|█▋        | 26/153 [03:34<18:25,  8.70s/it] 20%|██        | 31/153 [03:33<13:01,  6.41s/it] 23%|██▎       | 35/153 [03:38<11:14,  5.71s/it] 24%|██▎       | 36/153 [03:38<11:58,  6.14s/it] 21%|██        | 32/153 [03:39<14:39,  7.27s/it] 12%|█▏        | 19/153 [03:39<24:25, 10.93s/it] 24%|██▎       | 36/153 [03:40<12:01,  6.16s/it] 18%|█▊        | 27/153 [03:42<17:58,  8.56s/it] 24%|██▎       | 36/153 [03:42<10:27,  5.36s/it] 21%|██        | 32/153 [03:41<13:55,  6.90s/it] 22%|██▏       | 33/153 [03:45<13:46,  6.88s/it] 13%|█▎        | 20/153 [03:44<27:20, 12.33s/it] 24%|██▍       | 37/153 [03:46<12:57,  6.70s/it] 18%|█▊        | 28/153 [03:47<15:25,  7.41s/it] 24%|██▍       | 37/153 [03:47<12:33,  6.50s/it] 22%|██▏       | 33/153 [03:47<13:11,  6.59s/it] 19%|█▉        | 29/153 [03:50<12:41,  6.14s/it] 14%|█▎        | 21/153 [03:50<22:53, 10.41s/it] 24%|██▍       | 37/153 [03:51<12:27,  6.44s/it] 22%|██▏       | 34/153 [03:52<13:40,  6.89s/it] 25%|██▍       | 38/153 [03:52<12:10,  6.35s/it] 13%|█▎        | 20/153 [03:54<26:30, 11.96s/it] 25%|██▍       | 38/153 [03:54<12:48,  6.68s/it] 22%|██▏       | 34/153 [03:55<13:51,  6.99s/it] 25%|██▍       | 38/153 [03:56<11:35,  6.05s/it] 20%|█▉        | 30/153 [03:57<13:02,  6.36s/it] 23%|██▎       | 35/153 [03:57<12:37,  6.42s/it] 25%|██▌       | 39/153 [03:59<12:22,  6.51s/it] 25%|██▌       | 39/153 [04:00<12:01,  6.33s/it] 25%|██▌       | 39/153 [04:01<10:52,  5.73s/it] 14%|█▍        | 22/153 [04:01<22:40, 10.39s/it] 23%|██▎       | 35/153 [04:01<13:12,  6.72s/it] 14%|█▎        | 21/153 [04:03<24:51, 11.30s/it] 20%|██        | 31/153 [04:05<14:10,  6.97s/it] 24%|██▎       | 36/153 [04:06<13:37,  6.99s/it] 26%|██▌       | 40/153 [04:07<13:16,  7.05s/it] 26%|██▌       | 40/153 [04:07<12:40,  6.73s/it] 26%|██▌       | 40/153 [04:09<11:39,  6.19s/it] 24%|██▍       | 37/153 [04:11<12:24,  6.42s/it] 24%|██▎       | 36/153 [04:10<14:07,  7.24s/it] 15%|█▌        | 23/153 [04:10<21:52, 10.09s/it] 27%|██▋       | 41/153 [04:13<10:40,  5.71s/it] 27%|██▋       | 41/153 [04:13<12:03,  6.46s/it] 27%|██▋       | 41/153 [04:13<12:46,  6.85s/it] 14%|█▍        | 22/153 [04:14<24:22, 11.16s/it] 21%|██        | 32/153 [04:15<15:42,  7.79s/it] 25%|██▍       | 38/153 [04:17<11:59,  6.25s/it] 24%|██▍       | 37/153 [04:16<13:27,  6.97s/it] 27%|██▋       | 42/153 [04:18<11:19,  6.12s/it] 27%|██▋       | 42/153 [04:20<11:22,  6.14s/it] 27%|██▋       | 42/153 [04:20<12:46,  6.90s/it] 25%|██▍       | 38/153 [04:20<11:44,  6.13s/it] 16%|█▌        | 24/153 [04:21<22:10, 10.31s/it] 25%|██▌       | 39/153 [04:24<12:22,  6.52s/it] 28%|██▊       | 43/153 [04:24<09:56,  5.42s/it] 28%|██▊       | 43/153 [04:24<10:48,  5.89s/it] 22%|██▏       | 33/153 [04:25<16:40,  8.34s/it] 28%|██▊       | 43/153 [04:25<11:24,  6.23s/it] 15%|█▌        | 23/153 [04:26<24:38, 11.38s/it] 29%|██▉       | 44/153 [04:28<08:54,  4.91s/it] 25%|██▌       | 39/153 [04:27<11:53,  6.26s/it] 26%|██▌       | 40/153 [04:30<12:09,  6.46s/it] 29%|██▉       | 44/153 [04:30<10:45,  5.92s/it] 16%|█▋        | 25/153 [04:31<21:47, 10.22s/it] 29%|██▉       | 45/153 [04:33<08:46,  4.88s/it] 22%|██▏       | 34/153 [04:34<17:01,  8.58s/it] 29%|██▉       | 44/153 [04:33<12:30,  6.88s/it] 26%|██▌       | 40/153 [04:33<11:54,  6.32s/it] 27%|██▋       | 41/153 [04:35<11:16,  6.04s/it] 16%|█▌        | 24/153 [04:37<24:10, 11.24s/it] 30%|███       | 46/153 [04:38<08:49,  4.95s/it] 27%|██▋       | 41/153 [04:37<10:09,  5.44s/it] 29%|██▉       | 45/153 [04:38<11:47,  6.55s/it] 27%|██▋       | 42/153 [04:38<09:35,  5.18s/it] 29%|██▉       | 45/153 [04:40<12:09,  6.75s/it] 17%|█▋        | 26/153 [04:40<20:46,  9.81s/it] 23%|██▎       | 35/153 [04:41<16:21,  8.31s/it] 28%|██▊       | 43/153 [04:44<09:34,  5.23s/it] 31%|███       | 47/153 [04:44<09:15,  5.24s/it] 27%|██▋       | 42/153 [04:43<10:19,  5.58s/it] 30%|███       | 46/153 [04:45<12:01,  6.75s/it] 16%|█▋        | 25/153 [04:47<23:05, 10.82s/it] 31%|███       | 47/153 [04:48<09:47,  5.54s/it] 29%|██▉       | 44/153 [04:48<09:12,  5.07s/it] 31%|███▏      | 48/153 [04:48<08:53,  5.08s/it] 30%|███       | 46/153 [04:48<12:48,  7.18s/it] 24%|██▎       | 36/153 [04:49<16:01,  8.22s/it] 28%|██▊       | 43/153 [04:49<10:37,  5.79s/it]