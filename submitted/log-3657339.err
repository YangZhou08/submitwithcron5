Already on 'yangexppp'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-08-03:08:41:33,169 INFO     [main.py:288] Verbosity set to INFO
2024-08-03:08:41:42,529 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-08-03:08:41:42,562 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-08-03:08:41:42,562 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-70B-Instruct', 'cats': True, 'check': False, 'contextlength': 1500, 'kernel_size': 16, 'thr': 0.05}
2024-08-03:08:41:42,572 INFO     [xhuggingface.py:176] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:05<02:38,  5.45s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:11<02:35,  5.54s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:16<02:32,  5.66s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:22<02:26,  5.62s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:27<02:17,  5.50s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:32<02:09,  5.41s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:38<02:03,  5.36s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:43<01:59,  5.43s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:49<01:54,  5.47s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:54<01:48,  5.41s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [00:59<01:41,  5.36s/it]Loading checkpoint shards:  40%|████      | 12/30 [01:05<01:36,  5.35s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [01:10<01:32,  5.41s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [01:16<01:27,  5.45s/it]Loading checkpoint shards:  50%|█████     | 15/30 [01:21<01:20,  5.38s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [01:26<01:14,  5.33s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [01:31<01:09,  5.31s/it]Loading checkpoint shards:  60%|██████    | 18/30 [01:37<01:04,  5.40s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [01:43<00:59,  5.43s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [01:48<00:53,  5.35s/it]Loading checkpoint shards:  70%|███████   | 21/30 [01:53<00:47,  5.32s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [01:58<00:42,  5.29s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [02:04<00:37,  5.39s/it]Loading checkpoint shards:  80%|████████  | 24/30 [02:09<00:32,  5.44s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [02:15<00:26,  5.36s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [02:20<00:21,  5.31s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [02:25<00:15,  5.27s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [02:31<00:10,  5.37s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [02:36<00:05,  5.42s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:39<00:00,  4.53s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:39<00:00,  5.30s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-08-03:08:50:51,177 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-03:08:50:51,177 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-03:08:50:51,260 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 0...
  0%|          | 0/1319 [00:00<?, ?it/s] 13%|█▎        | 169/1319 [00:00<00:00, 1688.27it/s] 26%|██▌       | 339/1319 [00:00<00:00, 1694.69it/s] 39%|███▊      | 509/1319 [00:00<00:00, 1695.31it/s] 51%|█████▏    | 679/1319 [00:00<00:00, 1694.71it/s] 64%|██████▍   | 849/1319 [00:00<00:00, 1693.41it/s] 77%|███████▋  | 1019/1319 [00:00<00:00, 1693.11it/s] 90%|█████████ | 1190/1319 [00:00<00:00, 1695.46it/s]100%|██████████| 1319/1319 [00:00<00:00, 1695.09it/s]
2024-08-03:08:50:52,064 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 1/1319 [00:44<16:23:31, 44.77s/it]Running generate_until requests:   0%|          | 2/1319 [01:25<15:34:50, 42.59s/it]Running generate_until requests:   0%|          | 3/1319 [02:00<14:15:50, 39.02s/it]Running generate_until requests:   0%|          | 4/1319 [02:39<14:10:33, 38.81s/it]Running generate_until requests:   0%|          | 5/1319 [03:40<17:07:39, 46.92s/it]Running generate_until requests:   0%|          | 6/1319 [04:18<15:57:39, 43.76s/it]Running generate_until requests:   1%|          | 7/1319 [04:53<14:54:56, 40.93s/it]Running generate_until requests:   1%|          | 8/1319 [05:35<15:03:25, 41.35s/it]Running generate_until requests:   1%|          | 9/1319 [06:08<14:08:03, 38.84s/it]Running generate_until requests:   1%|          | 10/1319 [06:53<14:49:05, 40.75s/it]Running generate_until requests:   1%|          | 11/1319 [07:31<14:31:23, 39.97s/it]Running generate_until requests:   1%|          | 12/1319 [08:21<15:36:46, 43.00s/it]Running generate_until requests:   1%|          | 13/1319 [08:57<14:46:35, 40.73s/it]