wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.07s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.02s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.62s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.15s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.92s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.04s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.03s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.12s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.31s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.61s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.26s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.31s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.32s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.38s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.34s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [01:23<27:46, 83.33s/it]  5%|▍         | 1/21 [01:24<28:03, 84.19s/it]  5%|▍         | 1/21 [01:24<28:02, 84.11s/it]  5%|▍         | 1/21 [01:24<28:00, 84.03s/it]  5%|▍         | 1/21 [01:23<27:57, 83.87s/it]  5%|▍         | 1/21 [01:24<28:00, 84.04s/it]  5%|▍         | 1/21 [01:02<20:50, 62.52s/it]  5%|▍         | 1/21 [01:01<20:34, 61.73s/it] 10%|▉         | 2/21 [02:22<21:56, 69.27s/it] 10%|▉         | 2/21 [02:23<22:02, 69.62s/it] 10%|▉         | 2/21 [02:01<19:13, 60.70s/it] 10%|▉         | 2/21 [02:23<22:01, 69.56s/it] 10%|▉         | 2/21 [02:23<22:01, 69.56s/it] 10%|▉         | 2/21 [02:23<22:00, 69.49s/it] 10%|▉         | 2/21 [02:23<22:02, 69.59s/it] 10%|▉         | 2/21 [02:01<19:07, 60.37s/it] 14%|█▍        | 3/21 [03:28<20:13, 67.41s/it] 14%|█▍        | 3/21 [03:27<20:09, 67.22s/it] 14%|█▍        | 3/21 [03:28<20:12, 67.38s/it] 14%|█▍        | 3/21 [03:28<20:13, 67.39s/it] 14%|█▍        | 3/21 [03:28<20:12, 67.34s/it] 14%|█▍        | 3/21 [03:28<20:12, 67.38s/it] 14%|█▍        | 3/21 [03:06<18:46, 62.56s/it] 14%|█▍        | 3/21 [03:05<18:42, 62.39s/it] 19%|█▉        | 4/21 [04:22<17:40, 62.37s/it] 19%|█▉        | 4/21 [04:22<17:40, 62.39s/it] 19%|█▉        | 4/21 [04:22<17:38, 62.29s/it] 19%|█▉        | 4/21 [04:23<17:40, 62.40s/it] 19%|█▉        | 4/21 [04:23<17:40, 62.41s/it] 19%|█▉        | 4/21 [04:22<17:40, 62.39s/it] 19%|█▉        | 4/21 [04:01<16:51, 59.47s/it] 19%|█▉        | 4/21 [04:00<16:49, 59.37s/it] 24%|██▍       | 5/21 [05:09<15:04, 56.53s/it] 24%|██▍       | 5/21 [05:09<15:04, 56.52s/it] 24%|██▍       | 5/21 [05:08<15:04, 56.51s/it] 24%|██▍       | 5/21 [05:09<15:04, 56.53s/it] 24%|██▍       | 5/21 [05:08<15:03, 56.46s/it] 24%|██▍       | 5/21 [05:09<15:04, 56.52s/it] 24%|██▍       | 5/21 [04:47<14:34, 54.66s/it] 24%|██▍       | 5/21 [04:46<14:33, 54.59s/it] 29%|██▊       | 6/21 [06:14<14:52, 59.52s/it] 29%|██▊       | 6/21 [06:14<14:52, 59.53s/it] 29%|██▊       | 6/21 [06:13<14:52, 59.49s/it] 29%|██▊       | 6/21 [05:52<14:34, 58.30s/it] 29%|██▊       | 6/21 [06:14<14:53, 59.54s/it] 29%|██▊       | 6/21 [06:14<14:52, 59.53s/it] 29%|██▊       | 6/21 [06:14<14:52, 59.53s/it] 29%|██▊       | 6/21 [05:52<14:33, 58.25s/it] 33%|███▎      | 7/21 [07:10<13:40, 58.57s/it] 33%|███▎      | 7/21 [07:11<13:40, 58.60s/it] 33%|███▎      | 7/21 [07:11<13:40, 58.60s/it] 33%|███▎      | 7/21 [06:49<13:28, 57.77s/it] 33%|███▎      | 7/21 [07:11<13:40, 58.60s/it] 33%|███▎      | 7/21 [07:10<13:40, 58.59s/it] 33%|███▎      | 7/21 [07:11<13:40, 58.61s/it] 33%|███▎      | 7/21 [06:48<13:28, 57.74s/it] 38%|███▊      | 8/21 [08:00<12:07, 55.98s/it] 38%|███▊      | 8/21 [08:01<12:08, 56.00s/it] 38%|███▊      | 8/21 [08:01<12:08, 56.00s/it] 38%|███▊      | 8/21 [08:01<12:08, 56.00s/it] 38%|███▊      | 8/21 [08:01<12:08, 56.01s/it] 38%|███▊      | 8/21 [07:39<12:00, 55.42s/it] 38%|███▊      | 8/21 [08:01<12:07, 56.00s/it] 38%|███▊      | 8/21 [07:40<12:00, 55.44s/it] 43%|████▎     | 9/21 [08:47<10:32, 52.74s/it] 43%|████▎     | 9/21 [08:47<10:32, 52.75s/it] 43%|████▎     | 9/21 [08:47<10:32, 52.75s/it] 43%|████▎     | 9/21 [08:46<10:32, 52.73s/it] 43%|████▎     | 9/21 [08:47<10:32, 52.75s/it] 43%|████▎     | 9/21 [08:47<10:32, 52.75s/it] 43%|████▎     | 9/21 [08:25<10:28, 52.36s/it] 43%|████▎     | 9/21 [08:24<10:28, 52.34s/it] 48%|████▊     | 10/21 [09:28<09:02, 49.29s/it] 48%|████▊     | 10/21 [09:28<09:02, 49.30s/it] 48%|████▊     | 10/21 [09:28<09:02, 49.30s/it] 48%|████▊     | 10/21 [09:28<09:02, 49.30s/it] 48%|████▊     | 10/21 [09:28<09:02, 49.30s/it] 48%|████▊     | 10/21 [09:28<09:02, 49.30s/it] 48%|████▊     | 10/21 [09:07<08:59, 49.03s/it] 48%|████▊     | 10/21 [09:06<08:59, 49.02s/it] 52%|█████▏    | 11/21 [10:09<07:45, 46.51s/it] 52%|█████▏    | 11/21 [10:08<07:45, 46.51s/it] 52%|█████▏    | 11/21 [10:08<07:45, 46.51s/it] 52%|█████▏    | 11/21 [10:08<07:45, 46.50s/it] 52%|█████▏    | 11/21 [10:09<07:45, 46.51s/it] 52%|█████▏    | 11/21 [10:08<07:45, 46.51s/it] 52%|█████▏    | 11/21 [09:46<07:43, 46.32s/it] 52%|█████▏    | 11/21 [09:47<07:43, 46.32s/it] 57%|█████▋    | 12/21 [11:07<07:31, 50.17s/it] 57%|█████▋    | 12/21 [11:07<07:31, 50.17s/it] 57%|█████▋    | 12/21 [11:06<07:31, 50.17s/it] 57%|█████▋    | 12/21 [11:07<07:31, 50.17s/it] 57%|█████▋    | 12/21 [11:07<07:31, 50.17s/it] 57%|█████▋    | 12/21 [11:07<07:31, 50.17s/it] 57%|█████▋    | 12/21 [10:45<07:30, 50.04s/it] 57%|█████▋    | 12/21 [10:45<07:30, 50.04s/it] 62%|██████▏   | 13/21 [12:08<07:08, 53.59s/it] 62%|██████▏   | 13/21 [12:08<07:08, 53.58s/it] 62%|██████▏   | 13/21 [12:09<07:08, 53.59s/it] 62%|██████▏   | 13/21 [12:08<07:08, 53.59s/it] 62%|██████▏   | 13/21 [12:08<07:08, 53.59s/it] 62%|██████▏   | 13/21 [12:09<07:08, 53.59s/it] 62%|██████▏   | 13/21 [11:46<07:07, 53.49s/it] 62%|██████▏   | 13/21 [11:47<07:07, 53.50s/it] 67%|██████▋   | 14/21 [13:08<06:28, 55.48s/it] 67%|██████▋   | 14/21 [13:08<06:28, 55.48s/it] 67%|██████▋   | 14/21 [13:08<06:28, 55.48s/it] 67%|██████▋   | 14/21 [13:08<06:28, 55.48s/it] 67%|██████▋   | 14/21 [13:08<06:28, 55.48s/it] 67%|██████▋   | 14/21 [13:08<06:28, 55.48s/it] 67%|██████▋   | 14/21 [12:47<06:27, 55.41s/it] 67%|██████▋   | 14/21 [12:46<06:27, 55.41s/it] 71%|███████▏  | 15/21 [13:59<05:24, 54.08s/it] 71%|███████▏  | 15/21 [13:59<05:24, 54.08s/it] 71%|███████▏  | 15/21 [13:58<05:24, 54.08s/it] 71%|███████▏  | 15/21 [13:59<05:24, 54.08s/it] 71%|███████▏  | 15/21 [13:59<05:24, 54.08s/it] 71%|███████▏  | 15/21 [13:59<05:24, 54.08s/it] 71%|███████▏  | 15/21 [13:38<05:24, 54.03s/it] 71%|███████▏  | 15/21 [13:37<05:24, 54.03s/it] 76%|███████▌  | 16/21 [14:40<04:10, 50.03s/it] 76%|███████▌  | 16/21 [14:40<04:10, 50.03s/it] 76%|███████▌  | 16/21 [14:40<04:10, 50.03s/it] 76%|███████▌  | 16/21 [14:39<04:10, 50.03s/it] 76%|███████▌  | 16/21 [14:40<04:10, 50.03s/it] 76%|███████▌  | 16/21 [14:40<04:10, 50.03s/it] 76%|███████▌  | 16/21 [14:17<04:09, 49.99s/it] 76%|███████▌  | 16/21 [14:18<04:09, 50.00s/it] 81%|████████  | 17/21 [15:15<03:02, 45.69s/it] 81%|████████  | 17/21 [15:15<03:02, 45.68s/it] 81%|████████  | 17/21 [15:15<03:02, 45.69s/it] 81%|████████  | 17/21 [15:15<03:02, 45.69s/it] 81%|████████  | 17/21 [15:15<03:02, 45.69s/it] 81%|████████  | 17/21 [15:15<03:02, 45.69s/it] 81%|████████  | 17/21 [14:53<03:02, 45.66s/it] 81%|████████  | 17/21 [14:54<03:02, 45.66s/it] 86%|████████▌ | 18/21 [15:58<02:14, 44.79s/it] 86%|████████▌ | 18/21 [15:58<02:14, 44.79s/it] 86%|████████▌ | 18/21 [15:58<02:14, 44.79s/it] 86%|████████▌ | 18/21 [15:57<02:14, 44.79s/it] 86%|████████▌ | 18/21 [15:58<02:14, 44.79s/it] 86%|████████▌ | 18/21 [15:58<02:14, 44.79s/it] 86%|████████▌ | 18/21 [15:36<02:14, 44.77s/it] 86%|████████▌ | 18/21 [15:37<02:14, 44.77s/it] 90%|█████████ | 19/21 [16:42<01:29, 44.67s/it] 90%|█████████ | 19/21 [16:43<01:29, 44.67s/it] 90%|█████████ | 19/21 [16:42<01:29, 44.67s/it] 90%|█████████ | 19/21 [16:42<01:29, 44.67s/it] 90%|█████████ | 19/21 [16:42<01:29, 44.67s/it] 90%|█████████ | 19/21 [16:42<01:29, 44.67s/it] 90%|█████████ | 19/21 [16:21<01:29, 44.66s/it] 90%|█████████ | 19/21 [16:20<01:29, 44.66s/it] 95%|█████████▌| 20/21 [17:27<00:44, 44.65s/it] 95%|█████████▌| 20/21 [17:26<00:44, 44.65s/it] 95%|█████████▌| 20/21 [17:27<00:44, 44.65s/it] 95%|█████████▌| 20/21 [17:27<00:44, 44.65s/it] 95%|█████████▌| 20/21 [17:27<00:44, 44.65s/it] 95%|█████████▌| 20/21 [17:27<00:44, 44.65s/it] 95%|█████████▌| 20/21 [17:05<00:44, 44.64s/it] 95%|█████████▌| 20/21 [17:06<00:44, 44.64s/it]100%|██████████| 21/21 [18:29<00:00, 49.88s/it]100%|██████████| 21/21 [18:08<00:00, 49.87s/it]100%|██████████| 21/21 [18:29<00:00, 49.88s/it]100%|██████████| 21/21 [18:28<00:00, 49.88s/it]100%|██████████| 21/21 [18:29<00:00, 49.88s/it]100%|██████████| 21/21 [18:29<00:00, 49.88s/it]100%|██████████| 21/21 [18:29<00:00, 49.88s/it]100%|██████████| 21/21 [18:07<00:00, 49.87s/it]22it [19:22, 51.03s/it]                        22it [19:23, 51.03s/it]                        22it [19:23, 51.03s/it]                        22it [19:23, 51.03s/it]                        22it [19:23, 51.03s/it]                        22it [19:23, 51.03s/it]                        22it [19:01, 51.03s/it]                        22it [19:01, 51.03s/it]                        23it [20:02, 47.39s/it]23it [20:02, 47.39s/it]23it [20:01, 47.39s/it]23it [20:02, 47.39s/it]23it [20:02, 47.39s/it]23it [20:02, 47.39s/it]23it [19:40, 47.39s/it]23it [19:39, 47.39s/it]24it [20:37, 44.05s/it]24it [20:38, 44.05s/it]24it [20:38, 44.05s/it]24it [20:38, 44.05s/it]24it [20:38, 44.05s/it]24it [20:38, 44.05s/it]24it [20:16, 44.04s/it]24it [20:16, 44.04s/it]25it [21:37, 48.68s/it]25it [21:37, 48.68s/it]25it [21:37, 48.68s/it]25it [21:38, 48.68s/it]25it [21:37, 48.68s/it]25it [21:38, 48.68s/it]25it [21:15, 48.68s/it]25it [21:16, 48.68s/it]26it [22:17, 45.98s/it]26it [22:17, 45.98s/it]26it [22:16, 45.98s/it]26it [22:17, 45.98s/it]26it [22:17, 45.98s/it]26it [22:17, 45.98s/it]26it [21:56, 45.98s/it]26it [21:55, 45.98s/it]27it [22:50, 42.01s/it]27it [22:50, 42.01s/it]27it [22:49, 42.01s/it]27it [22:50, 42.01s/it]27it [22:28, 42.01s/it]27it [22:50, 42.01s/it]27it [22:50, 42.01s/it]27it [22:28, 42.01s/it]28it [23:33, 42.38s/it]28it [23:32, 42.38s/it]28it [23:33, 42.38s/it]28it [23:33, 42.38s/it]28it [23:33, 42.38s/it]28it [23:33, 42.38s/it]28it [23:12, 42.38s/it]28it [23:11, 42.38s/it]29it [24:11, 40.89s/it]29it [24:11, 40.89s/it]29it [24:10, 40.89s/it]29it [24:10, 40.89s/it]29it [24:11, 40.89s/it]29it [24:11, 40.89s/it]29it [23:48, 40.89s/it]29it [23:49, 40.89s/it]30it [24:49, 40.12s/it]30it [24:48, 40.12s/it]30it [24:49, 40.12s/it]30it [24:49, 40.12s/it]30it [24:49, 40.12s/it]30it [24:49, 40.12s/it]30it [24:27, 40.12s/it]30it [24:27, 40.12s/it]31it [25:30, 40.53s/it]31it [25:30, 40.53s/it]31it [25:30, 40.53s/it]31it [25:30, 40.53s/it]31it [25:30, 40.53s/it]31it [25:30, 40.53s/it]31it [25:08, 40.53s/it]31it [25:09, 40.53s/it]32it [26:08, 39.82s/it]32it [26:09, 39.82s/it]32it [26:08, 39.82s/it]32it [26:09, 39.82s/it]32it [26:09, 39.82s/it]32it [26:08, 39.82s/it]32it [25:46, 39.82s/it]32it [25:47, 39.82s/it]33it [26:48, 39.63s/it]33it [26:48, 39.63s/it]33it [26:47, 39.63s/it]33it [26:48, 39.63s/it]33it [26:48, 39.63s/it]33it [26:48, 39.63s/it]33it [26:26, 39.63s/it]33it [26:25, 39.63s/it]34it [27:35, 42.20s/it]34it [27:36, 42.20s/it]34it [27:36, 42.20s/it]34it [27:36, 42.20s/it]34it [27:36, 42.20s/it]34it [27:36, 42.20s/it]34it [27:14, 42.20s/it]34it [27:14, 42.20s/it]35it [28:26, 44.50s/it]35it [28:26, 44.50s/it]35it [28:26, 44.50s/it]35it [28:25, 44.50s/it]35it [28:26, 44.50s/it]35it [28:26, 44.50s/it]35it [28:04, 44.50s/it]35it [28:03, 44.50s/it]36it [29:12, 45.24s/it]36it [29:13, 45.24s/it]36it [29:13, 45.24s/it]36it [28:51, 45.24s/it]36it [29:13, 45.24s/it]36it [29:13, 45.24s/it]36it [29:13, 45.24s/it]36it [28:50, 45.24s/it]37it [29:56, 44.66s/it]37it [29:56, 44.66s/it]37it [29:56, 44.66s/it]37it [29:56, 44.66s/it]37it [29:55, 44.66s/it]37it [29:56, 44.66s/it]37it [29:34, 44.66s/it]37it [29:34, 44.66s/it]38it [30:36, 43.57s/it]38it [30:37, 43.57s/it]38it [30:37, 43.57s/it]38it [30:37, 43.57s/it]38it [30:37, 43.57s/it]38it [30:37, 43.57s/it]38it [30:16, 43.57s/it]38it [30:15, 43.57s/it]39it [31:25, 44.76s/it]39it [31:25, 44.76s/it]39it [31:24, 44.76s/it]39it [31:25, 44.76s/it]39it [31:25, 44.76s/it]39it [31:24, 44.76s/it]39it [31:03, 44.76s/it]39it [31:02, 44.76s/it]40it [32:14, 46.00s/it]40it [32:13, 46.00s/it]40it [32:13, 46.00s/it]40it [32:14, 46.00s/it]40it [32:14, 46.00s/it]40it [32:13, 46.00s/it]40it [31:51, 46.00s/it]40it [31:52, 46.00s/it]41it [33:01, 46.43s/it]41it [33:01, 46.43s/it]41it [33:01, 46.43s/it]41it [32:39, 46.43s/it]41it [33:01, 46.43s/it]41it [33:01, 46.43s/it]41it [33:00, 46.43s/it]41it [33:01, 48.33s/it]
41it [33:01, 48.33s/it]
41it [33:01, 48.33s/it]
41it [33:01, 48.32s/it]41it [32:39, 47.80s/it]41it [33:01, 48.33s/it]

41it [33:00, 48.31s/it]

41it [32:39, 46.43s/it]41it [32:39, 47.78s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
