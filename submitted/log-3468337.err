Already on 'yangexp2threee'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-07-22:07:16:09,681 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:16:19,262 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:16:19,263 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:16:19,286 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:16:19,286 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 128}
2024-07-22:07:16:19,295 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:18,  6.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:12<00:12,  6.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:17<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.84s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:16:41,333 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.96it/s] 10%|▉         | 39/396 [00:00<00:01, 190.57it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.34it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.27it/s] 25%|██▌       | 99/396 [00:00<00:01, 191.87it/s] 30%|███       | 119/396 [00:00<00:01, 192.24it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.41it/s] 40%|████      | 159/396 [00:00<00:01, 192.44it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.34it/s] 50%|█████     | 199/396 [00:01<00:01, 192.24it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.29it/s] 60%|██████    | 239/396 [00:01<00:00, 192.02it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.78it/s] 70%|███████   | 279/396 [00:01<00:00, 191.30it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.56it/s] 81%|████████  | 319/396 [00:01<00:00, 191.70it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.83it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.88it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.91it/s]100%|██████████| 396/396 [00:02<00:00, 191.81it/s]
2024-07-22:07:16:43,428 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:07:17:13,980 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:17:21,235 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:17:21,236 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:17:21,242 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:17:21,242 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 128}
2024-07-22:07:17:21,251 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.59s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.70s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:18:13,218 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 187.06it/s] 10%|▉         | 38/396 [00:00<00:01, 187.94it/s] 15%|█▍        | 58/396 [00:00<00:01, 188.99it/s] 20%|█▉        | 78/396 [00:00<00:01, 190.06it/s] 25%|██▍       | 98/396 [00:00<00:01, 190.66it/s] 30%|██▉       | 118/396 [00:00<00:01, 187.35it/s] 35%|███▍      | 138/396 [00:00<00:01, 188.65it/s] 40%|███▉      | 158/396 [00:00<00:01, 189.21it/s] 45%|████▍     | 178/396 [00:00<00:01, 189.90it/s] 50%|█████     | 198/396 [00:01<00:01, 189.97it/s] 55%|█████▌    | 218/396 [00:01<00:00, 190.16it/s] 60%|██████    | 238/396 [00:01<00:00, 190.63it/s] 65%|██████▌   | 258/396 [00:01<00:00, 190.81it/s] 70%|███████   | 278/396 [00:01<00:00, 191.07it/s] 75%|███████▌  | 298/396 [00:01<00:00, 190.60it/s] 80%|████████  | 318/396 [00:01<00:00, 190.90it/s] 85%|████████▌ | 338/396 [00:01<00:00, 190.97it/s] 90%|█████████ | 358/396 [00:01<00:00, 191.14it/s] 95%|█████████▌| 378/396 [00:01<00:00, 191.17it/s]100%|██████████| 396/396 [00:02<00:00, 190.23it/s]
2024-07-22:07:18:15,310 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:16<?, ?it/s]
2024-07-22:07:18:42,440 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:18:49,574 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:18:49,574 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:18:49,580 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:18:49,580 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 256}
2024-07-22:07:18:49,589 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.54s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.36s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.70s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:19:02,757 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 188.25it/s] 10%|▉         | 39/396 [00:00<00:01, 189.35it/s] 15%|█▍        | 59/396 [00:00<00:01, 185.85it/s] 20%|█▉        | 78/396 [00:00<00:01, 187.13it/s] 25%|██▍       | 98/396 [00:00<00:01, 188.22it/s] 30%|██▉       | 118/396 [00:00<00:01, 188.91it/s] 35%|███▍      | 138/396 [00:00<00:01, 189.40it/s] 40%|███▉      | 157/396 [00:00<00:01, 189.43it/s] 44%|████▍     | 176/396 [00:00<00:01, 179.78it/s] 49%|████▉     | 196/396 [00:01<00:01, 182.95it/s] 54%|█████▍    | 215/396 [00:01<00:01, 177.11it/s] 59%|█████▉    | 233/396 [00:01<00:00, 172.40it/s] 64%|██████▍   | 253/396 [00:01<00:00, 177.57it/s] 69%|██████▊   | 272/396 [00:01<00:00, 181.10it/s] 73%|███████▎  | 291/396 [00:01<00:00, 183.53it/s] 78%|███████▊  | 310/396 [00:01<00:00, 185.35it/s] 83%|████████▎ | 329/396 [00:01<00:00, 186.67it/s] 88%|████████▊ | 348/396 [00:01<00:00, 187.43it/s] 93%|█████████▎| 367/396 [00:01<00:00, 188.10it/s] 97%|█████████▋| 386/396 [00:02<00:00, 188.46it/s]100%|██████████| 396/396 [00:02<00:00, 184.96it/s]
2024-07-22:07:19:04,906 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:07:19:35,159 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:19:42,411 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:19:42,412 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:19:42,417 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:19:42,417 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 256}
2024-07-22:07:19:42,426 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.34s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.68s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:20:33,955 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.14it/s] 10%|▉         | 39/396 [00:00<00:01, 190.58it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.93it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.63it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.03it/s] 30%|███       | 119/396 [00:00<00:01, 192.17it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.20it/s] 40%|████      | 159/396 [00:00<00:01, 192.15it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.09it/s] 50%|█████     | 199/396 [00:01<00:01, 192.06it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.08it/s] 60%|██████    | 239/396 [00:01<00:00, 192.02it/s] 65%|██████▌   | 259/396 [00:01<00:00, 192.05it/s] 70%|███████   | 279/396 [00:01<00:00, 192.05it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.95it/s] 81%|████████  | 319/396 [00:01<00:00, 191.91it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.82it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.78it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.72it/s]100%|██████████| 396/396 [00:02<00:00, 191.82it/s]
2024-07-22:07:20:36,027 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:07:21:02,385 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:21:09,840 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:21:09,841 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:21:09,847 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:21:09,847 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 512}
2024-07-22:07:21:09,857 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.37s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.18s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.54s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:21:22,970 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.82it/s] 10%|▉         | 39/396 [00:00<00:01, 191.11it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.39it/s] 20%|█▉        | 79/396 [00:00<00:01, 192.09it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.56it/s] 30%|███       | 119/396 [00:00<00:01, 192.47it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.61it/s] 40%|████      | 159/396 [00:00<00:01, 192.64it/s] 45%|████▌     | 179/396 [00:00<00:01, 189.59it/s] 50%|█████     | 199/396 [00:01<00:01, 190.22it/s] 55%|█████▌    | 219/396 [00:01<00:00, 190.74it/s] 60%|██████    | 239/396 [00:01<00:00, 191.10it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.45it/s] 70%|███████   | 279/396 [00:01<00:00, 191.80it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.04it/s] 81%|████████  | 319/396 [00:01<00:00, 191.89it/s] 86%|████████▌ | 339/396 [00:01<00:00, 192.02it/s] 91%|█████████ | 359/396 [00:01<00:00, 192.12it/s] 96%|█████████▌| 379/396 [00:01<00:00, 192.15it/s]100%|██████████| 396/396 [00:02<00:00, 191.72it/s]
2024-07-22:07:21:25,043 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:07:21:55,127 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:22:02,322 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:22:02,323 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:22:02,329 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:22:02,329 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 512}
2024-07-22:07:22:02,337 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.39s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.56s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:22:53,798 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.36it/s] 10%|█         | 40/396 [00:00<00:01, 192.47it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.87it/s] 20%|██        | 80/396 [00:00<00:01, 193.53it/s] 25%|██▌       | 100/396 [00:00<00:01, 194.02it/s] 30%|███       | 120/396 [00:00<00:01, 194.38it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.49it/s] 40%|████      | 160/396 [00:00<00:01, 194.66it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.48it/s] 51%|█████     | 200/396 [00:01<00:01, 193.70it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.03it/s] 61%|██████    | 240/396 [00:01<00:00, 194.29it/s] 66%|██████▌   | 260/396 [00:01<00:00, 194.41it/s] 71%|███████   | 280/396 [00:01<00:00, 194.49it/s] 76%|███████▌  | 300/396 [00:01<00:00, 194.58it/s] 81%|████████  | 320/396 [00:01<00:00, 194.59it/s] 86%|████████▌ | 340/396 [00:01<00:00, 194.41it/s] 91%|█████████ | 360/396 [00:01<00:00, 194.36it/s] 96%|█████████▌| 380/396 [00:01<00:00, 194.24it/s]100%|██████████| 396/396 [00:02<00:00, 194.15it/s]
2024-07-22:07:22:55,846 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:07:23:22,473 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:23:29,721 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:23:29,722 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:23:29,728 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:23:29,728 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1024}
2024-07-22:07:23:29,736 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.54s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:23:42,216 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 181.37it/s] 10%|▉         | 39/396 [00:00<00:01, 187.01it/s] 15%|█▍        | 59/396 [00:00<00:01, 189.21it/s] 20%|█▉        | 79/396 [00:00<00:01, 190.99it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.06it/s] 30%|███       | 119/396 [00:00<00:01, 192.80it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.33it/s] 40%|████      | 159/396 [00:00<00:01, 193.63it/s] 45%|████▌     | 179/396 [00:00<00:01, 193.74it/s] 50%|█████     | 199/396 [00:01<00:01, 193.82it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.58it/s] 60%|██████    | 239/396 [00:01<00:00, 193.62it/s] 65%|██████▌   | 259/396 [00:01<00:00, 193.75it/s] 70%|███████   | 279/396 [00:01<00:00, 193.83it/s] 76%|███████▌  | 299/396 [00:01<00:00, 193.82it/s] 81%|████████  | 319/396 [00:01<00:00, 193.86it/s] 86%|████████▌ | 339/396 [00:01<00:00, 193.87it/s] 91%|█████████ | 359/396 [00:01<00:00, 193.85it/s] 96%|█████████▌| 379/396 [00:01<00:00, 193.88it/s]100%|██████████| 396/396 [00:02<00:00, 193.00it/s]
2024-07-22:07:23:44,277 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:21<?, ?it/s]
2024-07-22:07:24:16,472 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:24:23,849 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:24:23,850 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:24:23,856 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:24:23,856 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1024}
2024-07-22:07:24:23,864 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.25s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.12s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:25:14,671 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.77it/s] 10%|▉         | 39/396 [00:00<00:01, 191.22it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.09it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.99it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.75it/s] 30%|███       | 119/396 [00:00<00:01, 193.25it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.46it/s] 40%|████      | 159/396 [00:00<00:01, 193.04it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.84it/s] 50%|█████     | 199/396 [00:01<00:01, 192.91it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.02it/s] 60%|██████    | 239/396 [00:01<00:00, 193.28it/s] 65%|██████▌   | 259/396 [00:01<00:00, 193.47it/s] 70%|███████   | 279/396 [00:01<00:00, 193.52it/s] 76%|███████▌  | 299/396 [00:01<00:00, 193.70it/s] 81%|████████  | 319/396 [00:01<00:00, 193.83it/s] 86%|████████▌ | 339/396 [00:01<00:00, 193.87it/s] 91%|█████████ | 359/396 [00:01<00:00, 193.92it/s] 96%|█████████▌| 379/396 [00:01<00:00, 193.77it/s]100%|██████████| 396/396 [00:02<00:00, 193.19it/s]
2024-07-22:07:25:16,729 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:18<?, ?it/s]
2024-07-22:07:25:46,179 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:25:53,472 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:25:53,474 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:25:53,479 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:25:53,479 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1536}
2024-07-22:07:25:53,658 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.66s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.14s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:26:08,396 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.91it/s] 10%|█         | 40/396 [00:00<00:01, 192.77it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.90it/s] 20%|██        | 80/396 [00:00<00:01, 193.53it/s] 25%|██▌       | 100/396 [00:00<00:01, 194.05it/s] 30%|███       | 120/396 [00:00<00:01, 194.43it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.52it/s] 40%|████      | 160/396 [00:00<00:01, 194.49it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.46it/s] 51%|█████     | 200/396 [00:01<00:01, 194.40it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.38it/s] 61%|██████    | 240/396 [00:01<00:00, 194.14it/s] 66%|██████▌   | 260/396 [00:01<00:00, 194.00it/s] 71%|███████   | 280/396 [00:01<00:00, 193.94it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.84it/s] 81%|████████  | 320/396 [00:01<00:00, 193.76it/s] 86%|████████▌ | 340/396 [00:01<00:00, 193.57it/s] 91%|█████████ | 360/396 [00:01<00:00, 193.46it/s] 96%|█████████▌| 380/396 [00:01<00:00, 193.29it/s]100%|██████████| 396/396 [00:02<00:00, 193.77it/s]
2024-07-22:07:26:10,448 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:22<?, ?it/s]
2024-07-22:07:26:44,240 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:26:51,388 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:26:51,388 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:26:51,394 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:26:51,394 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1536}
2024-07-22:07:26:51,402 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.25s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.50s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:27:42,156 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.03it/s] 10%|▉         | 39/396 [00:00<00:01, 190.40it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.79it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.83it/s] 25%|██▌       | 99/396 [00:00<00:01, 188.93it/s] 30%|███       | 119/396 [00:00<00:01, 190.67it/s] 35%|███▌      | 139/396 [00:00<00:01, 191.69it/s] 40%|████      | 159/396 [00:00<00:01, 192.29it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.77it/s] 50%|█████     | 199/396 [00:01<00:01, 192.98it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.14it/s] 60%|██████    | 239/396 [00:01<00:00, 193.26it/s] 65%|██████▌   | 259/396 [00:01<00:00, 193.40it/s] 70%|███████   | 279/396 [00:01<00:00, 193.43it/s] 76%|███████▌  | 299/396 [00:01<00:00, 193.20it/s] 81%|████████  | 319/396 [00:01<00:00, 193.20it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.13it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.34it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.55it/s]100%|██████████| 396/396 [00:02<00:00, 191.99it/s]
2024-07-22:07:27:44,226 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:18<?, ?it/s]
2024-07-22:07:28:13,185 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:28:20,428 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:28:20,429 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:28:20,435 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:28:20,435 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 2048}
2024-07-22:07:28:20,443 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.36s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.14s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.51s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:28:32,505 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.29it/s] 10%|█         | 40/396 [00:00<00:01, 192.01it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.34it/s] 20%|██        | 80/396 [00:00<00:01, 193.05it/s] 25%|██▌       | 100/396 [00:00<00:01, 190.23it/s] 30%|███       | 120/396 [00:00<00:01, 191.41it/s] 35%|███▌      | 140/396 [00:00<00:01, 192.02it/s] 40%|████      | 160/396 [00:00<00:01, 192.51it/s] 45%|████▌     | 180/396 [00:00<00:01, 192.81it/s] 51%|█████     | 200/396 [00:01<00:01, 192.94it/s] 56%|█████▌    | 220/396 [00:01<00:00, 192.81it/s] 61%|██████    | 240/396 [00:01<00:00, 192.93it/s] 66%|██████▌   | 260/396 [00:01<00:00, 193.10it/s] 71%|███████   | 280/396 [00:01<00:00, 193.29it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.38it/s] 81%|████████  | 320/396 [00:01<00:00, 193.45it/s] 86%|████████▌ | 340/396 [00:01<00:00, 193.36it/s] 91%|█████████ | 360/396 [00:01<00:00, 193.30it/s] 96%|█████████▌| 380/396 [00:01<00:00, 193.19it/s]100%|██████████| 396/396 [00:02<00:00, 192.78it/s]
2024-07-22:07:28:34,567 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:22<?, ?it/s]
2024-07-22:07:29:07,957 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:29:15,158 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:29:15,159 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:29:15,165 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:29:15,165 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 2048}
2024-07-22:07:29:15,173 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.34s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.72s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:30:07,593 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.02it/s] 10%|█         | 40/396 [00:00<00:01, 190.53it/s] 15%|█▌        | 60/396 [00:00<00:01, 190.90it/s] 20%|██        | 80/396 [00:00<00:01, 191.16it/s] 25%|██▌       | 100/396 [00:00<00:01, 192.00it/s] 30%|███       | 120/396 [00:00<00:01, 192.56it/s] 35%|███▌      | 140/396 [00:00<00:01, 192.70it/s] 40%|████      | 160/396 [00:00<00:01, 192.63it/s] 45%|████▌     | 180/396 [00:00<00:01, 192.67it/s] 51%|█████     | 200/396 [00:01<00:01, 192.06it/s] 56%|█████▌    | 220/396 [00:01<00:00, 192.53it/s] 61%|██████    | 240/396 [00:01<00:00, 192.70it/s] 66%|██████▌   | 260/396 [00:01<00:00, 190.67it/s] 71%|███████   | 280/396 [00:01<00:00, 189.94it/s] 76%|███████▌  | 299/396 [00:01<00:00, 189.76it/s] 80%|████████  | 318/396 [00:01<00:00, 189.11it/s] 85%|████████▌ | 337/396 [00:01<00:00, 189.22it/s] 90%|████████▉ | 356/396 [00:01<00:00, 189.39it/s] 95%|█████████▍| 376/396 [00:01<00:00, 189.73it/s]100%|█████████▉| 395/396 [00:02<00:00, 189.27it/s]100%|██████████| 396/396 [00:02<00:00, 190.79it/s]
2024-07-22:07:30:09,677 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:24<?, ?it/s]
2024-07-22:07:30:44,438 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:30:51,634 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:30:51,635 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:30:51,640 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:30:51,640 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 3072}
2024-07-22:07:30:51,649 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.62s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.70s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:31:04,504 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 190.36it/s] 10%|█         | 40/396 [00:00<00:01, 191.83it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.28it/s] 20%|██        | 80/396 [00:00<00:01, 192.95it/s] 25%|██▌       | 100/396 [00:00<00:01, 193.53it/s] 30%|███       | 120/396 [00:00<00:01, 193.83it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.00it/s] 40%|████      | 160/396 [00:00<00:01, 193.98it/s] 45%|████▌     | 180/396 [00:00<00:01, 193.97it/s] 51%|█████     | 200/396 [00:01<00:01, 193.82it/s] 56%|█████▌    | 220/396 [00:01<00:00, 193.66it/s] 61%|██████    | 240/396 [00:01<00:00, 193.65it/s] 66%|██████▌   | 260/396 [00:01<00:00, 193.64it/s] 71%|███████   | 280/396 [00:01<00:00, 193.67it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.75it/s] 81%|████████  | 320/396 [00:01<00:00, 193.67it/s] 86%|████████▌ | 340/396 [00:01<00:00, 193.56it/s] 91%|█████████ | 360/396 [00:01<00:00, 193.47it/s] 96%|█████████▌| 380/396 [00:01<00:00, 193.35it/s]100%|██████████| 396/396 [00:02<00:00, 193.46it/s]
2024-07-22:07:31:06,560 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:24<?, ?it/s]
2024-07-22:07:31:41,482 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:31:48,724 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:31:48,725 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:31:48,730 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:31:48,730 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 3072}
2024-07-22:07:31:48,739 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.56s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:32:39,636 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.44it/s] 10%|▉         | 39/396 [00:00<00:01, 190.70it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.30it/s] 20%|█▉        | 79/396 [00:00<00:01, 192.19it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.80it/s] 30%|███       | 119/396 [00:00<00:01, 193.32it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.21it/s] 40%|████      | 159/396 [00:00<00:01, 193.55it/s] 45%|████▌     | 179/396 [00:00<00:01, 193.73it/s] 50%|█████     | 199/396 [00:01<00:01, 193.84it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.85it/s] 60%|██████    | 239/396 [00:01<00:00, 193.87it/s] 65%|██████▌   | 259/396 [00:01<00:00, 193.95it/s] 70%|███████   | 279/396 [00:01<00:00, 193.97it/s] 76%|███████▌  | 299/396 [00:01<00:00, 194.01it/s] 81%|████████  | 319/396 [00:01<00:00, 194.01it/s] 86%|████████▌ | 339/396 [00:01<00:00, 193.44it/s] 91%|█████████ | 359/396 [00:01<00:00, 193.45it/s] 96%|█████████▌| 379/396 [00:01<00:00, 193.43it/s]100%|██████████| 396/396 [00:02<00:00, 193.33it/s]
2024-07-22:07:32:41,693 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:21<?, ?it/s]
2024-07-22:07:33:13,676 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:33:20,910 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:33:20,911 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:33:20,917 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:33:20,917 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 4096}
2024-07-22:07:33:20,925 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.25s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.51s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:33:33,016 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 193.76it/s] 10%|█         | 40/396 [00:00<00:01, 194.59it/s] 15%|█▌        | 60/396 [00:00<00:01, 194.86it/s] 20%|██        | 80/396 [00:00<00:01, 195.56it/s] 25%|██▌       | 100/396 [00:00<00:01, 196.15it/s] 30%|███       | 120/396 [00:00<00:01, 196.49it/s] 35%|███▌      | 140/396 [00:00<00:01, 196.26it/s] 40%|████      | 160/396 [00:00<00:01, 196.37it/s] 45%|████▌     | 180/396 [00:00<00:01, 196.35it/s] 51%|█████     | 200/396 [00:01<00:00, 196.23it/s] 56%|█████▌    | 220/396 [00:01<00:00, 196.28it/s] 61%|██████    | 240/396 [00:01<00:00, 196.17it/s] 66%|██████▌   | 260/396 [00:01<00:00, 196.10it/s] 71%|███████   | 280/396 [00:01<00:00, 196.04it/s] 76%|███████▌  | 300/396 [00:01<00:00, 196.08it/s] 81%|████████  | 320/396 [00:01<00:00, 196.01it/s] 86%|████████▌ | 340/396 [00:01<00:00, 195.91it/s] 91%|█████████ | 360/396 [00:01<00:00, 195.80it/s] 96%|█████████▌| 380/396 [00:01<00:00, 195.70it/s]100%|██████████| 396/396 [00:02<00:00, 195.89it/s]
2024-07-22:07:33:35,045 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:25<?, ?it/s]
2024-07-22:07:34:11,002 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:34:18,265 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:34:18,266 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:34:18,272 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:34:18,272 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 4096}
2024-07-22:07:34:18,281 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.23s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.09s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]
