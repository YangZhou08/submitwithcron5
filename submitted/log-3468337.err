Already on 'yangexp2threee'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-07-22:07:16:09,681 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:16:19,262 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:16:19,263 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:16:19,286 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:16:19,286 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 128}
2024-07-22:07:16:19,295 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:18,  6.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:12<00:12,  6.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:17<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.84s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:16:41,333 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.96it/s] 10%|▉         | 39/396 [00:00<00:01, 190.57it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.34it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.27it/s] 25%|██▌       | 99/396 [00:00<00:01, 191.87it/s] 30%|███       | 119/396 [00:00<00:01, 192.24it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.41it/s] 40%|████      | 159/396 [00:00<00:01, 192.44it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.34it/s] 50%|█████     | 199/396 [00:01<00:01, 192.24it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.29it/s] 60%|██████    | 239/396 [00:01<00:00, 192.02it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.78it/s] 70%|███████   | 279/396 [00:01<00:00, 191.30it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.56it/s] 81%|████████  | 319/396 [00:01<00:00, 191.70it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.83it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.88it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.91it/s]100%|██████████| 396/396 [00:02<00:00, 191.81it/s]
2024-07-22:07:16:43,428 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:07:17:13,980 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:17:21,235 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:17:21,236 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:17:21,242 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:17:21,242 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 128}
2024-07-22:07:17:21,251 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.59s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.70s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:18:13,218 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 187.06it/s] 10%|▉         | 38/396 [00:00<00:01, 187.94it/s] 15%|█▍        | 58/396 [00:00<00:01, 188.99it/s] 20%|█▉        | 78/396 [00:00<00:01, 190.06it/s] 25%|██▍       | 98/396 [00:00<00:01, 190.66it/s] 30%|██▉       | 118/396 [00:00<00:01, 187.35it/s] 35%|███▍      | 138/396 [00:00<00:01, 188.65it/s] 40%|███▉      | 158/396 [00:00<00:01, 189.21it/s] 45%|████▍     | 178/396 [00:00<00:01, 189.90it/s] 50%|█████     | 198/396 [00:01<00:01, 189.97it/s] 55%|█████▌    | 218/396 [00:01<00:00, 190.16it/s] 60%|██████    | 238/396 [00:01<00:00, 190.63it/s] 65%|██████▌   | 258/396 [00:01<00:00, 190.81it/s] 70%|███████   | 278/396 [00:01<00:00, 191.07it/s] 75%|███████▌  | 298/396 [00:01<00:00, 190.60it/s] 80%|████████  | 318/396 [00:01<00:00, 190.90it/s] 85%|████████▌ | 338/396 [00:01<00:00, 190.97it/s] 90%|█████████ | 358/396 [00:01<00:00, 191.14it/s] 95%|█████████▌| 378/396 [00:01<00:00, 191.17it/s]100%|██████████| 396/396 [00:02<00:00, 190.23it/s]
2024-07-22:07:18:15,310 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:16<?, ?it/s]
2024-07-22:07:18:42,440 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:18:49,574 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:18:49,574 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:18:49,580 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:18:49,580 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 256}
2024-07-22:07:18:49,589 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.54s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.36s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.70s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:19:02,757 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 188.25it/s] 10%|▉         | 39/396 [00:00<00:01, 189.35it/s] 15%|█▍        | 59/396 [00:00<00:01, 185.85it/s] 20%|█▉        | 78/396 [00:00<00:01, 187.13it/s] 25%|██▍       | 98/396 [00:00<00:01, 188.22it/s] 30%|██▉       | 118/396 [00:00<00:01, 188.91it/s] 35%|███▍      | 138/396 [00:00<00:01, 189.40it/s] 40%|███▉      | 157/396 [00:00<00:01, 189.43it/s] 44%|████▍     | 176/396 [00:00<00:01, 179.78it/s] 49%|████▉     | 196/396 [00:01<00:01, 182.95it/s] 54%|█████▍    | 215/396 [00:01<00:01, 177.11it/s] 59%|█████▉    | 233/396 [00:01<00:00, 172.40it/s] 64%|██████▍   | 253/396 [00:01<00:00, 177.57it/s] 69%|██████▊   | 272/396 [00:01<00:00, 181.10it/s] 73%|███████▎  | 291/396 [00:01<00:00, 183.53it/s] 78%|███████▊  | 310/396 [00:01<00:00, 185.35it/s] 83%|████████▎ | 329/396 [00:01<00:00, 186.67it/s] 88%|████████▊ | 348/396 [00:01<00:00, 187.43it/s] 93%|█████████▎| 367/396 [00:01<00:00, 188.10it/s] 97%|█████████▋| 386/396 [00:02<00:00, 188.46it/s]100%|██████████| 396/396 [00:02<00:00, 184.96it/s]
2024-07-22:07:19:04,906 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:07:19:35,159 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:19:42,411 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:19:42,412 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:19:42,417 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:19:42,417 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 256}
2024-07-22:07:19:42,426 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.34s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.68s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:20:33,955 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.14it/s] 10%|▉         | 39/396 [00:00<00:01, 190.58it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.93it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.63it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.03it/s] 30%|███       | 119/396 [00:00<00:01, 192.17it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.20it/s] 40%|████      | 159/396 [00:00<00:01, 192.15it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.09it/s] 50%|█████     | 199/396 [00:01<00:01, 192.06it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.08it/s] 60%|██████    | 239/396 [00:01<00:00, 192.02it/s] 65%|██████▌   | 259/396 [00:01<00:00, 192.05it/s] 70%|███████   | 279/396 [00:01<00:00, 192.05it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.95it/s] 81%|████████  | 319/396 [00:01<00:00, 191.91it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.82it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.78it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.72it/s]100%|██████████| 396/396 [00:02<00:00, 191.82it/s]
2024-07-22:07:20:36,027 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:07:21:02,385 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:21:09,840 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:21:09,841 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:21:09,847 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:21:09,847 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 512}
2024-07-22:07:21:09,857 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.37s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.18s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.54s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:21:22,970 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.82it/s] 10%|▉         | 39/396 [00:00<00:01, 191.11it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.39it/s] 20%|█▉        | 79/396 [00:00<00:01, 192.09it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.56it/s] 30%|███       | 119/396 [00:00<00:01, 192.47it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.61it/s] 40%|████      | 159/396 [00:00<00:01, 192.64it/s] 45%|████▌     | 179/396 [00:00<00:01, 189.59it/s] 50%|█████     | 199/396 [00:01<00:01, 190.22it/s] 55%|█████▌    | 219/396 [00:01<00:00, 190.74it/s] 60%|██████    | 239/396 [00:01<00:00, 191.10it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.45it/s] 70%|███████   | 279/396 [00:01<00:00, 191.80it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.04it/s] 81%|████████  | 319/396 [00:01<00:00, 191.89it/s] 86%|████████▌ | 339/396 [00:01<00:00, 192.02it/s] 91%|█████████ | 359/396 [00:01<00:00, 192.12it/s] 96%|█████████▌| 379/396 [00:01<00:00, 192.15it/s]100%|██████████| 396/396 [00:02<00:00, 191.72it/s]
2024-07-22:07:21:25,043 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:07:21:55,127 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:22:02,322 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:22:02,323 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:22:02,329 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:22:02,329 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 512}
2024-07-22:07:22:02,337 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.39s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.56s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:22:53,798 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.36it/s] 10%|█         | 40/396 [00:00<00:01, 192.47it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.87it/s] 20%|██        | 80/396 [00:00<00:01, 193.53it/s] 25%|██▌       | 100/396 [00:00<00:01, 194.02it/s] 30%|███       | 120/396 [00:00<00:01, 194.38it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.49it/s] 40%|████      | 160/396 [00:00<00:01, 194.66it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.48it/s] 51%|█████     | 200/396 [00:01<00:01, 193.70it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.03it/s] 61%|██████    | 240/396 [00:01<00:00, 194.29it/s] 66%|██████▌   | 260/396 [00:01<00:00, 194.41it/s] 71%|███████   | 280/396 [00:01<00:00, 194.49it/s] 76%|███████▌  | 300/396 [00:01<00:00, 194.58it/s] 81%|████████  | 320/396 [00:01<00:00, 194.59it/s] 86%|████████▌ | 340/396 [00:01<00:00, 194.41it/s] 91%|█████████ | 360/396 [00:01<00:00, 194.36it/s] 96%|█████████▌| 380/396 [00:01<00:00, 194.24it/s]100%|██████████| 396/396 [00:02<00:00, 194.15it/s]
2024-07-22:07:22:55,846 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:07:23:22,473 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:23:29,721 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:23:29,722 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:23:29,728 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:23:29,728 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1024}
2024-07-22:07:23:29,736 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.54s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:07:23:42,216 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 181.37it/s] 10%|▉         | 39/396 [00:00<00:01, 187.01it/s] 15%|█▍        | 59/396 [00:00<00:01, 189.21it/s] 20%|█▉        | 79/396 [00:00<00:01, 190.99it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.06it/s] 30%|███       | 119/396 [00:00<00:01, 192.80it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.33it/s] 40%|████      | 159/396 [00:00<00:01, 193.63it/s] 45%|████▌     | 179/396 [00:00<00:01, 193.74it/s] 50%|█████     | 199/396 [00:01<00:01, 193.82it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.58it/s] 60%|██████    | 239/396 [00:01<00:00, 193.62it/s] 65%|██████▌   | 259/396 [00:01<00:00, 193.75it/s] 70%|███████   | 279/396 [00:01<00:00, 193.83it/s] 76%|███████▌  | 299/396 [00:01<00:00, 193.82it/s] 81%|████████  | 319/396 [00:01<00:00, 193.86it/s] 86%|████████▌ | 339/396 [00:01<00:00, 193.87it/s] 91%|█████████ | 359/396 [00:01<00:00, 193.85it/s] 96%|█████████▌| 379/396 [00:01<00:00, 193.88it/s]100%|██████████| 396/396 [00:02<00:00, 193.00it/s]
2024-07-22:07:23:44,277 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:21<?, ?it/s]
2024-07-22:07:24:16,472 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:07:24:23,849 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:07:24:23,850 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:07:24:23,856 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:07:24:23,856 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1024}
2024-07-22:07:24:23,864 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.25s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.12s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]
