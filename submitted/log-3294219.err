Already on 'addinggriffin'
Your configuration specifies to merge with the ref 'refs/heads/addinggriffin'
from the remote, but no such ref was fetched.
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.35s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.95s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:01<01:01, 61.00s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.95s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:01<01:01, 61.03s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.98s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:01<01:01, 61.75s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.41s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.60s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.97s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.62s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.58s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.51s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.59s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.59s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  3%|▎         | 1/32 [00:06<03:13,  6.25s/it]  3%|▎         | 1/32 [00:11<05:58, 11.55s/it]  6%|▋         | 2/32 [00:12<03:01,  6.06s/it]  3%|▎         | 1/32 [00:15<07:58, 15.43s/it]  9%|▉         | 3/32 [00:16<02:32,  5.27s/it]  6%|▋         | 2/32 [00:22<05:22, 10.75s/it]  9%|▉         | 3/32 [00:30<04:27,  9.21s/it]  3%|▎         | 1/32 [00:40<20:41, 40.04s/it]  3%|▎         | 1/32 [00:40<21:09, 40.97s/it]  3%|▎         | 1/32 [00:41<21:11, 41.02s/it]  3%|▎         | 1/32 [00:41<21:35, 41.79s/it]  6%|▋         | 2/32 [00:42<09:01, 18.04s/it]  6%|▋         | 2/32 [00:49<10:45, 21.51s/it]  6%|▋         | 2/32 [00:52<14:32, 29.09s/it]  3%|▎         | 1/32 [00:58<30:02, 58.15s/it] 12%|█▎        | 4/32 [00:58<09:08, 19.57s/it]  9%|▉         | 3/32 [00:59<07:50, 16.23s/it] 12%|█▎        | 4/32 [01:03<05:18, 11.38s/it]  6%|▋         | 2/32 [01:10<15:28, 30.96s/it]  9%|▉         | 3/32 [01:15<09:15, 19.15s/it]  6%|▋         | 2/32 [01:19<19:46, 39.55s/it]  6%|▋         | 2/32 [01:20<20:01, 40.06s/it]  9%|▉         | 3/32 [01:22<13:28, 27.87s/it] 12%|█▎        | 4/32 [01:27<13:05, 28.06s/it] 12%|█▎        | 4/32 [01:29<09:11, 19.70s/it]  9%|▉         | 3/32 [01:32<13:09, 27.22s/it] 16%|█▌        | 5/32 [01:37<12:04, 26.83s/it]  9%|▉         | 3/32 [01:39<17:57, 37.16s/it] 16%|█▌        | 5/32 [01:42<09:45, 21.70s/it] 12%|█▎        | 4/32 [01:48<12:11, 26.13s/it]  9%|▉         | 3/32 [01:58<19:04, 39.45s/it] 16%|█▌        | 5/32 [02:09<12:05, 26.88s/it] 12%|█▎        | 4/32 [02:11<15:51, 33.99s/it] 12%|█▎        | 4/32 [02:12<15:02, 32.22s/it] 19%|█▉        | 6/32 [02:13<08:17, 19.12s/it] 19%|█▉        | 6/32 [02:17<13:28, 31.11s/it] 22%|██▏       | 7/32 [02:18<06:05, 14.60s/it] 16%|█▌        | 5/32 [02:18<10:19, 22.94s/it] 16%|█▌        | 5/32 [02:20<11:09, 24.79s/it] 19%|█▉        | 6/32 [02:22<12:01, 27.74s/it] 22%|██▏       | 7/32 [02:22<09:24, 22.58s/it] 16%|█▌        | 5/32 [02:23<17:12, 38.22s/it] 25%|██▌       | 8/32 [02:26<06:44, 16.85s/it] 19%|█▉        | 6/32 [02:31<12:09, 28.06s/it] 28%|██▊       | 9/32 [02:32<05:05, 13.29s/it] 16%|█▌        | 5/32 [02:35<15:04, 33.50s/it] 31%|███▏      | 10/32 [02:36<03:50, 10.46s/it] 12%|█▎        | 4/32 [02:37<18:19, 39.27s/it] 19%|█▉        | 6/32 [02:45<10:59, 25.36s/it] 34%|███▍      | 11/32 [02:47<03:41, 10.55s/it] 25%|██▌       | 8/32 [02:58<09:01, 22.55s/it] 19%|█▉        | 6/32 [02:58<12:24, 28.65s/it] 22%|██▏       | 7/32 [03:01<13:08, 31.56s/it] 22%|██▏       | 7/32 [03:04<08:49, 21.18s/it] 25%|██▌       | 8/32 [03:12<06:52, 17.20s/it] 16%|█▌        | 5/32 [03:16<17:35, 39.08s/it] 19%|█▉        | 6/32 [03:16<15:23, 35.53s/it] 38%|███▊      | 12/32 [03:26<06:26, 19.35s/it] 22%|██▏       | 7/32 [03:28<15:37, 37.51s/it] 22%|██▏       | 7/32 [03:31<13:26, 32.25s/it] 28%|██▊       | 9/32 [03:37<10:40, 27.85s/it] 25%|██▌       | 8/32 [03:41<13:36, 34.02s/it] 28%|██▊       | 9/32 [03:52<09:17, 24.22s/it] 19%|█▉        | 6/32 [03:55<16:57, 39.13s/it] 41%|████      | 13/32 [04:06<08:08, 25.74s/it] 22%|██▏       | 7/32 [04:13<17:37, 42.30s/it] 31%|███▏      | 10/32 [04:17<11:31, 31.44s/it] 25%|██▌       | 8/32 [04:18<14:43, 36.81s/it] 28%|██▊       | 9/32 [04:20<13:41, 35.70s/it] 25%|██▌       | 8/32 [04:25<13:10, 32.93s/it] 25%|██▌       | 8/32 [04:25<17:28, 43.68s/it] 28%|██▊       | 9/32 [04:27<10:48, 28.18s/it] 31%|███▏      | 10/32 [04:31<10:33, 28.79s/it] 31%|███▏      | 10/32 [04:31<07:40, 20.92s/it] 22%|██▏       | 7/32 [04:34<16:19, 39.19s/it] 34%|███▍      | 11/32 [04:34<05:23, 15.40s/it] 34%|███▍      | 11/32 [04:34<07:20, 20.95s/it] 38%|███▊      | 12/32 [04:40<05:25, 16.26s/it] 38%|███▊      | 12/32 [04:42<04:21, 13.06s/it] 44%|████▍     | 14/32 [04:47<09:01, 30.09s/it] 41%|████      | 13/32 [04:49<03:32, 11.18s/it] 44%|████▍     | 14/32 [04:52<02:38,  8.83s/it] 34%|███▍      | 11/32 [04:56<11:51, 33.86s/it] 47%|████▋     | 15/32 [04:57<06:48, 24.05s/it] 31%|███▏      | 10/32 [05:00<13:31, 36.87s/it] 38%|███▊      | 12/32 [05:03<08:34, 25.74s/it] 25%|██▌       | 8/32 [05:13<15:38, 39.12s/it] 28%|██▊       | 9/32 [05:19<11:02, 28.79s/it] 41%|████      | 13/32 [05:19<07:21, 23.23s/it] 28%|██▊       | 9/32 [05:21<15:24, 40.18s/it] 28%|██▊       | 9/32 [05:21<18:13, 47.56s/it] 50%|█████     | 16/32 [05:37<07:42, 28.93s/it] 34%|███▍      | 11/32 [05:39<13:11, 37.71s/it] 47%|████▋     | 15/32 [05:39<05:44, 20.25s/it] 41%|████      | 13/32 [05:43<09:29, 29.98s/it] 53%|█████▎    | 17/32 [05:44<05:37, 22.49s/it] 56%|█████▋    | 18/32 [05:48<03:57, 16.94s/it] 31%|███▏      | 10/32 [05:58<11:40, 31.82s/it] 44%|████▍     | 14/32 [05:58<08:25, 28.06s/it] 47%|████▋     | 15/32 [06:02<05:50, 20.62s/it] 34%|███▍      | 11/32 [06:09<08:51, 25.31s/it] 38%|███▊      | 12/32 [06:14<06:26, 19.30s/it] 31%|███▏      | 10/32 [06:18<16:35, 45.25s/it] 31%|███▏      | 10/32 [06:18<18:27, 50.33s/it] 38%|███▊      | 12/32 [06:18<12:43, 38.17s/it] 44%|████▍     | 14/32 [06:23<09:54, 33.03s/it] 34%|███▍      | 11/32 [06:25<11:44, 33.57s/it] 50%|█████     | 16/32 [06:26<07:30, 28.19s/it] 59%|█████▉    | 19/32 [06:29<05:10, 23.89s/it] 53%|█████▎    | 17/32 [06:35<05:36, 22.43s/it] 50%|█████     | 16/32 [06:41<06:59, 26.23s/it] 56%|█████▋    | 18/32 [06:41<04:07, 17.68s/it] 41%|████      | 13/32 [06:53<08:01, 25.36s/it] 44%|████▍     | 14/32 [06:58<05:42, 19.05s/it] 41%|████      | 13/32 [06:58<12:14, 38.63s/it] 47%|████▋     | 15/32 [07:03<09:54, 34.97s/it] 62%|██████▎   | 20/32 [07:08<05:43, 28.58s/it] 34%|███▍      | 11/32 [07:14<18:15, 52.18s/it] 38%|███▊      | 12/32 [07:19<12:38, 37.92s/it] 53%|█████▎    | 17/32 [07:20<07:31, 30.11s/it] 38%|███▊      | 12/32 [07:22<13:32, 40.65s/it] 59%|█████▉    | 19/32 [07:28<05:43, 26.43s/it] 56%|█████▋    | 18/32 [07:31<05:38, 24.21s/it] 47%|████▋     | 15/32 [07:36<07:04, 24.94s/it] 44%|████▍     | 14/32 [07:38<11:40, 38.90s/it] 50%|█████     | 16/32 [07:42<09:43, 36.44s/it] 66%|██████▌   | 21/32 [07:47<05:50, 31.82s/it] 59%|█████▉    | 19/32 [08:10<06:13, 28.73s/it] 62%|██████▎   | 20/32 [08:14<04:18, 21.51s/it] 62%|██████▎   | 20/32 [08:15<06:29, 32.46s/it] 50%|█████     | 16/32 [08:16<07:47, 29.22s/it] 41%|████      | 13/32 [08:16<13:47, 43.57s/it] 66%|██████▌   | 21/32 [08:17<02:52, 15.69s/it] 47%|████▋     | 15/32 [08:17<11:03, 39.04s/it] 41%|████      | 13/32 [08:19<14:25, 45.56s/it] 53%|█████▎    | 17/32 [08:22<09:19, 37.30s/it] 69%|██████▉   | 22/32 [08:22<02:06, 12.62s/it] 69%|██████▉   | 22/32 [08:27<05:41, 34.14s/it] 44%|████▍     | 14/32 [08:28<10:23, 34.62s/it] 53%|█████▎    | 17/32 [08:54<08:01, 32.08s/it] 50%|█████     | 16/32 [08:57<10:28, 39.29s/it] 66%|██████▌   | 21/32 [09:01<06:43, 36.69s/it] 72%|███████▏  | 23/32 [09:01<03:04, 20.54s/it] 56%|█████▋    | 18/32 [09:01<08:51, 38.00s/it] 56%|█████▋    | 18/32 [09:04<05:55, 25.41s/it] 59%|█████▉    | 19/32 [09:04<05:57, 27.48s/it] 72%|███████▏  | 23/32 [09:06<05:21, 35.70s/it] 59%|█████▉    | 19/32 [09:08<04:05, 18.87s/it] 75%|███████▌  | 24/32 [09:12<03:32, 26.58s/it] 44%|████▍     | 14/32 [09:12<14:13, 47.44s/it] 47%|████▋     | 15/32 [09:17<09:47, 34.55s/it] 78%|███████▊  | 25/32 [09:17<02:21, 20.22s/it] 50%|█████     | 16/32 [09:21<06:43, 25.19s/it] 47%|████▋     | 15/32 [09:25<11:42, 41.34s/it] 53%|█████▎    | 17/32 [09:36<09:50, 39.38s/it] 75%|███████▌  | 24/32 [09:40<03:29, 26.16s/it] 62%|██████▎   | 20/32 [09:44<06:13, 31.16s/it] 62%|██████▎   | 20/32 [09:47<05:00, 25.07s/it] 69%|██████▉   | 22/32 [09:48<06:36, 39.68s/it] 81%|████████▏ | 26/32 [09:57<02:36, 26.11s/it] 72%|███████▏  | 23/32 [09:59<04:40, 31.15s/it] 56%|█████▋    | 18/32 [10:16<09:14, 39.58s/it] 53%|█████▎    | 17/32 [10:18<08:41, 34.74s/it] 78%|███████▊  | 25/32 [10:20<03:31, 30.15s/it] 59%|█████▉    | 19/32 [10:21<06:15, 28.90s/it] 50%|█████     | 16/32 [10:22<12:17, 46.12s/it] 62%|██████▎   | 20/32 [10:24<04:15, 21.30s/it] 66%|██████▌   | 21/32 [10:24<06:12, 33.89s/it] 66%|██████▌   | 21/32 [10:27<05:22, 29.29s/it] 66%|██████▌   | 21/32 [10:30<03:04, 16.73s/it] 84%|████████▍ | 27/32 [10:36<02:30, 30.05s/it] 75%|███████▌  | 24/32 [10:40<04:32, 34.12s/it] 81%|████████▏ | 26/32 [10:59<03:16, 32.77s/it] 69%|██████▉   | 22/32 [11:04<05:56, 35.63s/it] 69%|██████▉   | 22/32 [11:06<05:22, 32.24s/it] 69%|██████▉   | 22/32 [11:10<03:56, 23.60s/it] 72%|███████▏  | 23/32 [11:12<04:07, 27.48s/it] 56%|█████▋    | 18/32 [11:14<09:37, 41.25s/it] 88%|████████▊ | 28/32 [11:16<02:11, 32.93s/it] 53%|█████▎    | 17/32 [11:19<12:19, 49.30s/it] 78%|███████▊  | 25/32 [11:20<04:10, 35.71s/it] 56%|█████▋    | 18/32 [11:24<08:23, 35.97s/it] 59%|█████▉    | 19/32 [11:34<06:05, 28.14s/it] 84%|████████▍ | 27/32 [11:38<02:53, 34.66s/it] 88%|████████▊ | 28/32 [11:41<01:40, 25.08s/it] 72%|███████▏  | 23/32 [11:44<05:07, 34.21s/it] 91%|█████████ | 29/32 [11:45<00:56, 18.94s/it] 78%|███████▊  | 25/32 [11:47<02:12, 18.90s/it] 72%|███████▏  | 23/32 [11:49<04:15, 28.34s/it] 75%|███████▌  | 24/32 [11:52<04:09, 31.15s/it] 91%|█████████ | 29/32 [11:55<01:44, 34.92s/it] 75%|███████▌  | 24/32 [11:59<03:01, 22.65s/it] 81%|████████▏ | 26/32 [11:59<03:41, 36.85s/it] 59%|█████▉    | 19/32 [12:10<09:55, 45.82s/it] 94%|█████████▍| 30/32 [12:25<00:50, 25.14s/it] 81%|████████▏ | 26/32 [12:26<02:23, 23.96s/it] 84%|████████▍ | 27/32 [12:30<01:33, 18.70s/it] 62%|██████▎   | 20/32 [12:31<07:21, 36.79s/it] 78%|███████▊  | 25/32 [12:32<03:56, 33.83s/it] 94%|█████████▍| 30/32 [12:35<01:12, 36.26s/it] 78%|███████▊  | 25/32 [12:38<03:14, 27.72s/it] 84%|████████▍ | 27/32 [12:39<03:08, 37.72s/it] 88%|████████▊ | 28/32 [12:49<01:58, 29.54s/it] 97%|█████████▋| 31/32 [13:04<00:29, 29.34s/it] 62%|██████▎   | 20/32 [13:07<09:48, 49.01s/it] 88%|████████▊ | 28/32 [13:09<01:37, 24.31s/it] 91%|█████████ | 29/32 [13:12<00:54, 18.29s/it] 81%|████████▏ | 26/32 [13:12<03:33, 35.66s/it] 97%|█████████▋| 31/32 [13:14<00:37, 37.11s/it] 84%|████████▍ | 27/32 [13:17<02:12, 26.44s/it] 81%|████████▏ | 26/32 [13:18<03:07, 31.24s/it] 94%|█████████▍| 30/32 [13:20<00:30, 15.39s/it] 84%|████████▍ | 27/32 [13:24<01:59, 23.88s/it] 97%|█████████▋| 31/32 [13:25<00:12, 12.28s/it] 66%|██████▌   | 21/32 [13:28<07:51, 42.88s/it] 91%|█████████ | 29/32 [13:29<01:38, 32.69s/it] 69%|██████▉   | 22/32 [13:39<05:33, 33.38s/it]100%|██████████| 32/32 [13:44<00:00, 32.49s/it]100%|██████████| 32/32 [13:44<00:00, 25.76s/it]
100%|██████████| 32/32 [13:53<00:00, 37.76s/it]100%|██████████| 32/32 [13:53<00:00, 26.05s/it]
 88%|████████▊ | 28/32 [13:57<02:01, 30.50s/it] 91%|█████████ | 29/32 [14:00<01:06, 22.22s/it] 66%|██████▌   | 21/32 [14:03<09:23, 51.22s/it]100%|██████████| 32/32 [14:04<00:00, 20.13s/it]100%|██████████| 32/32 [14:04<00:00, 26.38s/it]
 88%|████████▊ | 28/32 [14:04<01:54, 28.59s/it] 91%|█████████ | 29/32 [14:09<01:05, 21.68s/it] 94%|█████████▍| 30/32 [14:12<01:11, 35.58s/it] 94%|█████████▍| 30/32 [14:15<00:33, 16.84s/it] 72%|███████▏  | 23/32 [14:36<06:04, 40.48s/it] 94%|█████████▍| 30/32 [14:40<00:54, 27.48s/it] 97%|█████████▋| 31/32 [14:51<00:22, 22.62s/it] 97%|█████████▋| 31/32 [14:51<00:36, 36.82s/it]100%|██████████| 32/32 [14:54<00:00, 16.77s/it]100%|██████████| 32/32 [14:54<00:00, 27.96s/it]
 97%|█████████▋| 31/32 [14:54<00:23, 23.64s/it] 69%|██████▉   | 22/32 [15:00<08:48, 52.80s/it]100%|██████████| 32/32 [15:31<00:00, 37.79s/it]100%|██████████| 32/32 [15:31<00:00, 29.12s/it]
 75%|███████▌  | 24/32 [15:34<06:04, 45.54s/it]100%|██████████| 32/32 [15:34<00:00, 28.42s/it]100%|██████████| 32/32 [15:34<00:00, 29.20s/it]
 72%|███████▏  | 23/32 [15:56<08:05, 53.90s/it] 78%|███████▊  | 25/32 [16:30<05:42, 48.92s/it] 75%|███████▌  | 24/32 [16:52<07:16, 54.62s/it] 78%|███████▊  | 25/32 [17:02<04:48, 41.24s/it] 81%|████████▏ | 26/32 [17:27<05:07, 51.28s/it] 81%|████████▏ | 26/32 [17:59<04:35, 45.86s/it] 84%|████████▍ | 27/32 [18:15<03:04, 36.85s/it] 84%|████████▍ | 27/32 [18:24<04:24, 52.98s/it] 88%|████████▊ | 28/32 [18:30<02:34, 38.74s/it] 91%|█████████ | 29/32 [18:46<01:35, 31.90s/it] 94%|█████████▍| 30/32 [18:51<00:48, 24.08s/it] 97%|█████████▋| 31/32 [19:00<00:19, 19.57s/it] 88%|████████▊ | 28/32 [19:12<02:51, 42.77s/it] 94%|█████████▍| 30/32 [19:19<00:49, 24.71s/it]100%|██████████| 32/32 [19:57<00:00, 30.79s/it]100%|██████████| 32/32 [19:57<00:00, 37.43s/it]
 97%|█████████▋| 31/32 [20:12<00:31, 31.82s/it]100%|██████████| 32/32 [20:19<00:00, 25.26s/it]100%|██████████| 32/32 [20:19<00:00, 38.11s/it]
