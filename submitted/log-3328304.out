Already up to date.
Already up to date.
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /data/home/beidic/.cache/huggingface/token
Login successful
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
We now use eos_token as pad token
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
beam width is 8
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
tasks ['csqa']tasks ['csqa']tasks ['csqa']


tasks ['csqa']
tasks ['csqa']tasks ['csqa']
tasks ['csqa']

tasks ['csqa']
length of dataset:  1224
length of dataset:  1224
length of dataset:  1224
length of dataset:  1224
length of dataset:  1224
length of dataset:  1224
length of dataset:  1224
length of dataset:  1224
Answer n expected b
Answer e expected e
Answer a expected a
Answer e expected c
Answer a expected a
Answer e expected d
Answer c expected c
Answer b expected c
Answer e expected e
Answer 
 expected c
Answer e expected b
Answer d expected d
Answer a expected a
Answer b expected a
Answer d expected d
Answer a expected a
Answer d expected d
Answer b expected d
Answer d expected d
Answer a expected a
Answer e expected c
Answer e expected e
Answer s expected e
Answer a expected a
Answer e expected e
Answer b expected a
Answer   expected d
Answer a expected a
Answer d expected d
Answer c expected c
Answer g expected a
Answer d expected d
Answer 
 expected d
Answer d expected d
Answer d expected d
Answer b expected b
Answer c expected c
Answer e expected e
Answer n expected e
Answer e expected a
Answer e expected e
Answer b expected b
Answer d expected d
Answer e expected e
Answer e expected e
Answer b expected b
Answer d expected d
Answer d expected d
Answer d expected b
Answer a expected a
Answer e expected a
Answer a expected a
Answer e expected e
Skipping the batch
Answer a expected a
Answer t expected b
Answer e expected e
Answer b expected b
Answer 
 expected a
Answer b expected b
Answer e expected e
Answer d expected d
Answer b expected c
Answer e expected e
Answer c expected c
Answer 
 expected b
Answer a expected a
Answer e expected e
Answer e expected e
Answer b expected b
Answer b expected b
Answer c expected c
Answer a expected d
Answer w expected d
Answer e expected e
Answer d expected d
Answer e expected e
Answer a expected d
Answer d expected d
Answer e expected e
Answer e expected a
Answer a expected a
Answer d expected d
Answer e expected e
Answer d expected d
Answer e expected e
Answer c expected c
Answer c expected b
Answer c expected b
Answer b expected b
Answer e expected e
Answer c expected a
Answer c expected c
Answer n expected d
Answer a expected a
Answer b expected b
Answer d expected d
Answer 
 expected d
Answer e expected a
Answer e expected d
Answer e expected a
Answer c expected c
Answer a expected a
Answer a expected a
Answer o expected d
Answer a expected b
Answer e expected e
Answer e expected e
Answer b expected b
Skipping the batch
Answer c expected c
Answer 
 expected a
Answer c expected c
Answer b expected b
Answer a expected a
Answer e expected e
Answer e expected e
Answer b expected b
Answer r expected b
Answer a expected a
Answer b expected b
Answer c expected c
Answer b expected b
Answer d expected d
Answer e expected e
Answer 
 expected c
Answer e expected e
Answer d expected e
Skipping the batch
Answer a expected a
Answer d expected d
Answer c expected a
Answer t expected d
Answer c expected c
Answer d expected d
Answer d expected d
Answer d expected d
Answer e expected e
Answer e expected b
Answer e expected b
Answer b expected b
Answer c expected e
Answer a expected a
Answer n expected d
Answer a expected a
Answer b expected b
Answer b expected b
Answer d expected b
Answer e expected e
Answer d expected d
Answer e expected e
Answer b expected b
index 7 start communication
Answer e expected c
index 6 start communication
Answer e expected e
index 3 start communication
Answer b expected b
index 0 start communication
index 2 start communication
index 1 start communication
index 4 start communication
index 5 start communication
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
+--------+----------------+---------------------------+-----------------------------+
| Task   |   Num Sentence |   Total Generation Length |   Average Generation Length |
+========+================+===========================+=============================+
| csqa   |           1221 |                    126440 |                     103.554 |
+--------+----------------+---------------------------+-----------------------------+
Namespace(tasks='csqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device='cuda:0', limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
+--------+---------+-----------+--------------+
| Task   |   Total |   Correct |   Solve Rate |
+========+=========+===========+==============+
| csqa   |    1221 |       833 |     0.682228 |
+--------+---------+-----------+--------------+
