Already on 'yangexppp'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-08-03:04:48:36,936 INFO     [main.py:288] Verbosity set to INFO
2024-08-03:04:48:46,765 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-08-03:04:48:46,798 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-08-03:04:48:46,798 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-70B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1500, 'kernel_size': 16, 'thr': 0.05}
2024-08-03:04:48:46,808 INFO     [xhuggingface.py:176] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:05<02:37,  5.44s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:10<02:33,  5.46s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:16<02:30,  5.58s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:22<02:26,  5.65s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:27<02:18,  5.55s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:33<02:11,  5.47s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:38<02:05,  5.44s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:44<02:01,  5.51s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:49<01:56,  5.54s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:55<01:49,  5.48s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [01:00<01:43,  5.42s/it]Loading checkpoint shards:  40%|████      | 12/30 [01:05<01:37,  5.39s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [01:11<01:33,  5.49s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [01:17<01:28,  5.53s/it]Loading checkpoint shards:  50%|█████     | 15/30 [01:22<01:22,  5.48s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [01:27<01:15,  5.41s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [01:32<01:09,  5.36s/it]Loading checkpoint shards:  60%|██████    | 18/30 [01:38<01:05,  5.44s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [01:44<01:00,  5.48s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [01:49<00:54,  5.43s/it]Loading checkpoint shards:  70%|███████   | 21/30 [01:54<00:49,  5.46s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [02:00<00:43,  5.46s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [02:06<00:38,  5.53s/it]Loading checkpoint shards:  80%|████████  | 24/30 [02:11<00:33,  5.59s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [02:18<00:29,  5.83s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [02:23<00:22,  5.67s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [02:28<00:16,  5.55s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [02:34<00:11,  5.57s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [02:39<00:05,  5.58s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:42<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:42<00:00,  5.42s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-08-03:04:51:35,654 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-03:04:51:35,654 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-03:04:51:35,755 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 0...
  0%|          | 0/1319 [00:00<?, ?it/s] 13%|█▎        | 169/1319 [00:00<00:00, 1689.39it/s] 26%|██▌       | 339/1319 [00:00<00:00, 1693.91it/s] 39%|███▊      | 509/1319 [00:00<00:00, 1696.26it/s] 51%|█████▏    | 679/1319 [00:00<00:00, 1695.68it/s] 64%|██████▍   | 849/1319 [00:00<00:00, 1693.73it/s] 77%|███████▋  | 1019/1319 [00:00<00:00, 1694.22it/s] 90%|█████████ | 1190/1319 [00:00<00:00, 1698.75it/s]100%|██████████| 1319/1319 [00:00<00:00, 1697.07it/s]
2024-08-03:04:51:36,557 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 1/1319 [00:57<20:55:47, 57.17s/it]Running generate_until requests:   0%|          | 2/1319 [01:36<17:00:41, 46.50s/it]Running generate_until requests:   0%|          | 3/1319 [02:13<15:32:27, 42.51s/it]Running generate_until requests:   0%|          | 4/1319 [02:59<15:58:50, 43.75s/it]Running generate_until requests:   0%|          | 5/1319 [03:57<17:51:48, 48.94s/it]Running generate_until requests:   0%|          | 6/1319 [04:49<18:09:48, 49.80s/it]Running generate_until requests:   1%|          | 7/1319 [05:28<16:54:42, 46.40s/it]Running generate_until requests:   1%|          | 8/1319 [06:12<16:38:56, 45.72s/it]Running generate_until requests:   1%|          | 9/1319 [06:46<15:14:58, 41.91s/it]Running generate_until requests:   1%|          | 10/1319 [07:30<15:28:54, 42.58s/it]Running generate_until requests:   1%|          | 11/1319 [08:08<14:57:15, 41.16s/it]Running generate_until requests:   1%|          | 12/1319 [09:11<17:19:24, 47.72s/it]Running generate_until requests:   1%|          | 13/1319 [09:49<16:18:29, 44.95s/it]Running generate_until requests:   1%|          | 14/1319 [10:16<14:15:42, 39.34s/it]Running generate_until requests:   1%|          | 15/1319 [10:59<14:42:40, 40.61s/it]Running generate_until requests:   1%|          | 16/1319 [11:29<13:31:12, 37.35s/it]Running generate_until requests:   1%|▏         | 17/1319 [12:15<14:24:34, 39.84s/it]Running generate_until requests:   1%|▏         | 18/1319 [13:06<15:36:36, 43.19s/it]