Already on 'yangexppp'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-08-03:04:48:36,936 INFO     [main.py:288] Verbosity set to INFO
2024-08-03:04:48:46,765 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-08-03:04:48:46,798 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-08-03:04:48:46,798 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-70B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1500, 'kernel_size': 16, 'thr': 0.05}
2024-08-03:04:48:46,808 INFO     [xhuggingface.py:176] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:05<02:37,  5.44s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:10<02:33,  5.46s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:16<02:30,  5.58s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:22<02:26,  5.65s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:27<02:18,  5.55s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:33<02:11,  5.47s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:38<02:05,  5.44s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:44<02:01,  5.51s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:49<01:56,  5.54s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:55<01:49,  5.48s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [01:00<01:43,  5.42s/it]Loading checkpoint shards:  40%|████      | 12/30 [01:05<01:37,  5.39s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [01:11<01:33,  5.49s/it]