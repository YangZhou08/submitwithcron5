Your branch is up to date with 'origin/addinggriffin'.
Already up to date.
Already up to date.
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /data/home/beidic/.cache/huggingface/token
Login successful
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
We now use eos_token as pad token
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
We now use eos_token as pad token
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
is_distributed TrueNamespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)

Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
tasks ['strategyqa']
tasks ['strategyqa']tasks ['strategyqa']

tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
Answer yes expected no
Answer no expected no
Answer no expected no
Answer yes expected yes
Skipping the batch
Answer no expected no
Answer no expected no
Answer yes expected yes
Answer yes expected yes
Answer no expected yes
Answer yes expected no
Answer no expected no
Skipping the batch
Answer no expected no
Skipping the batch
Answer yes expected yes
Skipping the batch
Answer no expected yes
Answer no expected yes
Answer no expected yes
Answer yes expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer yes expected yes
Answer yes expected no
Answer no expected no
Answer no expected no
Answer no expected yes
Answer yes expected no
Answer no expected no
Skipping the batch
Answer yes expected no
Answer no expected no
Skipping the batch
Answer yes expected yes
Answer no expected no
Skipping the batch
Answer no expected no
Answer yes expected yes
Answer no expected no
Answer no expected no
Answer no expected no
Answer yes expected yes
Answer yes expected yes
Answer no expected no
index 1 start communication
index 5 start communication
Answer  name when he was born. his father was named gaius octavius. his mother was named atia. his father died when he was very young. his mother remarried to marcus atius balbus. his mother's second husband adopted him. his name became gaius octavius thurinus. he was known as octavius. he was known as octavius because his mother's second husband was named gaius octavius. his mother's second husband was also his stepfather. his mother's second husband was also his stepbrother. his mother's second husband was also his stepuncle. his mother's second husband was also his stepgrandfather. his mother's second husband was also his stepgranduncle. his mother's second husband was also his stepgreat-grandfather. his mother's second husband was also his stepgreat-granduncle. his mother's second husband was also his stepgreat-great-grandfather. his mother's second husband was also his stepgreat-great-granduncle. his mother's second husband was also his stepgreat-great expected no
index 6 start communication
index 7 start communication
Answer no expected no
Answer yes expected yes
Answer no expected no
Answer no expected no
index 4 start communication
Answer no expected no
Answer yes expected no
index 3 start communication
Answer yes expected yes
Answer yes expected yes
Answer no expected yes
Answer no expected no
Answer yes expected yes
Answer yes expected yes
index 2 start communication
Answer yes expected no
Answer no expected no
index 0 start communication
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
+------------+----------------+---------------------------+-----------------------------+
| Task       |   Num Sentence |   Total Generation Length |   Average Generation Length |
+============+================+===========================+=============================+
| strategyqa |            457 |                     22512 |                     49.2604 |
+------------+----------------+---------------------------+-----------------------------+
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-13b-hf', device='cuda:0', limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
+------------+---------+-----------+--------------+
| Task       |   Total |   Correct |   Solve Rate |
+============+=========+===========+==============+
| strategyqa |     457 |       317 |     0.693654 |
+------------+---------+-----------+--------------+
