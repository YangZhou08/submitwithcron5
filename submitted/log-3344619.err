wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.60s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.10s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.05s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.09s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.08s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.77s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.70s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.48s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.77s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.09s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.78s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.63s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.80s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.79s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.89s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [01:00<20:01, 60.06s/it]  5%|▍         | 1/21 [01:00<20:02, 60.13s/it]  5%|▍         | 1/21 [01:00<20:02, 60.13s/it]  5%|▍         | 1/21 [00:58<19:31, 58.58s/it]  5%|▍         | 1/21 [00:43<14:26, 43.34s/it]  5%|▍         | 1/21 [00:43<14:34, 43.75s/it]  5%|▍         | 1/21 [00:59<19:57, 59.85s/it]  5%|▍         | 1/21 [00:58<19:27, 58.36s/it] 10%|▉         | 2/21 [01:29<13:13, 41.77s/it] 10%|▉         | 2/21 [01:29<13:13, 41.77s/it] 10%|▉         | 2/21 [01:28<13:13, 41.74s/it] 10%|▉         | 2/21 [01:27<13:01, 41.14s/it] 10%|▉         | 2/21 [01:27<12:59, 41.04s/it] 10%|▉         | 2/21 [01:12<11:02, 34.86s/it] 10%|▉         | 2/21 [01:12<11:05, 35.03s/it] 10%|▉         | 2/21 [01:28<13:11, 41.66s/it] 14%|█▍        | 3/21 [01:57<10:48, 36.04s/it] 14%|█▍        | 3/21 [01:58<10:54, 36.37s/it] 14%|█▍        | 3/21 [01:59<10:54, 36.39s/it] 14%|█▍        | 3/21 [01:59<10:54, 36.39s/it] 14%|█▍        | 3/21 [01:57<10:47, 35.99s/it] 14%|█▍        | 3/21 [01:42<09:47, 32.63s/it] 14%|█▍        | 3/21 [01:42<09:48, 32.72s/it] 14%|█▍        | 3/21 [01:58<10:53, 36.33s/it] 19%|█▉        | 4/21 [02:30<09:42, 34.25s/it] 19%|█▉        | 4/21 [02:29<09:42, 34.24s/it] 19%|█▉        | 4/21 [02:13<09:03, 31.98s/it] 19%|█▉        | 4/21 [02:30<09:42, 34.25s/it] 19%|█▉        | 4/21 [02:28<09:38, 34.04s/it] 19%|█▉        | 4/21 [02:29<09:41, 34.21s/it] 19%|█▉        | 4/21 [02:13<09:04, 32.03s/it] 19%|█▉        | 4/21 [02:28<09:38, 34.01s/it] 24%|██▍       | 5/21 [03:12<09:57, 37.32s/it] 24%|██▍       | 5/21 [03:12<09:57, 37.32s/it] 24%|██▍       | 5/21 [03:12<09:57, 37.32s/it] 24%|██▍       | 5/21 [03:11<09:54, 37.17s/it] 24%|██▍       | 5/21 [02:56<09:34, 35.91s/it] 24%|██▍       | 5/21 [03:11<09:55, 37.19s/it] 24%|██▍       | 5/21 [03:12<09:56, 37.30s/it] 24%|██▍       | 5/21 [02:55<09:33, 35.87s/it] 29%|██▊       | 6/21 [03:43<08:50, 35.40s/it] 29%|██▊       | 6/21 [03:44<08:52, 35.47s/it] 29%|██▊       | 6/21 [03:42<08:50, 35.38s/it] 29%|██▊       | 6/21 [03:44<08:52, 35.49s/it] 29%|██▊       | 6/21 [03:27<08:37, 34.53s/it] 29%|██▊       | 6/21 [03:44<08:52, 35.48s/it] 29%|██▊       | 6/21 [03:44<08:52, 35.49s/it] 29%|██▊       | 6/21 [03:28<08:38, 34.55s/it] 33%|███▎      | 7/21 [04:17<08:06, 34.72s/it] 33%|███▎      | 7/21 [04:17<08:06, 34.72s/it] 33%|███▎      | 7/21 [04:17<08:06, 34.72s/it] 33%|███▎      | 7/21 [04:16<08:05, 34.66s/it] 33%|███▎      | 7/21 [04:17<08:05, 34.71s/it] 33%|███▎      | 7/21 [04:01<07:57, 34.09s/it] 33%|███▎      | 7/21 [04:01<07:57, 34.07s/it] 33%|███▎      | 7/21 [04:16<08:05, 34.65s/it] 38%|███▊      | 8/21 [04:45<07:02, 32.52s/it] 38%|███▊      | 8/21 [04:28<06:57, 32.09s/it] 38%|███▊      | 8/21 [04:43<07:02, 32.48s/it] 38%|███▊      | 8/21 [04:45<07:02, 32.53s/it] 38%|███▊      | 8/21 [04:45<07:02, 32.53s/it] 38%|███▊      | 8/21 [04:45<07:02, 32.53s/it] 38%|███▊      | 8/21 [04:29<06:57, 32.10s/it] 38%|███▊      | 8/21 [04:44<07:02, 32.49s/it] 43%|████▎     | 9/21 [05:12<06:15, 31.30s/it] 43%|████▎     | 9/21 [05:12<06:15, 31.30s/it] 43%|████▎     | 9/21 [05:14<06:15, 31.32s/it] 43%|████▎     | 9/21 [05:14<06:15, 31.33s/it] 43%|████▎     | 9/21 [05:14<06:15, 31.33s/it] 43%|████▎     | 9/21 [04:57<06:12, 31.03s/it] 43%|████▎     | 9/21 [04:57<06:12, 31.03s/it] 43%|████▎     | 9/21 [05:14<06:15, 31.33s/it] 48%|████▊     | 10/21 [05:50<06:01, 32.84s/it] 48%|████▊     | 10/21 [05:50<06:01, 32.83s/it] 48%|████▊     | 10/21 [05:50<06:01, 32.84s/it] 48%|████▊     | 10/21 [05:50<06:01, 32.83s/it] 48%|████▊     | 10/21 [05:48<06:00, 32.81s/it] 48%|████▊     | 10/21 [05:33<05:58, 32.63s/it] 48%|████▊     | 10/21 [05:34<05:58, 32.63s/it] 48%|████▊     | 10/21 [05:49<06:00, 32.82s/it] 52%|█████▏    | 11/21 [06:12<05:00, 30.08s/it] 52%|█████▏    | 11/21 [06:14<05:00, 30.09s/it] 52%|█████▏    | 11/21 [05:57<04:59, 29.95s/it] 52%|█████▏    | 11/21 [06:12<05:00, 30.08s/it] 52%|█████▏    | 11/21 [06:14<05:00, 30.09s/it] 52%|█████▏    | 11/21 [06:14<05:00, 30.09s/it] 52%|█████▏    | 11/21 [06:14<05:00, 30.09s/it] 52%|█████▏    | 11/21 [05:58<04:59, 29.95s/it] 57%|█████▋    | 12/21 [07:06<05:33, 37.11s/it] 57%|█████▋    | 12/21 [07:07<05:34, 37.11s/it] 57%|█████▋    | 12/21 [07:05<05:33, 37.10s/it] 57%|█████▋    | 12/21 [07:07<05:34, 37.11s/it] 57%|█████▋    | 12/21 [06:51<05:33, 37.02s/it] 57%|█████▋    | 12/21 [06:50<05:33, 37.01s/it] 57%|█████▋    | 12/21 [07:07<05:34, 37.12s/it] 57%|█████▋    | 12/21 [07:07<05:34, 37.12s/it] 62%|██████▏   | 13/21 [07:36<04:37, 34.74s/it] 62%|██████▏   | 13/21 [07:36<04:37, 34.74s/it] 62%|██████▏   | 13/21 [07:20<04:37, 34.68s/it] 62%|██████▏   | 13/21 [07:36<04:37, 34.74s/it] 62%|██████▏   | 13/21 [07:35<04:37, 34.74s/it] 62%|██████▏   | 13/21 [07:35<04:37, 34.74s/it] 62%|██████▏   | 13/21 [07:36<04:37, 34.74s/it] 62%|██████▏   | 13/21 [07:20<04:37, 34.67s/it] 67%|██████▋   | 14/21 [08:21<04:27, 38.22s/it] 67%|██████▋   | 14/21 [08:21<04:27, 38.22s/it] 67%|██████▋   | 14/21 [08:23<04:27, 38.22s/it] 67%|██████▋   | 14/21 [08:23<04:27, 38.22s/it] 67%|██████▋   | 14/21 [08:22<04:27, 38.22s/it] 67%|██████▋   | 14/21 [08:23<04:27, 38.22s/it] 67%|██████▋   | 14/21 [08:06<04:27, 38.17s/it] 67%|██████▋   | 14/21 [08:06<04:27, 38.17s/it] 71%|███████▏  | 15/21 [08:56<03:41, 36.85s/it] 71%|███████▏  | 15/21 [08:55<03:41, 36.84s/it] 71%|███████▏  | 15/21 [08:40<03:40, 36.81s/it] 71%|███████▏  | 15/21 [08:56<03:41, 36.85s/it] 71%|███████▏  | 15/21 [08:56<03:41, 36.85s/it] 71%|███████▏  | 15/21 [08:56<03:41, 36.85s/it] 71%|███████▏  | 15/21 [08:40<03:40, 36.81s/it] 71%|███████▏  | 15/21 [08:55<03:41, 36.84s/it] 76%|███████▌  | 16/21 [09:31<03:02, 36.57s/it] 76%|███████▌  | 16/21 [09:32<03:02, 36.57s/it] 76%|███████▌  | 16/21 [09:32<03:02, 36.57s/it] 76%|███████▌  | 16/21 [09:31<03:02, 36.57s/it] 76%|███████▌  | 16/21 [09:16<03:02, 36.55s/it] 76%|███████▌  | 16/21 [09:32<03:02, 36.57s/it] 76%|███████▌  | 16/21 [09:32<03:02, 36.57s/it] 76%|███████▌  | 16/21 [09:15<03:02, 36.55s/it] 81%|████████  | 17/21 [10:04<02:20, 35.20s/it] 81%|████████  | 17/21 [10:04<02:20, 35.20s/it] 81%|████████  | 17/21 [10:04<02:20, 35.20s/it] 81%|████████  | 17/21 [10:03<02:20, 35.20s/it] 81%|████████  | 17/21 [10:03<02:20, 35.20s/it] 81%|████████  | 17/21 [10:04<02:20, 35.20s/it] 81%|████████  | 17/21 [09:48<02:20, 35.19s/it] 81%|████████  | 17/21 [09:47<02:20, 35.18s/it] 86%|████████▌ | 18/21 [10:51<01:55, 38.56s/it] 86%|████████▌ | 18/21 [10:51<01:55, 38.56s/it] 86%|████████▌ | 18/21 [10:51<01:55, 38.56s/it] 86%|████████▌ | 18/21 [10:50<01:55, 38.56s/it] 86%|████████▌ | 18/21 [10:34<01:55, 38.55s/it] 86%|████████▌ | 18/21 [10:34<01:55, 38.55s/it] 86%|████████▌ | 18/21 [10:49<01:55, 38.56s/it] 86%|████████▌ | 18/21 [10:49<01:55, 38.56s/it] 90%|█████████ | 19/21 [11:18<01:10, 35.38s/it] 90%|█████████ | 19/21 [11:17<01:10, 35.38s/it] 90%|█████████ | 19/21 [11:02<01:10, 35.37s/it] 90%|█████████ | 19/21 [11:17<01:10, 35.38s/it] 90%|█████████ | 19/21 [11:19<01:10, 35.38s/it] 90%|█████████ | 19/21 [11:19<01:10, 35.38s/it] 90%|█████████ | 19/21 [11:02<01:10, 35.37s/it] 90%|█████████ | 19/21 [11:19<01:10, 35.38s/it] 95%|█████████▌| 20/21 [12:00<00:37, 37.69s/it] 95%|█████████▌| 20/21 [12:01<00:37, 37.69s/it] 95%|█████████▌| 20/21 [12:00<00:37, 37.69s/it] 95%|█████████▌| 20/21 [11:45<00:37, 37.69s/it] 95%|█████████▌| 20/21 [12:02<00:37, 37.69s/it] 95%|█████████▌| 20/21 [11:45<00:37, 37.69s/it] 95%|█████████▌| 20/21 [12:02<00:37, 37.69s/it] 95%|█████████▌| 20/21 [12:02<00:37, 37.69s/it]100%|██████████| 21/21 [12:44<00:00, 39.55s/it]100%|██████████| 21/21 [12:45<00:00, 39.55s/it]100%|██████████| 21/21 [12:44<00:00, 39.55s/it]100%|██████████| 21/21 [12:29<00:00, 39.54s/it]100%|██████████| 21/21 [12:46<00:00, 39.55s/it]100%|██████████| 21/21 [12:46<00:00, 39.55s/it]100%|██████████| 21/21 [12:46<00:00, 39.55s/it]100%|██████████| 21/21 [12:29<00:00, 39.54s/it]22it [13:31, 41.90s/it]                        22it [13:31, 41.90s/it]                        22it [13:17, 41.89s/it]                        22it [13:33, 41.90s/it]                        22it [13:33, 41.90s/it]                        22it [13:33, 41.90s/it]                        22it [13:33, 41.90s/it]                        22it [13:16, 41.89s/it]                        23it [14:05, 38.82s/it]23it [14:05, 38.82s/it]23it [14:05, 38.82s/it]23it [14:04, 38.82s/it]23it [14:03, 38.82s/it]23it [14:03, 38.82s/it]23it [13:48, 38.82s/it]23it [13:48, 38.82s/it]24it [14:34, 36.64s/it]24it [14:35, 36.64s/it]24it [14:19, 36.64s/it]24it [14:36, 36.64s/it]24it [14:20, 36.64s/it]24it [14:36, 36.65s/it]24it [14:36, 36.65s/it]24it [14:36, 36.65s/it]25it [15:01, 32.98s/it]25it [15:01, 32.98s/it]25it [15:01, 32.98s/it]25it [14:44, 32.97s/it]25it [14:59, 32.98s/it]25it [14:59, 32.98s/it]25it [15:00, 32.98s/it]25it [14:44, 32.97s/it]26it [15:27, 31.14s/it]26it [15:11, 31.14s/it]26it [15:26, 31.14s/it]26it [15:26, 31.14s/it]26it [15:27, 31.14s/it]26it [15:27, 31.14s/it]26it [15:11, 31.14s/it]26it [15:27, 31.14s/it]27it [16:03, 33.01s/it]27it [16:05, 33.01s/it]27it [16:05, 33.01s/it]27it [16:03, 33.01s/it]27it [15:48, 33.01s/it]27it [16:05, 33.01s/it]27it [15:48, 33.01s/it]27it [16:05, 33.01s/it]28it [16:25, 29.26s/it]28it [16:25, 29.26s/it]28it [16:25, 29.26s/it]28it [16:25, 29.26s/it]28it [16:09, 29.26s/it]28it [16:24, 29.26s/it]28it [16:24, 29.26s/it]28it [16:09, 29.26s/it]29it [16:46, 26.77s/it]29it [16:45, 26.77s/it]29it [16:30, 26.77s/it]29it [16:46, 26.77s/it]29it [16:46, 26.77s/it]29it [16:45, 26.77s/it]29it [16:46, 26.77s/it]29it [16:30, 26.77s/it]30it [17:09, 25.92s/it]30it [17:10, 25.92s/it]30it [16:53, 25.92s/it]30it [17:10, 25.92s/it]30it [17:10, 25.92s/it]30it [17:08, 25.92s/it]30it [17:10, 25.92s/it]30it [16:54, 25.92s/it]31it [17:34, 30.17s/it]31it [17:34, 30.17s/it]31it [17:49, 30.17s/it]31it [17:49, 30.17s/it]31it [17:50, 30.17s/it]31it [17:50, 30.17s/it]31it [17:50, 30.17s/it]31it [17:50, 30.17s/it]32it [18:13, 27.82s/it]32it [17:56, 27.82s/it]32it [18:12, 27.82s/it]32it [18:11, 27.82s/it]32it [18:11, 27.82s/it]32it [17:56, 27.82s/it]32it [18:13, 27.82s/it]32it [18:13, 27.82s/it]33it [18:59, 33.85s/it]33it [19:01, 33.85s/it]33it [19:00, 33.85s/it]33it [19:01, 33.85s/it]33it [18:59, 33.85s/it]33it [18:44, 33.85s/it]33it [19:01, 33.85s/it]33it [18:44, 33.85s/it]34it [19:27, 31.69s/it]34it [19:27, 31.69s/it]34it [19:11, 31.69s/it]34it [19:27, 31.69s/it]34it [19:26, 31.69s/it]34it [19:25, 31.69s/it]34it [19:10, 31.69s/it]34it [19:27, 31.69s/it]35it [20:18, 37.53s/it]35it [20:18, 37.53s/it]35it [20:18, 37.53s/it]35it [20:17, 37.53s/it]35it [20:18, 37.53s/it]35it [20:17, 37.53s/it]35it [20:02, 37.53s/it]35it [20:02, 37.53s/it]36it [20:40, 37.73s/it]36it [20:55, 37.73s/it]36it [20:55, 37.73s/it]36it [20:56, 37.73s/it]36it [20:57, 37.73s/it]36it [20:57, 37.73s/it]36it [20:57, 37.73s/it]36it [20:40, 37.73s/it]37it [21:30, 36.54s/it]37it [21:30, 36.54s/it]37it [21:30, 36.54s/it]37it [21:14, 36.54s/it]37it [21:29, 36.54s/it]37it [21:30, 36.54s/it]37it [21:29, 36.54s/it]37it [21:14, 36.54s/it]38it [21:54, 33.09s/it]38it [21:55, 33.09s/it]38it [21:39, 33.09s/it]38it [21:54, 33.09s/it]38it [21:55, 33.09s/it]38it [21:55, 33.09s/it]38it [21:55, 33.09s/it]38it [21:39, 33.09s/it]39it [22:21, 30.76s/it]39it [22:21, 30.76s/it]39it [22:21, 30.76s/it]39it [22:04, 30.76s/it]39it [22:19, 30.76s/it]39it [22:20, 30.76s/it]39it [22:04, 30.76s/it]39it [22:19, 30.76s/it]40it [22:43, 28.82s/it]40it [22:43, 28.82s/it]40it [22:45, 28.82s/it]40it [22:29, 28.82s/it]40it [22:28, 28.82s/it]40it [22:45, 28.82s/it]40it [22:45, 28.82s/it]40it [22:45, 28.82s/it]41it [23:32, 34.14s/it]41it [23:31, 34.14s/it]41it [23:30, 34.14s/it]41it [23:31, 34.14s/it]41it [23:30, 34.14s/it]41it [23:15, 34.14s/it]41it [23:15, 34.14s/it]41it [23:32, 34.14s/it]41it [23:32, 34.44s/it]41it [23:31, 34.44s/it]41it [23:30, 34.40s/it]41it [23:30, 34.40s/it]41it [23:31, 34.43s/it]




41it [23:15, 34.04s/it]41it [23:32, 34.44s/it]

41it [23:15, 34.03s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
