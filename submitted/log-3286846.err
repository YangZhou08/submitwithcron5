error: Unable to create '/fsx-storygen/beidic/yang/GRIFFIN2/.git/index.lock': File exists.

Another git process seems to be running in this repository, e.g.
an editor opened by 'git commit'. Please make sure all processes
are terminated then try again. If it still fails, a git process
may have crashed in this repository earlier:
remove the file manually to continue.
fatal: Unable to create '/fsx-storygen/beidic/yang/GRIFFIN2/.git/index.lock': File exists.

Another git process seems to be running in this repository, e.g.
an editor opened by 'git commit'. Please make sure all processes
are terminated then try again. If it still fails, a git process
may have crashed in this repository earlier:
remove the file manually to continue.
Your configuration specifies to merge with the ref 'refs/heads/yangexp2two'
from the remote, but no such ref was fetched.
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-06:21:00:41,285 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:41,285 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:41,285 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:41,285 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:41,285 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:41,286 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:50,549 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:00:50,549 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:00:50,549 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:00:50,549 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:00:50,549 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:00:50,550 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:00:50,551 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:50,551 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:50,551 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:50,551 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:50,551 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:50,551 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:50,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:50,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:50,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:50,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:50,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:50,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.001, 'patternstrict': True}
2024-07-06:21:00:50,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.001, 'patternstrict': True}
2024-07-06:21:00:50,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.001, 'patternstrict': True}
2024-07-06:21:00:50,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.001, 'patternstrict': True}
2024-07-06:21:00:50,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.001, 'patternstrict': True}
2024-07-06:21:00:50,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:50,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.001, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:05, 21.98s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:09, 23.02s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.54s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.57s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.73s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.59s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:42<00:41, 20.85s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:43<00:42, 21.31s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:42<00:42, 21.13s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:42<00:42, 21.14s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:42<00:42, 21.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:42<00:42, 21.14s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.48s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.76s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.88s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.78s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.94s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 12.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 15.62s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 12.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 15.56s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 12.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 15.55s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 12.59s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 15.55s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 12.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 15.55s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 12.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 15.59s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:02:40,469 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:02:40,571 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:02:40,583 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:02:40,599 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:02:40,659 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:02:40,729 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:02:41,906 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
2024-07-06:21:02:41,908 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:21:02:41,989 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:21:02:42,011 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
 29%|██▉       | 19/66 [00:00<00:00, 188.74it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.27it/s]  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.08it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.60it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.18it/s] 30%|███       | 20/66 [00:00<00:00, 190.46it/s]2024-07-06:21:02:42,164 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/66 [00:00<?, ?it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.84it/s] 89%|████████▉ | 59/66 [00:00<00:00, 190.46it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.64it/s] 61%|██████    | 40/66 [00:00<00:00, 191.98it/s]100%|██████████| 66/66 [00:00<00:00, 191.45it/s]
100%|██████████| 66/66 [00:00<00:00, 190.47it/s]
 29%|██▉       | 19/66 [00:00<00:00, 188.12it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.13it/s]100%|██████████| 66/66 [00:00<00:00, 191.03it/s]
 91%|█████████ | 60/66 [00:00<00:00, 179.00it/s] 58%|█████▊    | 38/66 [00:00<00:00, 188.04it/s]100%|██████████| 66/66 [00:00<00:00, 182.14it/s]
 86%|████████▋ | 57/66 [00:00<00:00, 185.83it/s]100%|██████████| 66/66 [00:00<00:00, 183.80it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:02:43,942 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:02:45,248 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 186.69it/s] 59%|█████▉    | 39/66 [00:00<00:00, 189.34it/s] 89%|████████▉ | 59/66 [00:00<00:00, 189.97it/s]100%|██████████| 66/66 [00:00<00:00, 189.74it/s]
2024-07-06:21:02:58,734 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:02:58,734 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:02:58,734 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:02:58,734 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:02:58,735 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:02:58,736 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/66 [00:00<?, ?it/s]Running generate_until requests:   2%|▏         | 1/66 [00:18<20:34, 19.00s/it]Running generate_until requests:   3%|▎         | 2/66 [00:28<14:10, 13.30s/it]Running generate_until requests:   5%|▍         | 3/66 [00:45<15:55, 15.16s/it]Running generate_until requests:   6%|▌         | 4/66 [01:03<16:44, 16.19s/it]Running generate_until requests:   8%|▊         | 5/66 [01:11<13:21, 13.13s/it]Running generate_until requests:   9%|▉         | 6/66 [01:31<15:25, 15.43s/it]Running generate_until requests:  11%|█         | 7/66 [01:50<16:34, 16.85s/it]Running generate_until requests:  12%|█▏        | 8/66 [02:14<18:25, 19.06s/it]Running generate_until requests:  14%|█▎        | 9/66 [02:48<22:36, 23.79s/it]Running generate_until requests:  15%|█▌        | 10/66 [02:58<18:00, 19.29s/it]Running generate_until requests:  17%|█▋        | 11/66 [03:26<20:15, 22.10s/it]Running generate_until requests:  18%|█▊        | 12/66 [03:35<16:13, 18.03s/it]Running generate_until requests:  20%|█▉        | 13/66 [04:06<19:30, 22.08s/it]Running generate_until requests:  21%|██        | 14/66 [04:26<18:33, 21.42s/it]Running generate_until requests:  23%|██▎       | 15/66 [04:39<15:58, 18.78s/it]Running generate_until requests:  24%|██▍       | 16/66 [04:49<13:30, 16.21s/it]Running generate_until requests:  26%|██▌       | 17/66 [05:01<12:07, 14.84s/it]Running generate_until requests:  27%|██▋       | 18/66 [05:13<11:14, 14.05s/it]Running generate_until requests:  29%|██▉       | 19/66 [05:28<11:11, 14.28s/it]Running generate_until requests:  30%|███       | 20/66 [05:39<10:20, 13.49s/it]Running generate_until requests:  32%|███▏      | 21/66 [05:51<09:49, 13.11s/it]Running generate_until requests:  33%|███▎      | 22/66 [06:05<09:37, 13.12s/it]Running generate_until requests:  35%|███▍      | 23/66 [06:26<11:09, 15.57s/it]Running generate_until requests:  36%|███▋      | 24/66 [06:35<09:35, 13.70s/it]Running generate_until requests:  38%|███▊      | 25/66 [07:07<12:58, 18.98s/it]Running generate_until requests:  39%|███▉      | 26/66 [07:19<11:24, 17.11s/it]Running generate_until requests:  41%|████      | 27/66 [07:46<12:57, 19.92s/it]Running generate_until requests:  42%|████▏     | 28/66 [08:00<11:37, 18.35s/it]Running generate_until requests:  44%|████▍     | 29/66 [08:20<11:28, 18.62s/it]Running generate_until requests:  45%|████▌     | 30/66 [08:26<08:55, 14.89s/it]Running generate_until requests:  47%|████▋     | 31/66 [08:34<07:30, 12.87s/it]Running generate_until requests:  48%|████▊     | 32/66 [08:51<07:56, 14.02s/it]Running generate_until requests:  50%|█████     | 33/66 [09:28<11:33, 21.01s/it]Running generate_until requests:  52%|█████▏    | 34/66 [09:36<09:08, 17.15s/it]Running generate_until requests:  53%|█████▎    | 35/66 [09:47<07:51, 15.20s/it]Running generate_until requests:  55%|█████▍    | 36/66 [10:32<12:08, 24.27s/it]Running generate_until requests:  56%|█████▌    | 37/66 [10:38<08:58, 18.58s/it]Running generate_until requests:  58%|█████▊    | 38/66 [10:46<07:17, 15.61s/it]Running generate_until requests:  59%|█████▉    | 39/66 [11:09<07:58, 17.73s/it]Running generate_until requests:  61%|██████    | 40/66 [11:25<07:25, 17.12s/it]Running generate_until requests:  62%|██████▏   | 41/66 [11:40<06:56, 16.67s/it]Running generate_until requests:  64%|██████▎   | 42/66 [12:11<08:17, 20.75s/it]Running generate_until requests:  65%|██████▌   | 43/66 [12:28<07:37, 19.87s/it]Running generate_until requests:  67%|██████▋   | 44/66 [12:36<05:59, 16.35s/it]Running generate_until requests:  68%|██████▊   | 45/66 [12:59<06:19, 18.09s/it]Running generate_until requests:  70%|██████▉   | 46/66 [13:38<08:10, 24.51s/it]Running generate_until requests:  71%|███████   | 47/66 [13:55<07:02, 22.24s/it]Running generate_until requests:  73%|███████▎  | 48/66 [14:05<05:31, 18.41s/it]Running generate_until requests:  74%|███████▍  | 49/66 [14:16<04:37, 16.34s/it]Running generate_until requests:  76%|███████▌  | 50/66 [14:37<04:45, 17.85s/it]Running generate_until requests:  77%|███████▋  | 51/66 [14:55<04:28, 17.91s/it]Running generate_until requests:  79%|███████▉  | 52/66 [15:06<03:41, 15.81s/it]Running generate_until requests:  80%|████████  | 53/66 [15:15<02:58, 13.77s/it]Running generate_until requests:  82%|████████▏ | 54/66 [15:31<02:52, 14.41s/it]Running generate_until requests:  83%|████████▎ | 55/66 [15:38<02:12, 12.03s/it]Running generate_until requests:  85%|████████▍ | 56/66 [15:58<02:25, 14.53s/it]Running generate_until requests:  86%|████████▋ | 57/66 [16:10<02:03, 13.73s/it]Running generate_until requests:  88%|████████▊ | 58/66 [16:14<01:26, 10.84s/it]Running generate_until requests:  89%|████████▉ | 59/66 [16:29<01:23, 11.95s/it]Running generate_until requests:  91%|█████████ | 60/66 [16:59<01:44, 17.36s/it]Running generate_until requests:  92%|█████████▏| 61/66 [17:03<01:06, 13.35s/it]Running generate_until requests:  94%|█████████▍| 62/66 [17:14<00:51, 12.89s/it]Running generate_until requests:  95%|█████████▌| 63/66 [17:27<00:38, 12.76s/it]Running generate_until requests:  97%|█████████▋| 64/66 [17:37<00:24, 12.03s/it]Running generate_until requests:  98%|█████████▊| 65/66 [17:54<00:13, 13.60s/it]Running generate_until requests: 100%|██████████| 66/66 [18:08<00:00, 13.49s/it]Running generate_until requests: 100%|██████████| 66/66 [18:08<00:00, 16.49s/it]
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-06:21:22:15,199 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:22:15,199 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:22:15,199 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:22:15,200 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:22:15,200 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:22:15,200 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:22:24,129 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:22:24,129 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:22:24,129 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:22:24,129 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:22:24,129 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:22:24,129 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:22:24,130 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:22:24,130 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:22:24,130 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:22:24,130 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:22:24,130 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:22:24,130 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:22:24,154 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:22:24,154 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:22:24,154 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:22:24,154 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:22:24,154 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:22:24,154 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.005, 'patternstrict': True}
2024-07-06:21:22:24,154 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.005, 'patternstrict': True}
2024-07-06:21:22:24,154 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.005, 'patternstrict': True}
2024-07-06:21:22:24,154 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.005, 'patternstrict': True}
2024-07-06:21:22:24,154 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.005, 'patternstrict': True}
2024-07-06:21:22:24,154 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:22:24,154 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.005, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.31s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:57, 19.25s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:56, 18.74s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:56, 18.76s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:56, 18.74s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:56, 18.75s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:35<00:35, 17.89s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:36, 18.09s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:36, 18.09s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:36, 18.33s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:36, 18.13s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:36, 18.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:52<00:17, 17.29s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.57s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.69s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.77s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.62s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.63s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 11.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.69s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.86s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.77s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 11.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.74s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 11.26s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.75s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 11.37s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.75s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:24:06,524 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:24:06,549 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:24:06,555 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:24:06,651 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:24:06,678 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:24:06,773 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:24:07,733 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
2024-07-06:21:24:07,735 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
2024-07-06:21:24:07,737 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:21:24:07,791 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.77it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.25it/s] 29%|██▉       | 19/66 [00:00<00:00, 187.32it/s] 30%|███       | 20/66 [00:00<00:00, 191.62it/s]2024-07-06:21:24:07,923 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/66 [00:00<?, ?it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.48it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.97it/s] 59%|█████▉    | 39/66 [00:00<00:00, 189.51it/s] 61%|██████    | 40/66 [00:00<00:00, 193.23it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.68it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.93it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.61it/s] 88%|████████▊ | 58/66 [00:00<00:00, 189.38it/s]100%|██████████| 66/66 [00:00<00:00, 191.76it/s]
100%|██████████| 66/66 [00:00<00:00, 189.63it/s]
100%|██████████| 66/66 [00:00<00:00, 189.44it/s]
 91%|█████████ | 60/66 [00:00<00:00, 193.67it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.25it/s]100%|██████████| 66/66 [00:00<00:00, 193.42it/s]
 89%|████████▉ | 59/66 [00:00<00:00, 191.28it/s]100%|██████████| 66/66 [00:00<00:00, 191.19it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:24:09,818 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:24:11,202 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 183.39it/s] 58%|█████▊    | 38/66 [00:00<00:00, 186.51it/s] 86%|████████▋ | 57/66 [00:00<00:00, 187.36it/s]100%|██████████| 66/66 [00:00<00:00, 187.08it/s]
2024-07-06:21:24:25,723 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:24:25,723 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:24:25,723 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:24:25,723 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:24:25,723 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:21:24:25,724 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   2%|▏         | 1/66 [00:20<21:50, 20.17s/it]Running generate_until requests:   3%|▎         | 2/66 [00:28<13:56, 13.07s/it]Running generate_until requests:   5%|▍         | 3/66 [00:33<09:54,  9.44s/it]Running generate_until requests:   6%|▌         | 4/66 [00:43<10:00,  9.68s/it]Running generate_until requests:   8%|▊         | 5/66 [00:51<09:05,  8.94s/it]Running generate_until requests:   9%|▉         | 6/66 [01:14<13:44, 13.75s/it]Running generate_until requests:  11%|█         | 7/66 [01:32<15:03, 15.31s/it]Running generate_until requests:  12%|█▏        | 8/66 [01:54<16:51, 17.44s/it]Running generate_until requests:  14%|█▎        | 9/66 [02:27<21:12, 22.33s/it]Running generate_until requests:  15%|█▌        | 10/66 [02:35<16:35, 17.77s/it]Running generate_until requests:  17%|█▋        | 11/66 [02:55<17:03, 18.62s/it]Running generate_until requests:  18%|█▊        | 12/66 [03:04<14:00, 15.56s/it]Running generate_until requests:  20%|█▉        | 13/66 [03:24<15:05, 17.08s/it]Running generate_until requests:  21%|██        | 14/66 [03:32<12:18, 14.20s/it]Running generate_until requests:  23%|██▎       | 15/66 [03:45<11:38, 13.69s/it]Running generate_until requests:  24%|██▍       | 16/66 [03:55<10:30, 12.61s/it]Running generate_until requests:  26%|██▌       | 17/66 [04:07<10:16, 12.59s/it]Running generate_until requests:  27%|██▋       | 18/66 [04:18<09:35, 11.98s/it]Running generate_until requests:  29%|██▉       | 19/66 [05:00<16:36, 21.19s/it]Running generate_until requests:  30%|███       | 20/66 [05:38<20:01, 26.12s/it]Running generate_until requests:  32%|███▏      | 21/66 [06:09<20:44, 27.66s/it]Running generate_until requests:  33%|███▎      | 22/66 [06:26<17:54, 24.43s/it]Running generate_until requests:  35%|███▍      | 23/66 [06:53<18:06, 25.26s/it]Running generate_until requests:  36%|███▋      | 24/66 [07:05<14:52, 21.26s/it]Running generate_until requests:  38%|███▊      | 25/66 [07:28<14:49, 21.69s/it]Running generate_until requests:  39%|███▉      | 26/66 [07:45<13:37, 20.44s/it]Running generate_until requests:  41%|████      | 27/66 [08:08<13:36, 20.93s/it]Running generate_until requests:  42%|████▏     | 28/66 [08:22<12:04, 19.07s/it]Running generate_until requests:  44%|████▍     | 29/66 [08:37<11:02, 17.91s/it]Running generate_until requests:  45%|████▌     | 30/66 [08:47<09:16, 15.45s/it]Running generate_until requests:  47%|████▋     | 31/66 [08:55<07:44, 13.27s/it]Running generate_until requests:  48%|████▊     | 32/66 [09:14<08:21, 14.74s/it]Running generate_until requests:  50%|█████     | 33/66 [09:25<07:36, 13.82s/it]Running generate_until requests:  52%|█████▏    | 34/66 [09:36<06:56, 13.00s/it]Running generate_until requests:  53%|█████▎    | 35/66 [09:46<06:16, 12.13s/it]Running generate_until requests:  55%|█████▍    | 36/66 [10:13<08:11, 16.38s/it]Running generate_until requests:  56%|█████▌    | 37/66 [10:18<06:17, 13.01s/it]Running generate_until requests:  58%|█████▊    | 38/66 [10:53<09:07, 19.54s/it]Running generate_until requests:  59%|█████▉    | 39/66 [11:17<09:22, 20.85s/it]Running generate_until requests:  61%|██████    | 40/66 [11:33<08:29, 19.58s/it]Running generate_until requests:  62%|██████▏   | 41/66 [11:49<07:43, 18.55s/it]Running generate_until requests:  64%|██████▎   | 42/66 [12:30<10:01, 25.08s/it]Running generate_until requests:  65%|██████▌   | 43/66 [12:46<08:34, 22.38s/it]Running generate_until requests:  67%|██████▋   | 44/66 [12:55<06:48, 18.58s/it]Running generate_until requests:  68%|██████▊   | 45/66 [13:17<06:49, 19.50s/it]Running generate_until requests:  70%|██████▉   | 46/66 [14:09<09:43, 29.19s/it]Running generate_until requests:  71%|███████   | 47/66 [14:20<07:34, 23.93s/it]Running generate_until requests:  73%|███████▎  | 48/66 [14:29<05:45, 19.18s/it]Running generate_until requests:  74%|███████▍  | 49/66 [14:39<04:39, 16.45s/it]Running generate_until requests:  76%|███████▌  | 50/66 [15:02<04:58, 18.64s/it]Running generate_until requests:  77%|███████▋  | 51/66 [15:21<04:38, 18.55s/it]Running generate_until requests:  79%|███████▉  | 52/66 [15:32<03:48, 16.30s/it]Running generate_until requests:  80%|████████  | 53/66 [15:45<03:19, 15.32s/it]Running generate_until requests:  82%|████████▏ | 54/66 [16:03<03:14, 16.19s/it]Running generate_until requests:  83%|████████▎ | 55/66 [16:10<02:26, 13.30s/it]Running generate_until requests:  85%|████████▍ | 56/66 [16:32<02:40, 16.07s/it]Running generate_until requests:  86%|████████▋ | 57/66 [16:42<02:08, 14.25s/it]Running generate_until requests:  88%|████████▊ | 58/66 [16:46<01:29, 11.19s/it]Running generate_until requests:  89%|████████▉ | 59/66 [16:56<01:15, 10.73s/it]Running generate_until requests:  91%|█████████ | 60/66 [17:13<01:15, 12.61s/it]Running generate_until requests:  92%|█████████▏| 61/66 [17:18<00:51, 10.37s/it]Running generate_until requests:  94%|█████████▍| 62/66 [17:38<00:52, 13.14s/it]Running generate_until requests:  95%|█████████▌| 63/66 [17:50<00:38, 12.95s/it]Running generate_until requests:  97%|█████████▋| 64/66 [18:01<00:24, 12.24s/it]Running generate_until requests:  98%|█████████▊| 65/66 [18:14<00:12, 12.60s/it]Running generate_until requests: 100%|██████████| 66/66 [18:28<00:00, 12.85s/it]Running generate_until requests: 100%|██████████| 66/66 [18:28<00:00, 16.79s/it]
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-06:21:44:34,426 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:44:34,426 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:44:34,426 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:44:34,426 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:44:34,426 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:44:34,426 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:44:43,473 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:44:43,473 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:44:43,474 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:44:43,474 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:44:43,476 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:44:43,477 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:44:43,478 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:44:43,478 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:44:43,480 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:44:43,481 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:21:44:43,481 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:44:43,482 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:44:43,498 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:44:43,498 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:44:43,498 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.01, 'patternstrict': True}
2024-07-06:21:44:43,498 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:44:43,498 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:44:43,498 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:44:43,499 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.01, 'patternstrict': True}
2024-07-06:21:44:43,499 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.01, 'patternstrict': True}
2024-07-06:21:44:43,499 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.01, 'patternstrict': True}
2024-07-06:21:44:43,499 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.01, 'patternstrict': True}
2024-07-06:21:44:43,499 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:44:43,499 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.15, 'thr': 0.01, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:00, 20.11s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.08s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.13s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.05s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.56s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.85s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:39<00:38, 19.25s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:39<00:38, 19.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:39<00:38, 19.32s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:39<00:38, 19.36s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:39<00:39, 19.52s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:55<00:18, 18.06s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:56<00:18, 18.52s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:56<00:18, 18.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:56<00:18, 18.78s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:56<00:18, 18.55s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:57<00:18, 18.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:57<00:00, 11.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:57<00:00, 14.43s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 11.71s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 14.50s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 11.71s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 14.50s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 11.86s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 14.50s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:57<00:00, 11.71s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:57<00:00, 14.50s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 11.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 14.66s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:46:29,346 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:46:29,476 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:46:29,508 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:46:29,526 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:46:29,594 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:46:30,867 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
2024-07-06:21:46:30,869 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:21:46:30,900 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:21:46:30,948 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.13it/s] 30%|███       | 20/66 [00:00<00:00, 190.39it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.80it/s]2024-07-06:21:46:31,034 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/66 [00:00<?, ?it/s] 30%|███       | 20/66 [00:00<00:00, 191.29it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.98it/s] 61%|██████    | 40/66 [00:00<00:00, 192.02it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.69it/s] 30%|███       | 20/66 [00:00<00:00, 190.47it/s] 61%|██████    | 40/66 [00:00<00:00, 192.67it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.44it/s] 91%|█████████ | 60/66 [00:00<00:00, 192.48it/s] 89%|████████▉ | 59/66 [00:00<00:00, 192.17it/s]100%|██████████| 66/66 [00:00<00:00, 192.28it/s]
100%|██████████| 66/66 [00:00<00:00, 191.28it/s]
100%|██████████| 66/66 [00:00<00:00, 191.99it/s]
 61%|██████    | 40/66 [00:00<00:00, 192.08it/s] 91%|█████████ | 60/66 [00:00<00:00, 193.14it/s]100%|██████████| 66/66 [00:00<00:00, 192.96it/s]
 91%|█████████ | 60/66 [00:00<00:00, 192.38it/s]100%|██████████| 66/66 [00:00<00:00, 192.29it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:21:46:32,193 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:21:46:32,199 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
2024-07-06:21:46:33,282 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 188.32it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.11it/s] 89%|████████▉ | 59/66 [00:00<00:00, 189.79it/s]100%|██████████| 66/66 [00:00<00:00, 189.46it/s]
2024-07-06:21:46:47,521 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:46:47,521 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:46:47,521 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:46:47,521 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:46:47,521 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:46:47,522 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/66 [00:00<?, ?it/s]Running generate_until requests:   2%|▏         | 1/66 [00:20<21:54, 20.22s/it]Running generate_until requests:   3%|▎         | 2/66 [00:30<15:15, 14.31s/it]Running generate_until requests:   5%|▍         | 3/66 [00:39<12:19, 11.75s/it]Running generate_until requests:   6%|▌         | 4/66 [00:49<11:29, 11.12s/it]Running generate_until requests:   8%|▊         | 5/66 [00:56<10:03,  9.89s/it]Running generate_until requests:   9%|▉         | 6/66 [01:17<13:39, 13.66s/it]Running generate_until requests:  11%|█         | 7/66 [01:33<13:58, 14.21s/it]Running generate_until requests:  12%|█▏        | 8/66 [01:55<16:09, 16.72s/it]Running generate_until requests:  14%|█▎        | 9/66 [02:39<23:54, 25.18s/it]Running generate_until requests:  15%|█▌        | 10/66 [02:46<18:25, 19.75s/it]Running generate_until requests:  17%|█▋        | 11/66 [03:21<22:17, 24.32s/it]Running generate_until requests:  18%|█▊        | 12/66 [03:30<17:35, 19.54s/it]Running generate_until requests:  20%|█▉        | 13/66 [03:58<19:40, 22.27s/it]Running generate_until requests:  21%|██        | 14/66 [04:06<15:26, 17.82s/it]Running generate_until requests:  23%|██▎       | 15/66 [04:18<13:46, 16.21s/it]Running generate_until requests:  24%|██▍       | 16/66 [04:27<11:35, 13.92s/it]Running generate_until requests:  26%|██▌       | 17/66 [04:39<11:02, 13.52s/it]Running generate_until requests:  27%|██▋       | 18/66 [04:51<10:21, 12.94s/it]Running generate_until requests:  29%|██▉       | 19/66 [05:10<11:33, 14.75s/it]Running generate_until requests:  30%|███       | 20/66 [05:31<12:40, 16.54s/it]Running generate_until requests:  32%|███▏      | 21/66 [05:47<12:19, 16.42s/it]Running generate_until requests:  33%|███▎      | 22/66 [06:00<11:19, 15.44s/it]Running generate_until requests:  35%|███▍      | 23/66 [06:26<13:20, 18.62s/it]Running generate_until requests:  36%|███▋      | 24/66 [06:37<11:33, 16.51s/it]Running generate_until requests:  38%|███▊      | 25/66 [06:52<10:52, 15.92s/it]Running generate_until requests:  39%|███▉      | 26/66 [07:04<09:44, 14.62s/it]Running generate_until requests:  41%|████      | 27/66 [07:25<10:51, 16.69s/it]Running generate_until requests:  42%|████▏     | 28/66 [07:33<08:51, 13.97s/it]Running generate_until requests:  44%|████▍     | 29/66 [07:52<09:32, 15.46s/it]Running generate_until requests:  45%|████▌     | 30/66 [08:01<08:13, 13.70s/it]Running generate_until requests:  47%|████▋     | 31/66 [08:09<06:59, 12.00s/it]Running generate_until requests:  48%|████▊     | 32/66 [08:27<07:48, 13.79s/it]Running generate_until requests:  50%|█████     | 33/66 [08:37<06:54, 12.55s/it]Running generate_until requests:  52%|█████▏    | 34/66 [08:44<05:48, 10.89s/it]Running generate_until requests:  53%|█████▎    | 35/66 [08:54<05:30, 10.65s/it]Running generate_until requests:  55%|█████▍    | 36/66 [09:12<06:29, 12.98s/it]Running generate_until requests:  56%|█████▌    | 37/66 [09:18<05:07, 10.60s/it]Running generate_until requests:  58%|█████▊    | 38/66 [09:39<06:27, 13.86s/it]Running generate_until requests:  59%|█████▉    | 39/66 [10:02<07:31, 16.74s/it]Running generate_until requests:  61%|██████    | 40/66 [10:19<07:13, 16.66s/it]Running generate_until requests:  62%|██████▏   | 41/66 [10:36<06:56, 16.65s/it]Running generate_until requests:  64%|██████▎   | 42/66 [11:15<09:25, 23.58s/it]Running generate_until requests:  65%|██████▌   | 43/66 [11:31<08:09, 21.29s/it]Running generate_until requests:  67%|██████▋   | 44/66 [11:43<06:46, 18.49s/it]Running generate_until requests:  68%|██████▊   | 45/66 [12:08<07:05, 20.26s/it]Running generate_until requests:  70%|██████▉   | 46/66 [12:50<08:57, 26.90s/it]Running generate_until requests:  71%|███████   | 47/66 [13:07<07:34, 23.91s/it]Running generate_until requests:  73%|███████▎  | 48/66 [13:13<05:36, 18.69s/it]Running generate_until requests:  74%|███████▍  | 49/66 [13:23<04:30, 15.91s/it]Running generate_until requests:  76%|███████▌  | 50/66 [13:43<04:36, 17.30s/it]Running generate_until requests:  77%|███████▋  | 51/66 [14:02<04:24, 17.64s/it]Running generate_until requests:  79%|███████▉  | 52/66 [14:13<03:38, 15.61s/it]Running generate_until requests:  80%|████████  | 53/66 [14:29<03:24, 15.77s/it]Running generate_until requests:  82%|████████▏ | 54/66 [14:54<03:41, 18.47s/it]Running generate_until requests:  83%|████████▎ | 55/66 [15:00<02:43, 14.88s/it]Running generate_until requests:  85%|████████▍ | 56/66 [15:22<02:49, 16.93s/it]Running generate_until requests:  86%|████████▋ | 57/66 [15:33<02:16, 15.15s/it]Running generate_until requests:  88%|████████▊ | 58/66 [15:37<01:34, 11.82s/it]Running generate_until requests:  89%|████████▉ | 59/66 [15:48<01:20, 11.54s/it]Running generate_until requests:  91%|█████████ | 60/66 [16:05<01:18, 13.16s/it]Running generate_until requests:  92%|█████████▏| 61/66 [16:29<01:23, 16.65s/it]Running generate_until requests:  94%|█████████▍| 62/66 [16:53<01:14, 18.65s/it]Running generate_until requests:  95%|█████████▌| 63/66 [17:05<00:50, 16.77s/it]Running generate_until requests:  97%|█████████▋| 64/66 [17:16<00:29, 14.87s/it]Running generate_until requests:  98%|█████████▊| 65/66 [17:29<00:14, 14.47s/it]Running generate_until requests: 100%|██████████| 66/66 [17:43<00:00, 14.29s/it]Running generate_until requests: 100%|██████████| 66/66 [17:43<00:00, 16.11s/it]
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-06:22:06:07,937 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:06:07,937 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:06:07,937 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:06:07,938 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:06:07,948 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:06:07,985 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:06:17,123 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:06:17,123 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:06:17,123 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:06:17,123 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:06:17,123 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:06:17,123 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:06:17,124 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:06:17,124 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:06:17,124 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:06:17,124 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:06:17,124 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:06:17,124 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:06:17,149 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:06:17,149 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:06:17,149 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:06:17,149 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:06:17,149 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:06:17,149 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.001, 'patternstrict': True}
2024-07-06:22:06:17,149 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.001, 'patternstrict': True}
2024-07-06:22:06:17,149 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.001, 'patternstrict': True}
2024-07-06:22:06:17,149 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.001, 'patternstrict': True}
2024-07-06:22:06:17,149 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.001, 'patternstrict': True}
2024-07-06:22:06:17,149 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:06:17,149 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.001, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:01, 20.50s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.11s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.11s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.30s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.00s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:39<00:39, 19.62s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:40<00:40, 20.23s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:40<00:40, 20.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:40<00:40, 20.02s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:40<00:40, 20.02s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:40<00:40, 20.14s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:59<00:19, 19.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.92s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.91s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.97s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:20, 20.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:19, 19.91s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 12.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 15.34s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 12.62s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 15.40s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 12.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 15.37s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 12.69s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:02<00:00, 15.52s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 12.62s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 15.40s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 12.75s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:01<00:00, 15.45s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:08:06,582 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:08:06,654 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:22:08:06,660 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:08:06,668 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:08:06,673 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:08:06,735 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:22:08:08,010 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
2024-07-06:22:08:08,011 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:22:08:08,019 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.00it/s] 30%|███       | 20/66 [00:00<00:00, 190.77it/s] 30%|███       | 20/66 [00:00<00:00, 191.19it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.47it/s] 61%|██████    | 40/66 [00:00<00:00, 192.60it/s] 61%|██████    | 40/66 [00:00<00:00, 192.75it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.00it/s] 91%|█████████ | 60/66 [00:00<00:00, 192.89it/s] 91%|█████████ | 60/66 [00:00<00:00, 193.15it/s]100%|██████████| 66/66 [00:00<00:00, 192.68it/s]
100%|██████████| 66/66 [00:00<00:00, 190.84it/s]
100%|██████████| 66/66 [00:00<00:00, 192.94it/s]
2024-07-06:22:08:09,435 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/66 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:08:09,498 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
 30%|███       | 20/66 [00:00<00:00, 190.72it/s] 61%|██████    | 40/66 [00:00<00:00, 192.21it/s] 91%|█████████ | 60/66 [00:00<00:00, 192.49it/s]100%|██████████| 66/66 [00:00<00:00, 192.35it/s]
2024-07-06:22:08:11,348 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 185.66it/s] 59%|█████▉    | 39/66 [00:00<00:00, 188.79it/s] 88%|████████▊ | 58/66 [00:00<00:00, 188.94it/s]100%|██████████| 66/66 [00:00<00:00, 188.71it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-07-06:22:08:17,112 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /data/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Sat Apr 20 02:35:35 2024).
2024-07-06:22:08:17,116 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /data/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Sat Apr 20 02:35:35 2024).
2024-07-06:22:08:17,363 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 187.96it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.23it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.04it/s]100%|██████████| 66/66 [00:00<00:00, 190.62it/s]
2024-07-06:22:08:28,297 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:08:28,297 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:08:28,297 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:08:28,297 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:08:28,298 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:08:28,298 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/66 [00:00<?, ?it/s]Running generate_until requests:   2%|▏         | 1/66 [00:14<15:49, 14.61s/it]Running generate_until requests:   3%|▎         | 2/66 [00:20<10:17,  9.65s/it]Running generate_until requests:   5%|▍         | 3/66 [00:26<08:12,  7.81s/it]Running generate_until requests:   6%|▌         | 4/66 [00:41<11:14, 10.88s/it]Running generate_until requests:   8%|▊         | 5/66 [00:48<09:31,  9.37s/it]Running generate_until requests:   9%|▉         | 6/66 [01:05<11:50, 11.84s/it]Running generate_until requests:  11%|█         | 7/66 [01:17<11:44, 11.93s/it]Running generate_until requests:  12%|█▏        | 8/66 [01:27<10:48, 11.19s/it]Running generate_until requests:  14%|█▎        | 9/66 [01:54<15:31, 16.34s/it]Running generate_until requests:  15%|█▌        | 10/66 [01:59<12:00, 12.87s/it]Running generate_until requests:  17%|█▋        | 11/66 [02:13<11:59, 13.07s/it]Running generate_until requests:  18%|█▊        | 12/66 [02:17<09:27, 10.51s/it]Running generate_until requests:  20%|█▉        | 13/66 [02:33<10:45, 12.18s/it]Running generate_until requests:  21%|██        | 14/66 [02:45<10:15, 11.84s/it]Running generate_until requests:  23%|██▎       | 15/66 [02:54<09:24, 11.07s/it]Running generate_until requests:  24%|██▍       | 16/66 [03:00<08:06,  9.73s/it]Running generate_until requests:  26%|██▌       | 17/66 [03:10<07:46,  9.53s/it]Running generate_until requests:  27%|██▋       | 18/66 [03:13<06:04,  7.60s/it]Running generate_until requests:  29%|██▉       | 19/66 [03:28<07:49,  9.99s/it]Running generate_until requests:  30%|███       | 20/66 [03:40<08:07, 10.60s/it]Running generate_until requests:  32%|███▏      | 21/66 [03:58<09:38, 12.85s/it]Running generate_until requests:  33%|███▎      | 22/66 [04:02<07:29, 10.22s/it]Running generate_until requests:  35%|███▍      | 23/66 [04:11<07:04,  9.87s/it]Running generate_until requests:  36%|███▋      | 24/66 [04:18<06:14,  8.91s/it]Running generate_until requests:  38%|███▊      | 25/66 [04:26<05:48,  8.50s/it]Running generate_until requests:  39%|███▉      | 26/66 [04:32<05:16,  7.92s/it]Running generate_until requests:  41%|████      | 27/66 [04:45<06:08,  9.45s/it]Running generate_until requests:  42%|████▏     | 28/66 [05:01<07:14, 11.44s/it]Running generate_until requests:  44%|████▍     | 29/66 [05:15<07:27, 12.10s/it]Running generate_until requests:  45%|████▌     | 30/66 [05:21<06:10, 10.31s/it]Running generate_until requests:  47%|████▋     | 31/66 [05:27<05:11,  8.89s/it]Running generate_until requests:  48%|████▊     | 32/66 [05:40<05:44, 10.14s/it]Running generate_until requests:  50%|█████     | 33/66 [05:47<05:05,  9.25s/it]Running generate_until requests:  52%|█████▏    | 34/66 [05:52<04:11,  7.87s/it]Running generate_until requests:  53%|█████▎    | 35/66 [05:56<03:33,  6.90s/it]Running generate_until requests:  55%|█████▍    | 36/66 [06:15<05:16, 10.55s/it]Running generate_until requests:  56%|█████▌    | 37/66 [06:19<04:05,  8.47s/it]Running generate_until requests:  58%|█████▊    | 38/66 [06:31<04:27,  9.54s/it]Running generate_until requests:  59%|█████▉    | 39/66 [06:48<05:20, 11.87s/it]Running generate_until requests:  61%|██████    | 40/66 [06:55<04:28, 10.32s/it]Running generate_until requests:  62%|██████▏   | 41/66 [07:10<04:57, 11.90s/it]Running generate_until requests:  64%|██████▎   | 42/66 [07:20<04:29, 11.21s/it]Running generate_until requests:  65%|██████▌   | 43/66 [07:31<04:16, 11.16s/it]Running generate_until requests:  67%|██████▋   | 44/66 [07:37<03:32,  9.64s/it]Running generate_until requests:  68%|██████▊   | 45/66 [07:54<04:10, 11.91s/it]Running generate_until requests:  70%|██████▉   | 46/66 [08:02<03:29, 10.47s/it]Running generate_until requests:  71%|███████   | 47/66 [08:09<02:59,  9.45s/it]Running generate_until requests:  73%|███████▎  | 48/66 [08:15<02:32,  8.45s/it]Running generate_until requests:  74%|███████▍  | 49/66 [08:22<02:16,  8.05s/it]Running generate_until requests:  76%|███████▌  | 50/66 [08:46<03:25, 12.84s/it]Running generate_until requests:  77%|███████▋  | 51/66 [08:54<02:49, 11.28s/it]Running generate_until requests:  79%|███████▉  | 52/66 [08:58<02:09,  9.27s/it]Running generate_until requests:  80%|████████  | 53/66 [09:04<01:45,  8.15s/it]Running generate_until requests:  82%|████████▏ | 54/66 [09:23<02:18, 11.56s/it]Running generate_until requests:  83%|████████▎ | 55/66 [09:28<01:43,  9.45s/it]Running generate_until requests:  85%|████████▍ | 56/66 [09:39<01:39,  9.90s/it]Running generate_until requests:  86%|████████▋ | 57/66 [09:46<01:22,  9.19s/it]Running generate_until requests:  88%|████████▊ | 58/66 [09:48<00:56,  7.06s/it]Running generate_until requests:  89%|████████▉ | 59/66 [10:05<01:09,  9.90s/it]Running generate_until requests:  91%|█████████ | 60/66 [10:13<00:56,  9.34s/it]Running generate_until requests:  92%|█████████▏| 61/66 [10:20<00:43,  8.65s/it]Running generate_until requests:  94%|█████████▍| 62/66 [10:28<00:34,  8.59s/it]Running generate_until requests:  95%|█████████▌| 63/66 [10:34<00:23,  7.81s/it]Running generate_until requests:  97%|█████████▋| 64/66 [10:50<00:20, 10.30s/it]Running generate_until requests:  98%|█████████▊| 65/66 [10:53<00:07,  7.98s/it]Running generate_until requests: 100%|██████████| 66/66 [11:03<00:00,  8.57s/it]Running generate_until requests: 100%|██████████| 66/66 [11:03<00:00, 10.05s/it]
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-06:22:22:34,029 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:22:34,029 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:22:34,029 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:22:34,029 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:22:34,029 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:22:34,029 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:22:43,243 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:22:43,243 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:22:43,243 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:22:43,243 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:22:43,244 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:22:43,244 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:22:43,244 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:22:43,244 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:22:43,244 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:22:43,246 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:22:43,245 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:22:43,247 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:22:43,264 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:22:43,264 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.005, 'patternstrict': True}
2024-07-06:22:22:43,265 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:22:43,265 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:22:43,265 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:22:43,265 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.005, 'patternstrict': True}
2024-07-06:22:22:43,265 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.005, 'patternstrict': True}
2024-07-06:22:22:43,265 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.005, 'patternstrict': True}
2024-07-06:22:22:43,265 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:22:43,265 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.005, 'patternstrict': True}
2024-07-06:22:22:43,265 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:22:43,265 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.005, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:51, 17.29s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.19s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.29s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:56, 18.95s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.25s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.22s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:33<00:33, 16.65s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:34<00:34, 17.06s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:34<00:34, 17.08s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:34<00:34, 17.13s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:35<00:34, 17.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:34<00:34, 17.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.91s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:50<00:16, 16.37s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:50<00:16, 16.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:50<00:16, 16.55s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:50<00:16, 16.64s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:50<00:16, 16.40s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:50<00:00, 10.41s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:50<00:00, 12.75s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 10.41s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 12.82s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 10.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 12.85s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:52<00:00, 10.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:52<00:00, 13.01s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 10.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 12.84s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 10.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:51<00:00, 12.88s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:24:22,492 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:24:22,551 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:24:22,582 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:22:24:22,587 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:24:22,690 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:24:22,726 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:22:24:23,853 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
2024-07-06:22:24:23,853 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
2024-07-06:22:24:23,856 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:22:24:23,870 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
2024-07-06:22:24:23,877 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.82it/s] 30%|███       | 20/66 [00:00<00:00, 191.05it/s] 30%|███       | 20/66 [00:00<00:00, 192.63it/s] 29%|██▉       | 19/66 [00:00<00:00, 185.66it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.22it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.56it/s] 61%|██████    | 40/66 [00:00<00:00, 192.56it/s] 61%|██████    | 40/66 [00:00<00:00, 194.16it/s] 58%|█████▊    | 38/66 [00:00<00:00, 187.58it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.15it/s] 89%|████████▉ | 59/66 [00:00<00:00, 192.08it/s] 91%|█████████ | 60/66 [00:00<00:00, 192.90it/s] 91%|█████████ | 60/66 [00:00<00:00, 194.59it/s] 86%|████████▋ | 57/66 [00:00<00:00, 187.87it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.56it/s]100%|██████████| 66/66 [00:00<00:00, 194.41it/s]
100%|██████████| 66/66 [00:00<00:00, 192.79it/s]
100%|██████████| 66/66 [00:00<00:00, 191.89it/s]
100%|██████████| 66/66 [00:00<00:00, 191.35it/s]
100%|██████████| 66/66 [00:00<00:00, 187.69it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:24:25,317 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:22:24:26,450 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 188.47it/s] 59%|█████▉    | 39/66 [00:00<00:00, 189.67it/s] 89%|████████▉ | 59/66 [00:00<00:00, 190.41it/s]100%|██████████| 66/66 [00:00<00:00, 190.25it/s]
2024-07-06:22:24:33,844 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:24:33,844 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:24:33,844 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:24:33,844 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:24:33,844 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:22:24:33,846 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   2%|▏         | 1/66 [00:11<11:59, 11.07s/it]Running generate_until requests:   3%|▎         | 2/66 [00:17<08:44,  8.20s/it]Running generate_until requests:   5%|▍         | 3/66 [00:22<07:23,  7.04s/it]Running generate_until requests:   6%|▌         | 4/66 [00:28<06:42,  6.49s/it]Running generate_until requests:   8%|▊         | 5/66 [00:34<06:28,  6.37s/it]Running generate_until requests:   9%|▉         | 6/66 [00:53<10:37, 10.62s/it]Running generate_until requests:  11%|█         | 7/66 [01:03<10:17, 10.47s/it]Running generate_until requests:  12%|█▏        | 8/66 [01:19<11:43, 12.13s/it]Running generate_until requests:  14%|█▎        | 9/66 [01:43<15:06, 15.90s/it]Running generate_until requests:  15%|█▌        | 10/66 [01:48<11:36, 12.44s/it]Running generate_until requests:  17%|█▋        | 11/66 [02:06<13:01, 14.20s/it]Running generate_until requests:  18%|█▊        | 12/66 [02:11<10:10, 11.31s/it]Running generate_until requests:  20%|█▉        | 13/66 [02:34<13:17, 15.04s/it]Running generate_until requests:  21%|██        | 14/66 [02:43<11:25, 13.19s/it]Running generate_until requests:  23%|██▎       | 15/66 [02:56<11:04, 13.04s/it]Running generate_until requests:  24%|██▍       | 16/66 [03:04<09:30, 11.41s/it]Running generate_until requests:  26%|██▌       | 17/66 [03:14<09:00, 11.04s/it]Running generate_until requests:  27%|██▋       | 18/66 [03:18<07:16,  9.10s/it]Running generate_until requests:  29%|██▉       | 19/66 [03:38<09:40, 12.35s/it]Running generate_until requests:  30%|███       | 20/66 [03:57<11:00, 14.36s/it]Running generate_until requests:  32%|███▏      | 21/66 [04:18<12:15, 16.34s/it]Running generate_until requests:  33%|███▎      | 22/66 [04:22<09:17, 12.66s/it]Running generate_until requests:  35%|███▍      | 23/66 [04:30<07:58, 11.12s/it]Running generate_until requests:  36%|███▋      | 24/66 [04:37<07:01, 10.04s/it]Running generate_until requests:  38%|███▊      | 25/66 [04:43<05:57,  8.71s/it]Running generate_until requests:  39%|███▉      | 26/66 [04:50<05:28,  8.22s/it]Running generate_until requests:  41%|████      | 27/66 [05:10<07:37, 11.74s/it]Running generate_until requests:  42%|████▏     | 28/66 [05:16<06:15,  9.88s/it]Running generate_until requests:  44%|████▍     | 29/66 [05:27<06:17, 10.21s/it]Running generate_until requests:  45%|████▌     | 30/66 [05:33<05:22,  8.97s/it]Running generate_until requests:  47%|████▋     | 31/66 [05:38<04:32,  7.79s/it]Running generate_until requests:  48%|████▊     | 32/66 [05:45<04:23,  7.74s/it]Running generate_until requests:  50%|█████     | 33/66 [05:52<04:08,  7.53s/it]Running generate_until requests:  52%|█████▏    | 34/66 [05:58<03:46,  7.08s/it]Running generate_until requests:  53%|█████▎    | 35/66 [06:03<03:15,  6.31s/it]Running generate_until requests:  55%|█████▍    | 36/66 [06:18<04:26,  8.89s/it]Running generate_until requests:  56%|█████▌    | 37/66 [06:21<03:31,  7.29s/it]Running generate_until requests:  58%|█████▊    | 38/66 [06:40<04:57, 10.61s/it]Running generate_until requests:  59%|█████▉    | 39/66 [06:53<05:07, 11.38s/it]Running generate_until requests:  61%|██████    | 40/66 [07:03<04:44, 10.95s/it]Running generate_until requests:  62%|██████▏   | 41/66 [07:10<04:04,  9.78s/it]Running generate_until requests:  64%|██████▎   | 42/66 [07:19<03:48,  9.53s/it]Running generate_until requests:  65%|██████▌   | 43/66 [07:29<03:42,  9.66s/it]Running generate_until requests:  67%|██████▋   | 44/66 [07:33<02:58,  8.12s/it]Running generate_until requests:  68%|██████▊   | 45/66 [07:43<03:02,  8.69s/it]Running generate_until requests:  70%|██████▉   | 46/66 [07:50<02:43,  8.19s/it]Running generate_until requests:  71%|███████   | 47/66 [08:01<02:48,  8.89s/it]Running generate_until requests:  73%|███████▎  | 48/66 [08:08<02:30,  8.34s/it]Running generate_until requests:  74%|███████▍  | 49/66 [08:15<02:15,  7.95s/it]Running generate_until requests:  76%|███████▌  | 50/66 [08:27<02:26,  9.13s/it]Running generate_until requests:  77%|███████▋  | 51/66 [08:34<02:09,  8.63s/it]Running generate_until requests:  79%|███████▉  | 52/66 [08:39<01:43,  7.42s/it]Running generate_until requests:  80%|████████  | 53/66 [08:46<01:34,  7.31s/it]Running generate_until requests:  82%|████████▏ | 54/66 [09:00<01:51,  9.29s/it]Running generate_until requests:  83%|████████▎ | 55/66 [09:04<01:26,  7.85s/it]Running generate_until requests:  85%|████████▍ | 56/66 [09:16<01:29,  8.92s/it]Running generate_until requests:  86%|████████▋ | 57/66 [09:24<01:19,  8.82s/it]Running generate_until requests:  88%|████████▊ | 58/66 [09:27<00:55,  6.93s/it]Running generate_until requests:  89%|████████▉ | 59/66 [09:36<00:53,  7.68s/it]Running generate_until requests:  91%|█████████ | 60/66 [09:44<00:46,  7.78s/it]Running generate_until requests:  92%|█████████▏| 61/66 [09:47<00:31,  6.35s/it]Running generate_until requests:  94%|█████████▍| 62/66 [09:58<00:30,  7.71s/it]Running generate_until requests:  95%|█████████▌| 63/66 [10:09<00:26,  8.69s/it]Running generate_until requests:  97%|█████████▋| 64/66 [10:21<00:18,  9.49s/it]Running generate_until requests:  98%|█████████▊| 65/66 [10:28<00:09,  9.01s/it]Running generate_until requests: 100%|██████████| 66/66 [10:38<00:00,  9.25s/it]Running generate_until requests: 100%|██████████| 66/66 [10:38<00:00,  9.68s/it]
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-06:22:42:57,943 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:42:57,943 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:42:57,943 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:42:57,943 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:42:57,943 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:42:57,943 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:22:43:07,184 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:43:07,184 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:43:07,184 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:43:07,184 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:43:07,184 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:43:07,184 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-06:22:43:07,185 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:43:07,185 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:43:07,185 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:43:07,185 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:43:07,185 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:43:07,185 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:22:43:07,211 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:43:07,211 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:43:07,211 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:43:07,211 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:43:07,211 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:43:07,211 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.01, 'patternstrict': True}
2024-07-06:22:43:07,211 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.01, 'patternstrict': True}
2024-07-06:22:43:07,211 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.01, 'patternstrict': True}
2024-07-06:22:43:07,211 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.01, 'patternstrict': True}
2024-07-06:22:43:07,211 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.01, 'patternstrict': True}
2024-07-06:22:43:07,211 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:22:43:07,211 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 9, 'spr': 0.2, 'thr': 0.01, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:00, 20.10s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.12s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.11s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.53s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.22s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.12s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:35, 17.97s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:37, 18.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:37, 18.70s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.74s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:37, 18.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:37, 18.57s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:52<00:16, 16.81s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:54<00:17, 17.35s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:53<00:17, 17.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 10.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.68s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 11.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:55<00:00, 13.84s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 11.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.74s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 10.97s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.73s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 11.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.73s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 10.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.75s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:44:49,853 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:44:49,898 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:44:50,058 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:44:50,078 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:44:50,079 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:22:44:50,084 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
2024-07-06:22:44:51,183 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
2024-07-06:22:44:51,183 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
2024-07-06:22:44:51,185 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]  0%|          | 0/66 [00:00<?, ?it/s]2024-07-06:22:44:51,225 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.60it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.62it/s] 29%|██▉       | 19/66 [00:00<00:00, 188.58it/s] 30%|███       | 20/66 [00:00<00:00, 192.45it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.28it/s] 59%|█████▉    | 39/66 [00:00<00:00, 191.53it/s] 59%|█████▉    | 39/66 [00:00<00:00, 190.07it/s]2024-07-06:22:44:51,433 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
 61%|██████    | 40/66 [00:00<00:00, 193.84it/s]  0%|          | 0/66 [00:00<?, ?it/s] 89%|████████▉ | 59/66 [00:00<00:00, 191.70it/s] 89%|████████▉ | 59/66 [00:00<00:00, 192.00it/s] 89%|████████▉ | 59/66 [00:00<00:00, 190.46it/s]100%|██████████| 66/66 [00:00<00:00, 191.85it/s]
100%|██████████| 66/66 [00:00<00:00, 191.52it/s]
100%|██████████| 66/66 [00:00<00:00, 190.31it/s]
 91%|█████████ | 60/66 [00:00<00:00, 194.15it/s] 29%|██▉       | 19/66 [00:00<00:00, 189.01it/s]100%|██████████| 66/66 [00:00<00:00, 193.98it/s]
 59%|█████▉    | 39/66 [00:00<00:00, 190.63it/s] 89%|████████▉ | 59/66 [00:00<00:00, 190.73it/s]100%|██████████| 66/66 [00:00<00:00, 190.65it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-06:22:44:52,903 WARNING  [xhuggingface.py:298] WARNING: The number of total system GPUs does not match the number of spawned processes. If you would like to use data parallelism, please launch the script with 'accelerate launch *script*'. Current run will proceed with 6 devices.
2024-07-06:22:44:54,076 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/66 [00:00<?, ?it/s] 29%|██▉       | 19/66 [00:00<00:00, 186.71it/s] 58%|█████▊    | 38/66 [00:00<00:00, 188.51it/s] 86%|████████▋ | 57/66 [00:00<00:00, 188.91it/s]100%|██████████| 66/66 [00:00<00:00, 188.77it/s]
2024-07-06:22:45:02,398 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:45:02,398 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:45:02,398 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:45:02,399 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:45:02,399 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:22:45:02,399 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/66 [00:00<?, ?it/s]Running generate_until requests:   2%|▏         | 1/66 [00:12<13:36, 12.56s/it]Running generate_until requests:   3%|▎         | 2/66 [00:18<09:22,  8.80s/it]Running generate_until requests:   5%|▍         | 3/66 [00:24<07:42,  7.34s/it]Running generate_until requests:   6%|▌         | 4/66 [00:30<07:03,  6.84s/it]Running generate_until requests:   8%|▊         | 5/66 [00:36<06:40,  6.56s/it]Running generate_until requests:   9%|▉         | 6/66 [00:45<07:15,  7.26s/it]Running generate_until requests:  11%|█         | 7/66 [01:03<10:34, 10.76s/it]Running generate_until requests:  12%|█▏        | 8/66 [01:18<11:51, 12.28s/it]Running generate_until requests:  14%|█▎        | 9/66 [01:47<16:34, 17.45s/it]Running generate_until requests:  15%|█▌        | 10/66 [01:51<12:34, 13.47s/it]Running generate_until requests:  17%|█▋        | 11/66 [02:04<12:03, 13.16s/it]Running generate_until requests:  18%|█▊        | 12/66 [02:09<09:45, 10.85s/it]Running generate_until requests:  20%|█▉        | 13/66 [02:21<09:38, 10.91s/it]Running generate_until requests:  21%|██        | 14/66 [02:41<11:51, 13.67s/it]Running generate_until requests:  23%|██▎       | 15/66 [02:53<11:11, 13.16s/it]Running generate_until requests:  24%|██▍       | 16/66 [03:00<09:25, 11.31s/it]Running generate_until requests:  26%|██▌       | 17/66 [03:07<08:18, 10.17s/it]Running generate_until requests:  27%|██▋       | 18/66 [03:12<06:48,  8.50s/it]Running generate_until requests:  29%|██▉       | 19/66 [03:29<08:38, 11.04s/it]Running generate_until requests:  30%|███       | 20/66 [03:48<10:16, 13.41s/it]Running generate_until requests:  32%|███▏      | 21/66 [04:06<11:16, 15.04s/it]Running generate_until requests:  33%|███▎      | 22/66 [04:11<08:37, 11.76s/it]Running generate_until requests:  35%|███▍      | 23/66 [04:22<08:16, 11.54s/it]Running generate_until requests:  36%|███▋      | 24/66 [04:32<07:51, 11.22s/it]Running generate_until requests:  38%|███▊      | 25/66 [04:37<06:24,  9.37s/it]Running generate_until requests:  39%|███▉      | 26/66 [04:44<05:47,  8.68s/it]Running generate_until requests:  41%|████      | 27/66 [04:55<06:04,  9.35s/it]Running generate_until requests:  42%|████▏     | 28/66 [05:01<05:11,  8.21s/it]Running generate_until requests:  44%|████▍     | 29/66 [05:09<05:01,  8.14s/it]Running generate_until requests:  45%|████▌     | 30/66 [05:15<04:30,  7.52s/it]Running generate_until requests:  47%|████▋     | 31/66 [05:20<03:58,  6.81s/it]Running generate_until requests:  48%|████▊     | 32/66 [05:25<03:38,  6.42s/it]Running generate_until requests:  50%|█████     | 33/66 [05:34<03:51,  7.03s/it]Running generate_until requests:  52%|█████▏    | 34/66 [05:43<04:03,  7.62s/it]Running generate_until requests:  53%|█████▎    | 35/66 [05:47<03:27,  6.69s/it]Running generate_until requests:  55%|█████▍    | 36/66 [06:08<05:26, 10.90s/it]Running generate_until requests:  56%|█████▌    | 37/66 [06:12<04:12,  8.70s/it]Running generate_until requests:  58%|█████▊    | 38/66 [06:30<05:28, 11.75s/it]Running generate_until requests:  59%|█████▉    | 39/66 [06:42<05:16, 11.71s/it]Running generate_until requests:  61%|██████    | 40/66 [06:52<04:50, 11.17s/it]Running generate_until requests:  62%|██████▏   | 41/66 [06:59<04:07,  9.91s/it]Running generate_until requests:  64%|██████▎   | 42/66 [07:03<03:15,  8.15s/it]Running generate_until requests:  65%|██████▌   | 43/66 [07:14<03:30,  9.14s/it]Running generate_until requests:  67%|██████▋   | 44/66 [07:20<02:54,  7.91s/it]Running generate_until requests:  68%|██████▊   | 45/66 [07:36<03:42, 10.59s/it]Running generate_until requests:  70%|██████▉   | 46/66 [07:46<03:25, 10.26s/it]Running generate_until requests:  71%|███████   | 47/66 [07:57<03:18, 10.47s/it]Running generate_until requests:  73%|███████▎  | 48/66 [08:02<02:39,  8.84s/it]Running generate_until requests:  74%|███████▍  | 49/66 [08:09<02:20,  8.28s/it]Running generate_until requests:  76%|███████▌  | 50/66 [08:21<02:30,  9.40s/it]Running generate_until requests:  77%|███████▋  | 51/66 [08:28<02:12,  8.82s/it]Running generate_until requests:  79%|███████▉  | 52/66 [08:33<01:47,  7.68s/it]Running generate_until requests:  80%|████████  | 53/66 [08:40<01:35,  7.31s/it]Running generate_until requests:  82%|████████▏ | 54/66 [08:56<01:58,  9.87s/it]Running generate_until requests:  83%|████████▎ | 55/66 [09:00<01:30,  8.25s/it]Running generate_until requests:  85%|████████▍ | 56/66 [09:12<01:32,  9.21s/it]Running generate_until requests:  86%|████████▋ | 57/66 [09:20<01:19,  8.84s/it]Running generate_until requests:  88%|████████▊ | 58/66 [09:22<00:55,  6.96s/it]Running generate_until requests:  89%|████████▉ | 59/66 [09:30<00:49,  7.10s/it]Running generate_until requests:  91%|█████████ | 60/66 [09:49<01:04, 10.75s/it]Running generate_until requests:  92%|█████████▏| 61/66 [09:53<00:44,  8.87s/it]