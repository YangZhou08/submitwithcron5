Switched to branch 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-25:03:49:36,427 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:36,493 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:36,590 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:36,633 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:36,637 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:36,638 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:36,644 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:36,647 INFO     [main.py:288] Verbosity set to INFO
2024-07-25:03:49:45,520 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,520 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,520 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,520 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,520 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,521 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,530 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,531 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-25:03:49:45,541 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,541 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
2024-07-25:03:49:45,542 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,542 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,542 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,542 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,542 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,542 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
2024-07-25:03:49:45,542 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
2024-07-25:03:49:45,542 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
2024-07-25:03:49:45,542 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
2024-07-25:03:49:45,542 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
2024-07-25:03:49:45,542 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,543 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
2024-07-25:03:49:45,542 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-25:03:49:45,543 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'widthtree': 8, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.05}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:48, 16.16s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:47, 15.81s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:47, 15.83s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:47, 15.97s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:47, 15.89s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:47, 15.84s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:47, 15.84s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:15<00:47, 15.86s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:29, 14.98s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:30<00:30, 15.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.44s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.44s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:32<00:32, 16.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.49s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:44<00:14, 14.52s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:15, 15.08s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:15, 15.07s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:15, 15.08s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:15, 15.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:15, 15.09s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:46<00:15, 15.38s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:15, 15.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.56s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.65s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.66s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.53s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.67s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.66s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:47<00:00,  9.71s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:47<00:00, 11.92s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.70s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00,  9.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:46<00:00, 11.67s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-25:03:51:14,782 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:14,782 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:14,814 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s]2024-07-25:03:51:14,931 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:14,931 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:14,936 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:14,937 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
100%|██████████| 165/165 [00:00<00:00, 1652.87it/s]
2024-07-25:03:51:14,963 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 6...
2024-07-25:03:51:14,967 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 1...
2024-07-25:03:51:14,978 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:14,979 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s]2024-07-25:03:51:15,009 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s]2024-07-25:03:51:15,052 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:15,052 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:15,059 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:15,059 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:15,083 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 5...
100%|██████████| 165/165 [00:00<00:00, 1667.00it/s]
100%|██████████| 165/165 [00:00<00:00, 1710.20it/s]
2024-07-25:03:51:15,090 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-25:03:51:15,128 INFO     [xhuggingface.py:336] Using 8 devices with data parallelism
100%|██████████| 165/165 [00:00<00:00, 1687.68it/s]
100%|██████████| 165/165 [00:00<00:00, 1693.52it/s]
100%|██████████| 165/165 [00:00<00:00, 1692.71it/s]
2024-07-25:03:51:15,995 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:15,995 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:16,032 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s]100%|██████████| 165/165 [00:00<00:00, 1674.66it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-25:03:51:17,129 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:17,130 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-07-25:03:51:17,161 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s]100%|██████████| 164/164 [00:00<00:00, 1670.99it/s]
2024-07-25:03:51:30,380 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-25:03:51:30,380 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-25:03:51:30,380 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-25:03:51:30,380 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-25:03:51:30,380 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-25:03:51:30,380 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-25:03:51:30,380 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-25:03:51:30,381 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/165 [00:10<27:39, 10.12s/it]Running generate_until requests:   1%|          | 2/165 [00:18<25:24,  9.35s/it]Running generate_until requests:   2%|▏         | 3/165 [00:33<31:54, 11.82s/it]Running generate_until requests:   2%|▏         | 4/165 [00:47<34:19, 12.79s/it]Running generate_until requests:   3%|▎         | 5/165 [01:07<40:49, 15.31s/it]Running generate_until requests:   4%|▎         | 6/165 [01:20<38:01, 14.35s/it]Running generate_until requests:   4%|▍         | 7/165 [01:27<31:37, 12.01s/it]Running generate_until requests:   5%|▍         | 8/165 [01:43<34:47, 13.30s/it]Running generate_until requests:   5%|▌         | 9/165 [01:57<35:13, 13.55s/it]Running generate_until requests:   6%|▌         | 10/165 [02:15<38:38, 14.96s/it]Running generate_until requests:   7%|▋         | 11/165 [02:30<38:02, 14.82s/it]Running generate_until requests:   7%|▋         | 12/165 [02:39<33:14, 13.04s/it]Running generate_until requests:   8%|▊         | 13/165 [02:51<32:42, 12.91s/it]Running generate_until requests:   8%|▊         | 14/165 [03:07<34:55, 13.88s/it]Running generate_until requests:   9%|▉         | 15/165 [03:15<29:44, 11.89s/it]Running generate_until requests:  10%|▉         | 16/165 [03:26<28:43, 11.57s/it]Running generate_until requests:  10%|█         | 17/165 [03:43<33:09, 13.44s/it]Running generate_until requests:  11%|█         | 18/165 [03:59<34:53, 14.24s/it]Running generate_until requests:  12%|█▏        | 19/165 [04:21<39:50, 16.38s/it]Running generate_until requests:  12%|█▏        | 20/165 [04:53<50:58, 21.09s/it]Running generate_until requests:  13%|█▎        | 21/165 [05:09<47:06, 19.63s/it]Running generate_until requests:  13%|█▎        | 22/165 [05:21<41:36, 17.46s/it]Running generate_until requests:  14%|█▍        | 23/165 [05:35<38:51, 16.42s/it]Running generate_until requests:  15%|█▍        | 24/165 [05:43<32:14, 13.72s/it]Running generate_until requests:  15%|█▌        | 25/165 [05:55<31:06, 13.33s/it]Running generate_until requests:  16%|█▌        | 26/165 [06:08<30:12, 13.04s/it]Running generate_until requests:  16%|█▋        | 27/165 [06:17<27:21, 11.90s/it]Running generate_until requests:  17%|█▋        | 28/165 [06:28<26:19, 11.53s/it]Running generate_until requests:  18%|█▊        | 29/165 [06:35<23:10, 10.22s/it]Running generate_until requests:  18%|█▊        | 30/165 [06:44<22:09,  9.85s/it]Running generate_until requests:  19%|█▉        | 31/165 [06:55<22:42, 10.17s/it]Running generate_until requests:  19%|█▉        | 32/165 [07:05<22:52, 10.32s/it]Running generate_until requests:  20%|██        | 33/165 [07:14<21:50,  9.93s/it]Running generate_until requests:  21%|██        | 34/165 [07:21<19:51,  9.10s/it]Running generate_until requests:  21%|██        | 35/165 [07:31<19:51,  9.16s/it]Running generate_until requests:  22%|██▏       | 36/165 [07:40<19:36,  9.12s/it]Running generate_until requests:  22%|██▏       | 37/165 [07:47<18:14,  8.55s/it]Running generate_until requests:  23%|██▎       | 38/165 [08:01<21:40, 10.24s/it]Running generate_until requests:  24%|██▎       | 39/165 [08:12<22:00, 10.48s/it]Running generate_until requests:  24%|██▍       | 40/165 [08:20<19:49,  9.51s/it]Running generate_until requests:  25%|██▍       | 41/165 [08:27<18:14,  8.83s/it]Running generate_until requests:  25%|██▌       | 42/165 [08:36<18:12,  8.88s/it]Running generate_until requests:  26%|██▌       | 43/165 [08:43<17:09,  8.44s/it]Running generate_until requests:  27%|██▋       | 44/165 [08:54<18:21,  9.10s/it]Running generate_until requests:  27%|██▋       | 45/165 [09:02<17:50,  8.92s/it]Running generate_until requests:  28%|██▊       | 46/165 [09:15<20:01, 10.09s/it]Running generate_until requests:  28%|██▊       | 47/165 [09:33<24:19, 12.37s/it]Running generate_until requests:  29%|██▉       | 48/165 [09:44<23:11, 11.89s/it]Running generate_until requests:  30%|██▉       | 49/165 [09:53<21:23, 11.07s/it]Running generate_until requests:  30%|███       | 50/165 [10:05<22:00, 11.48s/it]Running generate_until requests:  31%|███       | 51/165 [10:16<21:24, 11.26s/it]Running generate_until requests:  32%|███▏      | 52/165 [10:25<19:54, 10.57s/it]Running generate_until requests:  32%|███▏      | 53/165 [10:32<17:41,  9.48s/it]Running generate_until requests:  33%|███▎      | 54/165 [10:43<18:15,  9.87s/it]Running generate_until requests:  33%|███▎      | 55/165 [10:55<19:32, 10.66s/it]Running generate_until requests:  34%|███▍      | 56/165 [11:04<18:27, 10.16s/it]Running generate_until requests:  35%|███▍      | 57/165 [11:11<16:44,  9.30s/it]Running generate_until requests:  35%|███▌      | 58/165 [11:22<17:19,  9.72s/it]Running generate_until requests:  36%|███▌      | 59/165 [11:31<16:42,  9.46s/it]Running generate_until requests:  36%|███▋      | 60/165 [11:44<18:19, 10.47s/it]Running generate_until requests:  37%|███▋      | 61/165 [11:51<16:25,  9.48s/it]Running generate_until requests:  38%|███▊      | 62/165 [12:05<18:40, 10.88s/it]Running generate_until requests:  38%|███▊      | 63/165 [12:18<19:30, 11.48s/it]Running generate_until requests:  39%|███▉      | 64/165 [12:30<19:50, 11.79s/it]Running generate_until requests:  39%|███▉      | 65/165 [12:40<18:18, 10.98s/it]Running generate_until requests:  40%|████      | 66/165 [12:51<18:07, 10.98s/it]Running generate_until requests:  41%|████      | 67/165 [13:05<19:28, 11.92s/it]Running generate_until requests:  41%|████      | 68/165 [13:17<19:38, 12.15s/it]Running generate_until requests:  42%|████▏     | 69/165 [13:28<18:51, 11.79s/it]Running generate_until requests:  42%|████▏     | 70/165 [13:43<19:52, 12.56s/it]Running generate_until requests:  43%|████▎     | 71/165 [13:50<17:08, 10.94s/it]Running generate_until requests:  44%|████▎     | 72/165 [13:55<14:23,  9.29s/it]Running generate_until requests:  44%|████▍     | 73/165 [14:08<15:47, 10.30s/it]Running generate_until requests:  45%|████▍     | 74/165 [14:17<15:01,  9.91s/it]Running generate_until requests:  45%|████▌     | 75/165 [14:28<15:14, 10.16s/it]Running generate_until requests:  46%|████▌     | 76/165 [14:42<17:03, 11.49s/it]Running generate_until requests:  47%|████▋     | 77/165 [14:51<15:44, 10.73s/it]Running generate_until requests:  47%|████▋     | 78/165 [15:00<14:46, 10.19s/it]Running generate_until requests:  48%|████▊     | 79/165 [15:09<14:05,  9.83s/it]Running generate_until requests:  48%|████▊     | 80/165 [15:17<12:53,  9.10s/it]Running generate_until requests:  49%|████▉     | 81/165 [15:22<11:11,  8.00s/it]Running generate_until requests:  50%|████▉     | 82/165 [15:29<10:40,  7.72s/it]Running generate_until requests:  50%|█████     | 83/165 [15:58<19:06, 13.98s/it]Running generate_until requests:  51%|█████     | 84/165 [16:08<17:36, 13.04s/it]Running generate_until requests:  52%|█████▏    | 85/165 [16:18<15:47, 11.84s/it]Running generate_until requests:  52%|█████▏    | 86/165 [16:23<13:04,  9.93s/it]Running generate_until requests:  53%|█████▎    | 87/165 [16:34<13:16, 10.22s/it]Running generate_until requests:  53%|█████▎    | 88/165 [16:45<13:18, 10.37s/it]Running generate_until requests:  54%|█████▍    | 89/165 [16:55<13:18, 10.50s/it]Running generate_until requests:  55%|█████▍    | 90/165 [17:05<12:37, 10.10s/it]Running generate_until requests:  55%|█████▌    | 91/165 [17:17<13:21, 10.83s/it]Running generate_until requests:  56%|█████▌    | 92/165 [17:24<11:50,  9.73s/it]Running generate_until requests:  56%|█████▋    | 93/165 [17:33<11:23,  9.49s/it]Running generate_until requests:  57%|█████▋    | 94/165 [17:41<10:29,  8.87s/it]Running generate_until requests:  58%|█████▊    | 95/165 [17:51<10:58,  9.41s/it]Running generate_until requests:  58%|█████▊    | 96/165 [17:58<10:02,  8.73s/it]Running generate_until requests:  59%|█████▉    | 97/165 [18:07<09:59,  8.82s/it]Running generate_until requests:  59%|█████▉    | 98/165 [18:17<10:00,  8.96s/it]Running generate_until requests:  60%|██████    | 99/165 [18:24<09:15,  8.42s/it]