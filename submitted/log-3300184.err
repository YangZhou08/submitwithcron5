Already on 'addinggriffin'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:35<01:11, 35.57s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:13, 36.72s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:13, 37.00s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:13, 36.71s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:35<01:11, 35.69s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:13, 36.71s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:13, 36.95s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:36<01:13, 36.98s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:07<00:33, 33.12s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:09<00:34, 34.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:09<00:34, 34.31s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:09<00:34, 34.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:09<00:34, 34.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:09<00:34, 34.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:17<00:39, 39.07s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:18<00:39, 39.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 27.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 29.72s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 27.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 29.90s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 27.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 29.90s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:28<00:00, 27.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:28<00:00, 29.56s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 27.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 29.90s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 28.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 29.99s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:42<00:00, 32.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:42<00:00, 34.01s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:42<00:00, 32.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:42<00:00, 34.27s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]  0%|          | 0/153 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  1%|          | 1/153 [00:31<1:20:56, 31.95s/it]  1%|          | 1/153 [00:36<1:33:10, 36.78s/it]  1%|          | 1/153 [00:37<1:34:38, 37.36s/it]  1%|          | 1/153 [00:41<1:46:08, 41.90s/it]  1%|          | 1/153 [00:42<1:48:40, 42.90s/it]  1%|          | 1/153 [01:02<2:38:26, 62.54s/it]  1%|▏         | 2/153 [01:11<1:26:12, 34.26s/it]  1%|▏         | 2/153 [01:16<1:35:01, 37.76s/it]  1%|          | 1/153 [01:16<3:14:28, 76.77s/it]  1%|▏         | 2/153 [01:24<1:48:46, 43.23s/it]  1%|▏         | 2/153 [01:44<2:20:07, 55.68s/it]  1%|▏         | 2/153 [01:49<2:26:04, 58.04s/it]  2%|▏         | 3/153 [01:52<1:32:01, 36.81s/it]  2%|▏         | 3/153 [01:55<1:34:01, 37.61s/it]  1%|          | 1/153 [02:11<5:32:01, 131.06s/it]  1%|▏         | 2/153 [02:15<2:52:37, 68.59s/it]  2%|▏         | 3/153 [02:19<2:04:52, 49.95s/it]  1%|▏         | 2/153 [02:23<2:58:48, 71.05s/it]  2%|▏         | 3/153 [02:32<2:11:16, 52.51s/it]  2%|▏         | 3/153 [02:36<2:12:32, 53.02s/it]  1%|▏         | 2/153 [02:57<3:24:45, 81.36s/it]   3%|▎         | 4/153 [02:58<1:58:24, 47.68s/it]  3%|▎         | 4/153 [03:00<1:45:46, 42.60s/it]  2%|▏         | 3/153 [03:09<2:28:47, 59.52s/it]  3%|▎         | 4/153 [03:10<2:11:55, 53.12s/it]  3%|▎         | 4/153 [03:12<2:07:10, 51.21s/it]  2%|▏         | 3/153 [03:15<2:42:16, 64.91s/it]  3%|▎         | 5/153 [03:45<1:50:12, 44.68s/it]  3%|▎         | 5/153 [03:51<2:02:13, 49.55s/it]  3%|▎         | 4/153 [03:52<2:13:18, 53.68s/it]  3%|▎         | 4/153 [03:57<2:38:17, 63.74s/it]  2%|▏         | 3/153 [04:00<3:02:23, 72.96s/it]  3%|▎         | 5/153 [04:11<2:10:18, 52.83s/it]  3%|▎         | 4/153 [04:13<2:31:44, 61.10s/it]  4%|▍         | 6/153 [04:25<1:48:51, 44.43s/it]  3%|▎         | 5/153 [04:27<1:55:49, 46.96s/it]  3%|▎         | 5/153 [04:29<2:33:54, 62.40s/it]  3%|▎         | 4/153 [04:51<2:39:04, 64.06s/it]  4%|▍         | 6/153 [04:54<2:09:34, 52.89s/it]  4%|▍         | 6/153 [04:55<1:39:39, 40.68s/it]  3%|▎         | 5/153 [05:00<2:37:03, 63.67s/it]  5%|▍         | 7/153 [05:00<1:40:18, 41.22s/it]  3%|▎         | 5/153 [05:15<2:31:43, 61.51s/it]  4%|▍         | 6/153 [05:24<2:26:07, 59.65s/it]  5%|▍         | 7/153 [05:31<1:55:45, 47.57s/it]  5%|▍         | 7/153 [05:37<1:39:41, 40.97s/it]  4%|▍         | 6/153 [05:39<2:38:59, 64.89s/it]  4%|▍         | 6/153 [05:42<2:18:08, 56.39s/it]  3%|▎         | 5/153 [05:47<2:31:31, 61.43s/it]  5%|▌         | 8/153 [05:57<1:38:24, 40.72s/it]  5%|▌         | 8/153 [06:09<1:32:21, 38.22s/it]  5%|▍         | 7/153 [06:13<2:16:34, 56.13s/it]  5%|▌         | 8/153 [06:16<2:06:09, 52.20s/it]  6%|▌         | 9/153 [06:32<1:33:33, 38.98s/it]  5%|▍         | 7/153 [06:44<2:38:15, 65.04s/it]  5%|▌         | 8/153 [06:44<1:56:50, 48.35s/it]  6%|▌         | 9/153 [06:46<1:30:24, 37.67s/it]  5%|▍         | 7/153 [07:04<2:37:16, 64.63s/it]  4%|▍         | 6/153 [07:08<3:13:45, 79.08s/it]  6%|▌         | 9/153 [07:09<2:05:50, 52.43s/it]  6%|▌         | 9/153 [07:10<1:39:15, 41.36s/it]  7%|▋         | 10/153 [07:17<1:24:42, 35.54s/it]  5%|▌         | 8/153 [07:39<2:13:41, 55.32s/it]  7%|▋         | 10/153 [07:43<1:31:57, 38.59s/it]  7%|▋         | 10/153 [07:47<1:59:05, 49.97s/it]  7%|▋         | 10/153 [07:47<1:54:30, 48.04s/it]  4%|▍         | 6/153 [07:58<3:28:17, 85.02s/it]  7%|▋         | 11/153 [08:11<1:24:13, 35.59s/it]  7%|▋         | 11/153 [08:17<1:40:45, 42.58s/it]  5%|▌         | 8/153 [08:18<2:59:09, 74.13s/it]  7%|▋         | 11/153 [08:21<1:46:55, 45.18s/it]  7%|▋         | 11/153 [08:37<1:56:50, 49.37s/it]  6%|▌         | 9/153 [08:48<2:23:04, 59.61s/it]  8%|▊         | 12/153 [08:53<1:36:57, 41.26s/it]  8%|▊         | 12/153 [08:54<1:35:49, 40.78s/it]  5%|▍         | 7/153 [09:01<3:39:17, 90.12s/it]  8%|▊         | 12/153 [09:12<1:45:44, 45.00s/it]  7%|▋         | 10/153 [09:22<2:03:06, 51.65s/it]  8%|▊         | 13/153 [09:28<1:30:37, 38.84s/it]  8%|▊         | 13/153 [09:30<1:32:58, 39.84s/it]  8%|▊         | 12/153 [09:31<1:54:58, 48.93s/it]  8%|▊         | 13/153 [09:52<1:41:34, 43.53s/it]  6%|▌         | 9/153 [09:54<3:14:27, 81.02s/it]  7%|▋         | 11/153 [09:58<1:50:26, 46.67s/it]  5%|▍         | 7/153 [09:59<3:55:15, 96.68s/it]  9%|▉         | 14/153 [10:01<1:25:54, 37.09s/it]  9%|▉         | 14/153 [10:04<1:28:01, 37.99s/it]  5%|▌         | 8/153 [10:17<3:27:01, 85.67s/it]  7%|▋         | 10/153 [10:31<2:41:10, 67.62s/it] 10%|▉         | 15/153 [10:32<1:20:37, 35.06s/it]  8%|▊         | 13/153 [10:43<2:10:30, 55.93s/it]  9%|▉         | 14/153 [10:52<1:52:14, 48.45s/it]  8%|▊         | 12/153 [10:57<1:58:37, 50.48s/it] 10%|▉         | 15/153 [11:12<1:48:46, 47.29s/it]  7%|▋         | 11/153 [11:20<2:26:21, 61.84s/it]  9%|▉         | 14/153 [11:32<2:05:00, 53.96s/it]  6%|▌         | 9/153 [11:33<3:18:22, 82.66s/it] 10%|▉         | 15/153 [11:43<1:53:11, 49.22s/it]  5%|▌         | 8/153 [11:48<4:03:20, 100.70s/it] 10%|█         | 16/153 [11:50<1:50:03, 48.20s/it] 10%|█         | 16/153 [11:52<1:42:30, 44.89s/it]  8%|▊         | 12/153 [12:03<2:11:56, 56.14s/it]  8%|▊         | 13/153 [12:04<2:09:52, 55.66s/it] 10%|▉         | 15/153 [12:13<1:55:06, 50.05s/it] 11%|█         | 17/153 [12:17<1:34:59, 41.91s/it] 11%|█         | 17/153 [12:28<1:35:58, 42.34s/it]  9%|▉         | 14/153 [12:30<1:47:39, 46.47s/it]  8%|▊         | 13/153 [12:38<1:56:01, 49.72s/it] 10%|█         | 16/153 [12:49<1:44:30, 45.77s/it]  7%|▋         | 10/153 [12:49<3:12:10, 80.63s/it] 10%|█         | 16/153 [12:50<2:04:26, 54.50s/it]  6%|▌         | 9/153 [12:52<3:34:20, 89.31s/it]  12%|█▏        | 18/153 [12:56<1:25:37, 38.06s/it] 12%|█▏        | 18/153 [13:04<1:37:11, 43.20s/it] 10%|▉         | 15/153 [13:05<1:39:11, 43.12s/it] 12%|█▏        | 19/153 [13:33<1:27:16, 39.08s/it] 12%|█▏        | 19/153 [13:34<1:24:30, 37.84s/it]  7%|▋         | 10/153 [13:39<3:01:24, 76.12s/it] 10%|█         | 16/153 [13:42<1:34:35, 41.43s/it]  7%|▋         | 11/153 [13:42<2:51:01, 72.26s/it] 11%|█         | 17/153 [14:00<2:14:23, 59.29s/it]  9%|▉         | 14/153 [14:03<2:19:53, 60.39s/it] 13%|█▎        | 20/153 [14:06<1:20:10, 36.17s/it] 11%|█         | 17/153 [14:06<2:04:51, 55.08s/it] 13%|█▎        | 20/153 [14:12<1:26:33, 39.05s/it] 11%|█         | 17/153 [14:23<1:33:05, 41.07s/it] 12%|█▏        | 18/153 [14:36<1:47:05, 47.59s/it] 14%|█▎        | 21/153 [14:42<1:20:03, 36.39s/it] 10%|▉         | 15/153 [14:47<2:07:30, 55.44s/it]  8%|▊         | 12/153 [14:52<2:48:01, 71.50s/it]  7%|▋         | 11/153 [14:53<2:58:40, 75.50s/it] 12%|█▏        | 19/153 [15:05<1:33:41, 41.95s/it] 12%|█▏        | 18/153 [15:05<1:33:21, 41.49s/it] 12%|█▏        | 18/153 [15:10<2:20:28, 62.43s/it] 14%|█▎        | 21/153 [15:11<1:38:41, 44.86s/it] 10%|█         | 16/153 [15:27<1:55:33, 50.61s/it] 13%|█▎        | 20/153 [15:33<1:23:42, 37.76s/it] 12%|█▏        | 19/153 [15:33<1:23:39, 37.46s/it] 14%|█▍        | 22/153 [15:34<1:29:42, 41.09s/it] 14%|█▍        | 22/153 [15:45<1:30:41, 41.54s/it] 12%|█▏        | 19/153 [15:49<2:03:56, 55.49s/it]  8%|▊         | 12/153 [15:53<2:46:38, 70.91s/it]  8%|▊         | 13/153 [15:56<2:41:07, 69.06s/it] 13%|█▎        | 20/153 [16:00<1:15:55, 34.25s/it] 14%|█▎        | 21/153 [16:10<1:22:49, 37.65s/it] 11%|█         | 17/153 [16:12<1:50:57, 48.95s/it] 15%|█▌        | 23/153 [16:18<1:30:32, 41.79s/it] 13%|█▎        | 20/153 [16:33<1:55:04, 51.91s/it] 15%|█▌        | 23/153 [16:38<1:37:50, 45.16s/it] 14%|█▎        | 21/153 [16:40<1:18:54, 35.87s/it] 12%|█▏        | 18/153 [17:08<1:54:50, 51.04s/it] 14%|█▎        | 21/153 [17:10<1:44:22, 47.45s/it]  8%|▊         | 13/153 [17:10<2:49:37, 72.70s/it] 16%|█▌        | 24/153 [17:13<1:30:09, 41.93s/it]  9%|▉         | 14/153 [17:13<2:45:49, 71.58s/it] 16%|█▌        | 24/153 [17:22<1:44:30, 48.61s/it] 14%|█▍        | 22/153 [17:26<1:47:10, 49.09s/it] 14%|█▍        | 22/153 [17:48<1:37:17, 44.56s/it] 12%|█▏        | 19/153 [17:51<1:48:37, 48.63s/it] 14%|█▍        | 22/153 [17:52<1:42:17, 46.85s/it] 15%|█▌        | 23/153 [18:00<1:36:50, 44.70s/it] 10%|▉         | 15/153 [18:03<2:29:23, 64.95s/it] 16%|█▋        | 25/153 [18:04<1:35:04, 44.56s/it] 16%|█▋        | 25/153 [18:09<1:42:41, 48.13s/it]  9%|▉         | 14/153 [18:17<2:44:14, 70.89s/it] 15%|█▌        | 23/153 [18:21<1:28:51, 41.01s/it] 15%|█▌        | 23/153 [18:26<1:33:02, 42.94s/it] 13%|█▎        | 20/153 [18:27<1:39:33, 44.91s/it] 16%|█▌        | 24/153 [18:30<1:26:20, 40.16s/it] 17%|█▋        | 26/153 [18:33<1:24:40, 40.00s/it] 16%|█▌        | 24/153 [18:48<1:19:37, 37.04s/it] 16%|█▋        | 25/153 [19:05<1:22:31, 38.68s/it] 16%|█▌        | 24/153 [19:06<1:30:13, 41.96s/it] 10%|█         | 16/153 [19:06<2:27:16, 64.50s/it] 17%|█▋        | 26/153 [19:07<1:48:11, 51.11s/it] 18%|█▊        | 27/153 [19:08<1:20:58, 38.56s/it] 10%|▉         | 15/153 [19:14<2:33:14, 66.63s/it] 17%|█▋        | 26/153 [19:33<1:15:05, 35.48s/it] 14%|█▎        | 21/153 [19:37<1:55:41, 52.59s/it] 18%|█▊        | 27/153 [19:38<1:34:05, 44.80s/it] 16%|█▋        | 25/153 [19:38<1:23:21, 39.07s/it] 18%|█▊        | 28/153 [19:51<1:23:17, 39.98s/it] 10%|█         | 16/153 [20:04<2:20:56, 61.73s/it] 16%|█▋        | 25/153 [20:07<1:45:31, 49.46s/it] 11%|█         | 17/153 [20:12<2:27:09, 64.92s/it] 19%|█▉        | 29/153 [20:17<1:13:35, 35.61s/it] 18%|█▊        | 28/153 [20:21<1:32:23, 44.35s/it] 18%|█▊        | 27/153 [20:29<1:27:23, 41.61s/it] 17%|█▋        | 26/153 [20:49<1:43:11, 48.75s/it] 14%|█▍        | 22/153 [20:55<2:11:03, 60.03s/it] 19%|█▉        | 29/153 [20:56<1:26:09, 41.69s/it] 18%|█▊        | 28/153 [21:04<1:22:22, 39.54s/it] 11%|█         | 17/153 [21:08<2:21:38, 62.49s/it] 20%|█▉        | 30/153 [21:16<1:27:21, 42.62s/it] 18%|█▊        | 27/153 [21:22<1:32:32, 44.07s/it] 15%|█▌        | 23/153 [21:28<1:52:49, 52.07s/it] 17%|█▋        | 26/153 [21:34<2:08:40, 60.79s/it] 20%|██        | 31/153 [21:46<1:19:17, 39.00s/it] 19%|█▉        | 29/153 [21:51<1:26:14, 41.73s/it] 12%|█▏        | 18/153 [21:55<2:09:55, 57.75s/it] 16%|█▌        | 24/153 [22:08<1:44:10, 48.45s/it] 18%|█▊        | 28/153 [22:11<1:34:27, 45.34s/it] 12%|█▏        | 18/153 [22:11<3:02:46, 81.23s/it] 20%|█▉        | 30/153 [22:17<1:15:50, 37.00s/it] 18%|█▊        | 27/153 [22:18<1:56:52, 55.66s/it] 20%|█▉        | 30/153 [22:18<1:50:18, 53.81s/it] 19%|█▉        | 29/153 [22:43<1:25:18, 41.28s/it] 20%|██        | 31/153 [22:43<1:31:27, 44.98s/it] 20%|██        | 31/153 [22:44<1:09:22, 34.11s/it] 16%|█▋        | 25/153 [22:45<1:35:39, 44.84s/it] 21%|██        | 32/153 [22:51<1:34:03, 46.64s/it] 12%|█▏        | 19/153 [23:04<2:16:41, 61.20s/it] 18%|█▊        | 28/153 [23:08<1:52:31, 54.01s/it] 20%|█▉        | 30/153 [23:10<1:16:07, 37.14s/it] 22%|██▏       | 33/153 [23:22<1:23:59, 42.00s/it] 20%|██        | 31/153 [23:40<1:11:21, 35.09s/it] 17%|█▋        | 26/153 [23:42<1:43:05, 48.71s/it] 21%|██        | 32/153 [23:48<1:26:52, 43.08s/it] 21%|██        | 32/153 [23:52<1:45:12, 52.17s/it] 12%|█▏        | 19/153 [24:01<3:20:50, 89.93s/it] 19%|█▉        | 29/153 [24:08<1:55:33, 55.92s/it] 22%|██▏       | 34/153 [24:10<1:26:50, 43.79s/it] 21%|██        | 32/153 [24:19<1:13:05, 36.24s/it] 22%|██▏       | 33/153 [24:28<1:34:57, 47.48s/it] 13%|█▎        | 20/153 [24:30<2:31:50, 68.50s/it] 22%|██▏       | 33/153 [24:30<1:25:19, 42.66s/it] 20%|█▉        | 30/153 [24:38<1:38:35, 48.10s/it] 23%|██▎       | 35/153 [24:50<1:24:12, 42.82s/it] 18%|█▊        | 27/153 [24:54<1:56:29, 55.47s/it] 13%|█▎        | 20/153 [24:54<2:54:11, 78.58s/it] 22%|██▏       | 33/153 [24:56<1:12:47, 36.39s/it] 22%|██▏       | 34/153 [25:02<1:18:06, 39.38s/it] 22%|██▏       | 34/153 [25:04<1:27:25, 44.08s/it] 24%|██▎       | 36/153 [25:16<1:13:20, 37.62s/it] 20%|██        | 31/153 [25:17<1:32:00, 45.25s/it]