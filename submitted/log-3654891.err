Already on 'yangexppp'
From github.com:Infini-AI-Lab/GRIFFIN2
   26466c1..304f3cb  yangexppp  -> origin/yangexppp
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-08-03:04:47:58,014 INFO     [main.py:288] Verbosity set to INFO
2024-08-03:04:48:08,679 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-08-03:04:48:08,681 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-08-03:04:48:08,760 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-08-03:04:48:08,761 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-70B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1500, 'kernel_size': 16, 'thr': 0.05}
2024-08-03:04:48:08,982 INFO     [xhuggingface.py:176] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:05<02:41,  5.56s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:11<02:35,  5.55s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:16<02:32,  5.65s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:22<02:27,  5.69s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:28<02:20,  5.61s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:33<02:13,  5.54s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:38<02:06,  5.48s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:44<02:02,  5.58s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:50<01:57,  5.60s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:55<01:51,  5.58s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [01:01<01:45,  5.56s/it]Loading checkpoint shards:  40%|████      | 12/30 [01:06<01:39,  5.53s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [01:12<01:35,  5.60s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [01:18<01:31,  5.69s/it]Loading checkpoint shards:  50%|█████     | 15/30 [01:24<01:25,  5.67s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [01:29<01:19,  5.66s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [01:35<01:13,  5.63s/it]Loading checkpoint shards:  60%|██████    | 18/30 [01:41<01:08,  5.72s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [01:47<01:04,  5.82s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [01:52<00:57,  5.79s/it]Loading checkpoint shards:  70%|███████   | 21/30 [01:58<00:51,  5.73s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [02:04<00:45,  5.73s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [02:10<00:40,  5.80s/it]Loading checkpoint shards:  80%|████████  | 24/30 [02:16<00:34,  5.83s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [02:21<00:28,  5.75s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [02:27<00:22,  5.71s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [02:33<00:17,  5.70s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [02:38<00:11,  5.72s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [02:44<00:05,  5.68s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:46<00:00,  4.73s/it]Loading checkpoint shards: 100%|██████████| 30/30 [02:46<00:00,  5.56s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-08-03:04:51:02,451 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-03:04:51:02,451 WARNING  [task.py:322] [Task: gsm8k_cot] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-08-03:04:51:02,539 INFO     [task.py:395] Building contexts for gsm8k_cot on rank 0...
  0%|          | 0/500 [00:00<?, ?it/s] 34%|███▍      | 169/500 [00:00<00:00, 1682.22it/s] 68%|██████▊   | 338/500 [00:00<00:00, 1684.60it/s]100%|██████████| 500/500 [00:00<00:00, 1680.43it/s]
2024-08-03:04:51:02,849 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/500 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 1/500 [00:54<7:37:15, 54.98s/it]Running generate_until requests:   0%|          | 2/500 [01:39<6:44:29, 48.73s/it]Running generate_until requests:   1%|          | 3/500 [02:16<6:00:40, 43.54s/it]Running generate_until requests:   1%|          | 4/500 [02:43<5:05:00, 36.90s/it]Running generate_until requests:   1%|          | 5/500 [03:27<5:24:22, 39.32s/it]Running generate_until requests:   1%|          | 6/500 [03:56<4:56:50, 36.05s/it]Running generate_until requests:   1%|▏         | 7/500 [04:41<5:20:00, 38.95s/it]Running generate_until requests:   2%|▏         | 8/500 [05:20<5:18:17, 38.82s/it]Running generate_until requests:   2%|▏         | 9/500 [05:43<4:39:13, 34.12s/it]Running generate_until requests:   2%|▏         | 10/500 [06:28<5:04:21, 37.27s/it]Running generate_until requests:   2%|▏         | 11/500 [07:08<5:10:43, 38.12s/it]Running generate_until requests:   2%|▏         | 12/500 [08:22<6:40:19, 49.22s/it]Running generate_until requests:   3%|▎         | 13/500 [09:12<6:40:18, 49.32s/it]Running generate_until requests:   3%|▎         | 14/500 [09:36<5:36:29, 41.54s/it]Running generate_until requests:   3%|▎         | 15/500 [09:57<4:46:00, 35.38s/it]Running generate_until requests:   3%|▎         | 16/500 [10:42<5:08:24, 38.23s/it]Running generate_until requests:   3%|▎         | 17/500 [11:09<4:41:28, 34.97s/it]Running generate_until requests:   4%|▎         | 18/500 [11:35<4:20:04, 32.37s/it]Running generate_until requests:   4%|▍         | 19/500 [11:58<3:57:33, 29.63s/it]Running generate_until requests:   4%|▍         | 20/500 [12:46<4:40:16, 35.03s/it]Running generate_until requests:   4%|▍         | 21/500 [13:29<4:57:36, 37.28s/it]