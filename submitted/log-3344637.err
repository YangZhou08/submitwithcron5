wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.07s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.72s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.26s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.26s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.36s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.57s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.41s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.14s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.40s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.16s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.24s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.17s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.33s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.23s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.29s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [01:30<30:17, 90.87s/it]  5%|▍         | 1/21 [01:30<30:03, 90.16s/it]  5%|▍         | 1/21 [01:30<30:18, 90.93s/it]  5%|▍         | 1/21 [01:08<22:57, 68.85s/it]  5%|▍         | 1/21 [01:30<30:05, 90.26s/it]  5%|▍         | 1/21 [01:30<30:11, 90.58s/it]  5%|▍         | 1/21 [01:30<30:15, 90.80s/it]  5%|▍         | 1/21 [01:09<23:04, 69.21s/it] 10%|▉         | 2/21 [02:15<20:13, 63.87s/it] 10%|▉         | 2/21 [02:15<20:16, 64.00s/it] 10%|▉         | 2/21 [02:16<20:17, 64.09s/it] 10%|▉         | 2/21 [02:16<20:18, 64.14s/it] 10%|▉         | 2/21 [01:54<17:28, 55.20s/it] 10%|▉         | 2/21 [02:16<20:18, 64.12s/it] 10%|▉         | 2/21 [02:15<20:12, 63.83s/it] 10%|▉         | 2/21 [01:54<17:26, 55.05s/it] 14%|█▍        | 3/21 [02:42<15:35, 51.98s/it] 14%|█▍        | 3/21 [03:03<17:00, 56.69s/it] 14%|█▍        | 3/21 [03:04<17:01, 56.76s/it] 14%|█▍        | 3/21 [03:03<16:59, 56.66s/it] 14%|█▍        | 3/21 [03:04<17:03, 56.84s/it] 14%|█▍        | 3/21 [02:42<15:34, 51.90s/it] 14%|█▍        | 3/21 [03:04<17:02, 56.82s/it] 14%|█▍        | 3/21 [03:04<17:02, 56.81s/it] 19%|█▉        | 4/21 [03:52<16:43, 59.02s/it] 19%|█▉        | 4/21 [03:52<16:42, 58.97s/it] 19%|█▉        | 4/21 [04:14<17:33, 61.96s/it] 19%|█▉        | 4/21 [04:13<17:31, 61.87s/it] 19%|█▉        | 4/21 [04:13<17:32, 61.91s/it] 19%|█▉        | 4/21 [04:14<17:33, 61.94s/it] 19%|█▉        | 4/21 [04:13<17:31, 61.86s/it] 19%|█▉        | 4/21 [04:14<17:33, 61.95s/it] 24%|██▍       | 5/21 [04:52<15:48, 59.30s/it] 24%|██▍       | 5/21 [05:14<16:19, 61.22s/it] 24%|██▍       | 5/21 [05:13<16:18, 61.16s/it] 24%|██▍       | 5/21 [04:52<15:49, 59.34s/it] 24%|██▍       | 5/21 [05:14<16:19, 61.20s/it] 24%|██▍       | 5/21 [05:13<16:18, 61.19s/it] 24%|██▍       | 5/21 [05:14<16:19, 61.21s/it] 24%|██▍       | 5/21 [05:13<16:18, 61.15s/it] 29%|██▊       | 6/21 [05:40<13:52, 55.47s/it] 29%|██▊       | 6/21 [06:01<14:10, 56.67s/it] 29%|██▊       | 6/21 [06:02<14:10, 56.71s/it] 29%|██▊       | 6/21 [06:02<14:10, 56.71s/it] 29%|██▊       | 6/21 [06:01<14:10, 56.69s/it] 29%|██▊       | 6/21 [06:02<14:10, 56.70s/it] 29%|██▊       | 6/21 [05:40<13:51, 55.45s/it] 29%|██▊       | 6/21 [06:01<14:10, 56.67s/it] 33%|███▎      | 7/21 [06:42<13:27, 57.68s/it] 33%|███▎      | 7/21 [07:04<13:39, 58.53s/it] 33%|███▎      | 7/21 [07:04<13:39, 58.52s/it] 33%|███▎      | 7/21 [07:03<13:38, 58.50s/it] 33%|███▎      | 7/21 [07:03<13:39, 58.50s/it] 33%|███▎      | 7/21 [07:04<13:39, 58.52s/it] 33%|███▎      | 7/21 [06:42<13:27, 57.69s/it] 33%|███▎      | 7/21 [07:04<13:39, 58.53s/it] 38%|███▊      | 8/21 [08:05<12:52, 59.41s/it] 38%|███▊      | 8/21 [07:43<12:44, 58.84s/it] 38%|███▊      | 8/21 [07:43<12:44, 58.83s/it] 38%|███▊      | 8/21 [08:04<12:52, 59.39s/it] 38%|███▊      | 8/21 [08:05<12:52, 59.40s/it] 38%|███▊      | 8/21 [08:05<12:52, 59.39s/it] 38%|███▊      | 8/21 [08:05<12:52, 59.41s/it] 38%|███▊      | 8/21 [08:05<12:52, 59.41s/it] 43%|████▎     | 9/21 [08:57<12:41, 63.45s/it] 43%|████▎     | 9/21 [08:57<12:41, 63.46s/it] 43%|████▎     | 9/21 [09:19<12:46, 63.85s/it] 43%|████▎     | 9/21 [09:18<12:46, 63.83s/it] 43%|████▎     | 9/21 [09:19<12:46, 63.84s/it] 43%|████▎     | 9/21 [09:18<12:46, 63.84s/it] 43%|████▎     | 9/21 [09:19<12:46, 63.85s/it] 43%|████▎     | 9/21 [09:18<12:46, 63.84s/it] 48%|████▊     | 10/21 [09:59<11:31, 62.87s/it] 48%|████▊     | 10/21 [09:58<11:31, 62.86s/it] 48%|████▊     | 10/21 [10:20<11:34, 63.14s/it] 48%|████▊     | 10/21 [10:20<11:34, 63.14s/it] 48%|████▊     | 10/21 [10:20<11:34, 63.14s/it] 48%|████▊     | 10/21 [10:20<11:34, 63.13s/it] 48%|████▊     | 10/21 [10:20<11:34, 63.13s/it] 48%|████▊     | 10/21 [10:20<11:34, 63.13s/it] 52%|█████▏    | 11/21 [11:08<09:42, 58.29s/it] 52%|█████▏    | 11/21 [11:08<09:42, 58.29s/it] 52%|█████▏    | 11/21 [11:07<09:42, 58.29s/it] 52%|█████▏    | 11/21 [11:07<09:42, 58.29s/it] 52%|█████▏    | 11/21 [10:46<09:41, 58.11s/it] 52%|█████▏    | 11/21 [11:08<09:42, 58.29s/it] 52%|█████▏    | 11/21 [10:46<09:41, 58.10s/it] 52%|█████▏    | 11/21 [11:07<09:42, 58.29s/it] 57%|█████▋    | 12/21 [12:03<08:39, 57.68s/it] 57%|█████▋    | 12/21 [12:04<08:39, 57.68s/it] 57%|█████▋    | 12/21 [12:03<08:39, 57.67s/it] 57%|█████▋    | 12/21 [12:04<08:39, 57.68s/it] 57%|█████▋    | 12/21 [12:04<08:39, 57.68s/it] 57%|█████▋    | 12/21 [12:04<08:39, 57.68s/it] 57%|█████▋    | 12/21 [11:42<08:37, 57.55s/it] 57%|█████▋    | 12/21 [11:42<08:37, 57.55s/it] 62%|██████▏   | 13/21 [12:36<07:32, 56.60s/it] 62%|██████▏   | 13/21 [12:58<07:33, 56.69s/it] 62%|██████▏   | 13/21 [12:58<07:33, 56.69s/it] 62%|██████▏   | 13/21 [12:58<07:33, 56.69s/it] 62%|██████▏   | 13/21 [12:58<07:33, 56.69s/it] 62%|██████▏   | 13/21 [12:58<07:33, 56.69s/it] 62%|██████▏   | 13/21 [12:37<07:32, 56.60s/it] 62%|██████▏   | 13/21 [12:58<07:33, 56.69s/it] 67%|██████▋   | 14/21 [13:57<06:42, 57.54s/it] 67%|██████▋   | 14/21 [13:57<06:42, 57.54s/it] 67%|██████▋   | 14/21 [13:36<06:42, 57.48s/it] 67%|██████▋   | 14/21 [13:36<06:42, 57.48s/it] 67%|██████▋   | 14/21 [13:58<06:42, 57.55s/it] 67%|██████▋   | 14/21 [13:58<06:42, 57.54s/it] 67%|██████▋   | 14/21 [13:58<06:42, 57.55s/it] 67%|██████▋   | 14/21 [13:58<06:42, 57.55s/it] 71%|███████▏  | 15/21 [14:47<05:31, 55.28s/it] 71%|███████▏  | 15/21 [14:47<05:31, 55.28s/it] 71%|███████▏  | 15/21 [14:48<05:31, 55.28s/it] 71%|███████▏  | 15/21 [14:48<05:31, 55.28s/it] 71%|███████▏  | 15/21 [14:26<05:31, 55.24s/it] 71%|███████▏  | 15/21 [14:26<05:31, 55.24s/it] 71%|███████▏  | 15/21 [14:48<05:31, 55.28s/it] 71%|███████▏  | 15/21 [14:48<05:31, 55.28s/it] 76%|███████▌  | 16/21 [15:24<04:39, 55.97s/it] 76%|███████▌  | 16/21 [15:45<04:40, 56.00s/it] 76%|███████▌  | 16/21 [15:45<04:40, 56.00s/it] 76%|███████▌  | 16/21 [15:45<04:40, 56.00s/it] 76%|███████▌  | 16/21 [15:45<04:40, 56.00s/it] 76%|███████▌  | 16/21 [15:46<04:40, 56.00s/it] 76%|███████▌  | 16/21 [15:24<04:39, 55.97s/it] 76%|███████▌  | 16/21 [15:46<04:40, 56.00s/it] 81%|████████  | 17/21 [16:39<03:41, 55.38s/it] 81%|████████  | 17/21 [16:39<03:41, 55.38s/it] 81%|████████  | 17/21 [16:39<03:41, 55.38s/it] 81%|████████  | 17/21 [16:40<03:41, 55.38s/it] 81%|████████  | 17/21 [16:17<03:41, 55.36s/it] 81%|████████  | 17/21 [16:18<03:41, 55.36s/it] 81%|████████  | 17/21 [16:39<03:41, 55.38s/it] 81%|████████  | 17/21 [16:39<03:41, 55.38s/it] 86%|████████▌ | 18/21 [17:17<02:49, 56.53s/it] 86%|████████▌ | 18/21 [17:17<02:49, 56.53s/it] 86%|████████▌ | 18/21 [17:39<02:49, 56.54s/it] 86%|████████▌ | 18/21 [17:38<02:49, 56.54s/it] 86%|████████▌ | 18/21 [17:38<02:49, 56.54s/it] 86%|████████▌ | 18/21 [17:39<02:49, 56.54s/it] 86%|████████▌ | 18/21 [17:39<02:49, 56.54s/it] 86%|████████▌ | 18/21 [17:38<02:49, 56.54s/it] 90%|█████████ | 19/21 [18:06<01:48, 54.36s/it] 90%|█████████ | 19/21 [18:28<01:48, 54.37s/it] 90%|█████████ | 19/21 [18:28<01:48, 54.37s/it] 90%|█████████ | 19/21 [18:27<01:48, 54.37s/it] 90%|█████████ | 19/21 [18:27<01:48, 54.37s/it] 90%|█████████ | 19/21 [18:28<01:48, 54.37s/it] 90%|█████████ | 19/21 [18:28<01:48, 54.37s/it] 90%|█████████ | 19/21 [18:06<01:48, 54.36s/it] 95%|█████████▌| 20/21 [19:10<00:50, 50.82s/it] 95%|█████████▌| 20/21 [19:11<00:50, 50.82s/it] 95%|█████████▌| 20/21 [18:49<00:50, 50.81s/it] 95%|█████████▌| 20/21 [19:10<00:50, 50.82s/it] 95%|█████████▌| 20/21 [19:11<00:50, 50.82s/it] 95%|█████████▌| 20/21 [19:11<00:50, 50.82s/it] 95%|█████████▌| 20/21 [19:10<00:50, 50.82s/it] 95%|█████████▌| 20/21 [18:49<00:50, 50.81s/it]100%|██████████| 21/21 [19:47<00:00, 53.02s/it]100%|██████████| 21/21 [20:09<00:00, 53.03s/it]100%|██████████| 21/21 [20:08<00:00, 53.03s/it]100%|██████████| 21/21 [20:08<00:00, 53.03s/it]100%|██████████| 21/21 [20:09<00:00, 53.03s/it]100%|██████████| 21/21 [20:09<00:00, 53.03s/it]100%|██████████| 21/21 [20:08<00:00, 53.03s/it]100%|██████████| 21/21 [19:47<00:00, 53.02s/it]22it [20:49, 55.62s/it]                        22it [21:11, 55.63s/it]                        22it [20:48, 55.62s/it]                        22it [21:10, 55.63s/it]                        22it [21:10, 55.63s/it]                        22it [21:10, 55.63s/it]                        22it [21:10, 55.63s/it]                        22it [21:10, 55.63s/it]                        23it [21:44, 55.52s/it]23it [22:06, 55.53s/it]23it [22:05, 55.53s/it]23it [22:05, 55.53s/it]23it [22:06, 55.53s/it]23it [22:06, 55.53s/it]23it [22:05, 55.53s/it]23it [21:44, 55.52s/it]24it [22:48, 51.65s/it]24it [22:48, 51.65s/it]24it [22:48, 51.65s/it]24it [22:48, 51.65s/it]24it [22:48, 51.65s/it]24it [22:26, 51.65s/it]24it [22:27, 51.65s/it]24it [22:48, 51.65s/it]25it [23:29, 55.07s/it]25it [23:51, 55.07s/it]25it [23:51, 55.07s/it]25it [23:51, 55.07s/it]25it [23:51, 55.07s/it]25it [23:30, 55.07s/it]25it [23:51, 55.07s/it]25it [23:51, 55.07s/it]26it [24:24, 54.97s/it]26it [24:24, 54.97s/it]26it [24:45, 54.97s/it]26it [24:46, 54.97s/it]26it [24:46, 54.97s/it]26it [24:46, 54.97s/it]26it [24:46, 54.97s/it]26it [24:46, 54.97s/it]27it [25:34, 52.73s/it]27it [25:33, 52.73s/it]27it [25:33, 52.73s/it]27it [25:12, 52.73s/it]27it [25:33, 52.73s/it]27it [25:34, 52.73s/it]27it [25:12, 52.73s/it]27it [25:34, 52.73s/it]28it [26:18, 50.30s/it]28it [26:18, 50.30s/it]28it [26:18, 50.30s/it]28it [26:18, 50.30s/it]28it [25:56, 50.30s/it]28it [26:18, 50.30s/it]28it [25:57, 50.30s/it]28it [26:18, 50.30s/it]29it [27:06, 56.10s/it]29it [27:06, 56.10s/it]29it [27:28, 56.10s/it]29it [27:28, 56.10s/it]29it [27:28, 56.10s/it]29it [27:27, 56.10s/it]29it [27:27, 56.10s/it]29it [27:28, 56.10s/it]30it [28:13, 52.94s/it]30it [27:52, 52.94s/it]30it [28:14, 52.94s/it]30it [28:13, 52.94s/it]30it [28:13, 52.94s/it]30it [28:13, 52.94s/it]30it [28:13, 52.94s/it]30it [27:51, 52.94s/it]31it [28:52, 55.16s/it]31it [29:14, 55.16s/it]31it [29:14, 55.16s/it]31it [29:14, 55.16s/it]31it [28:52, 55.16s/it]31it [29:14, 55.16s/it]31it [29:13, 55.16s/it]31it [29:13, 55.16s/it]32it [29:33, 50.93s/it]32it [29:55, 50.93s/it]32it [29:55, 50.93s/it]32it [29:33, 50.93s/it]32it [29:54, 50.93s/it]32it [29:55, 50.93s/it]32it [29:54, 50.93s/it]32it [29:55, 50.93s/it]33it [30:26, 45.27s/it]33it [30:27, 45.27s/it]33it [30:26, 45.27s/it]33it [30:27, 45.27s/it]33it [30:27, 45.27s/it]33it [30:27, 45.27s/it]33it [30:05, 45.27s/it]33it [30:05, 45.27s/it]34it [31:06, 43.40s/it]34it [31:05, 43.40s/it]34it [31:06, 43.40s/it]34it [31:06, 43.40s/it]34it [31:06, 43.40s/it]34it [31:05, 43.40s/it]34it [30:44, 43.40s/it]34it [30:44, 43.40s/it]35it [31:53, 44.59s/it]35it [31:53, 44.59s/it]35it [31:53, 44.59s/it]35it [31:53, 44.59s/it]35it [31:53, 44.59s/it]35it [31:31, 44.59s/it]35it [31:53, 44.59s/it]35it [31:32, 44.59s/it]36it [32:40, 45.14s/it]36it [32:39, 45.14s/it]36it [32:39, 45.14s/it]36it [32:39, 45.14s/it]36it [32:40, 45.14s/it]36it [32:40, 45.14s/it]36it [32:18, 45.14s/it]36it [32:18, 45.14s/it]37it [33:21, 50.56s/it]37it [33:43, 50.56s/it]37it [33:43, 50.56s/it]37it [33:21, 50.56s/it]37it [33:42, 50.56s/it]37it [33:42, 50.56s/it]37it [33:43, 50.56s/it]37it [33:43, 50.56s/it]38it [34:41, 52.73s/it]38it [34:40, 52.73s/it]38it [34:40, 52.73s/it]38it [34:19, 52.73s/it]38it [34:40, 52.73s/it]38it [34:41, 52.73s/it]38it [34:41, 52.73s/it]38it [34:19, 52.73s/it]39it [35:28, 51.18s/it]39it [35:28, 51.18s/it]39it [35:28, 51.18s/it]39it [35:28, 51.18s/it]39it [35:28, 51.18s/it]39it [35:28, 51.18s/it]39it [35:06, 51.18s/it]39it [35:07, 51.18s/it]40it [35:51, 49.22s/it]40it [35:51, 49.22s/it]40it [36:13, 49.22s/it]40it [36:12, 49.22s/it]40it [36:12, 49.22s/it]40it [36:13, 49.22s/it]40it [36:13, 49.22s/it]40it [36:13, 49.22s/it]41it [36:56, 53.93s/it]41it [37:18, 53.93s/it]41it [37:17, 53.93s/it]41it [37:18, 53.93s/it]41it [36:56, 53.93s/it]41it [37:18, 53.93s/it]41it [37:18, 53.93s/it]41it [37:17, 53.93s/it]41it [37:18, 54.60s/it]41it [37:17, 54.58s/it]41it [37:18, 54.59s/it]41it [37:18, 54.59s/it]

41it [36:56, 54.07s/it]
41it [36:56, 54.06s/it]
41it [37:18, 54.59s/it]


41it [37:17, 54.58s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
