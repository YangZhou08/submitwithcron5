Your branch is up to date with 'origin/addinggriffin'.
Already up to date.
Already up to date.
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /data/home/beidic/.cache/huggingface/token
Login successful
NCCL_TIMEOUT 1800
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
We now use eos_token as pad token
beam width is 8
is_distributed True
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device=None, limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']tasks ['strategyqa']

tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
beamwidth is 1
beamwidth is 1
beamwidth is 1
beamwidth is 1
beamwidth is 1
beamwidth is 1
beamwidth is 1
beamwidth is 1
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected yes
Answer no expected no
Answer no expected no
Answer no expected yes
Answer yes expected yes
Answer no expected yes
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected yes
Skipping the batch
Answer no expected yes
Answer no expected yes
Skipping the batch
Answer no expected yes
Answer no expected no
Skipping the batch
Answer no expected no
Answer no expected no
Answer no expected no
Skipping the batch
Answer yes expected no
Answer no expected no
Answer no expected no
Answer  not cause more expensive dental bills.

 q: yes or n expected yes
Answer yes expected no
Answer no expected no
Answer no expected no
Answer no expected yes
Answer lix shows is 10 hours of 1080p video at 60 frames per second. 1080p video takes up 1gb per hour. 1gb = 1000mb. 1000mb = 1gb. 1gb = 1024mb. 1024mb = 1024kb. 1024kb = 1024 bytes. 1024 bytes = 1024 * 8 = 8192 bytes. 8192 bytes = 8192 * 8 = 65,536 bytes. 65,536 bytes = 65,536 * 8 = 518,432 bytes. 518,432 bytes = 518,432 * 8 = 4,193,072 bytes. 4,193,072 bytes = 4,193,072 * 8 = 33,109,152 bytes. 33 expected no
Answer yes expected no
Skipping the batch
Answer no expected no
Answer no expected no
Skipping the batch
Answer yes expected yes
Answer no expected no
Answer no expected no
Answer yes expected yes
Answer no expected no
Skipping the batch
Answer no expected no
Answer yes expected no
Answer yes expected yes
Answer yes expected yes
Answer no expected no
Answer yes expected no
Answer no expected no
Answer yes expected yes
Answer no expected no
Answer yes expected no
Answer that requires a person to be able to interact with customers and coworkers. retail requires a person to be able to work in a fast paced environment. retail requires a person to be able to work in a team environment. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires a person to be able to work in a variety of different environments. retail requires  expected no
Answer no expected no
Answer yes expected yes
Answer yes expected yes
Answer no expected yes
Answer no expected no
index 7 start communication
Answer yes expected yes
Answer no expected yes
index 6 start communication
Answer yes expected no
Answer no expected no
index 0 start communication
index 2 start communication
index 5 start communication
index 1 start communication
index 4 start communication
index 3 start communication
Here are the statistics for inference
+------------+----------------+---------------------------+-----------------------------+---------------+-------------+---------+--------------------------------+------------------+----------------------------------+-----------------------+----------------------+
| Task       |   Num Sentence |   Total Generation Length |   Average Generation Length |   Total Steps |   Num Steps |     AAL |   Total Roll Back Length Error |   Error Instance |   Average Roll Back Length Error |   Effective Tree Size |   Drafting Tree Size |
+============+================+===========================+=============================+===============+=============+=========+================================+==================+==================================+=======================+======================+
| strategyqa |            457 |                     26931 |                       58.93 |         21908 |        2251 | 9.73256 |                            602 |              102 |                          5.90196 |                    10 |                    1 |
+------------+----------------+---------------------------+-----------------------------+---------------+-------------+---------+--------------------------------+------------------+----------------------------------+-----------------------+----------------------+
Namespace(tasks='strategyqa', model='meta-llama/Llama-2-7b-hf', device='cuda:0', limit=None, griffin=False, cats=True, check=True, kernel_size=10, spr=0.4, thr=0.01, widthtree=1, patternstrict=True, shotfive=True, shottwo=False, filteractiveenabled=False)
+------------+---------+-----------+--------------+
| Task       |   Total |   Correct |   Solve Rate |
+============+=========+===========+==============+
| strategyqa |     457 |       280 |     0.612691 |
+------------+---------+-----------+--------------+
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
