Already on 'yangexp2two'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-07-06:21:00:48,296 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:48,296 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:48,296 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:48,296 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:48,296 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:48,296 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:48,311 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:48,312 INFO     [main.py:288] Verbosity set to INFO
2024-07-06:21:00:57,622 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,622 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,622 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,622 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,622 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,623 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,645 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,645 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,645 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,645 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,645 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,645 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,645 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
2024-07-06:21:00:57,645 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
2024-07-06:21:00:57,645 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
2024-07-06:21:00:57,645 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
2024-07-06:21:00:57,645 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
2024-07-06:21:00:57,645 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
2024-07-06:21:00:57,679 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,685 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-06:21:00:57,686 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,686 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
2024-07-06:21:00:57,691 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-06:21:00:57,691 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-13b-hf', 'widthtree': 6, 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1, 'patternstrict': True}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:44<01:29, 44.89s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:32, 46.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:32, 46.50s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:32, 46.37s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:32, 46.42s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 47.00s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:32, 46.35s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:32, 46.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:32<00:46, 46.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:34<00:47, 47.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:34<00:47, 47.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:34<00:47, 47.36s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:35<00:47, 47.62s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:34<00:47, 47.39s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:34<00:47, 47.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:34<00:47, 47.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:52<00:00, 33.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:52<00:00, 37.42s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 34.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 37.90s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 34.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 37.88s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 34.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 34.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 34.54s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 37.93s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 37.88s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 37.93s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 34.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:53<00:00, 37.89s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:54<00:00, 34.68s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:54<00:00, 38.11s/it]
2024-07-06:21:04:04,314 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
2024-07-06:21:04:04,314 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
2024-07-06:21:04:04,314 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
2024-07-06:21:04:04,314 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
2024-07-06:21:04:04,315 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 19/165 [00:00<00:00, 185.12it/s] 12%|█▏        | 19/165 [00:00<00:00, 184.95it/s] 12%|█▏        | 19/164 [00:00<00:00, 183.26it/s] 10%|█         | 17/165 [00:00<00:00, 162.31it/s] 10%|█         | 17/165 [00:00<00:00, 160.78it/s] 23%|██▎       | 38/164 [00:00<00:00, 185.39it/s] 24%|██▎       | 39/165 [00:00<00:00, 190.30it/s] 24%|██▎       | 39/165 [00:00<00:00, 189.88it/s]2024-07-06:21:04:04,588 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
 21%|██        | 35/165 [00:00<00:00, 167.40it/s]  0%|          | 0/165 [00:00<?, ?it/s] 21%|██        | 34/165 [00:00<00:00, 141.14it/s] 35%|███▍      | 57/164 [00:00<00:00, 186.65it/s] 36%|███▌      | 59/165 [00:00<00:00, 191.88it/s] 36%|███▌      | 59/165 [00:00<00:00, 191.37it/s] 12%|█▏        | 19/165 [00:00<00:00, 182.57it/s] 32%|███▏      | 52/165 [00:00<00:00, 151.05it/s] 31%|███       | 51/165 [00:00<00:00, 149.94it/s] 46%|████▋     | 76/164 [00:00<00:00, 187.23it/s] 48%|████▊     | 79/165 [00:00<00:00, 191.37it/s] 48%|████▊     | 79/165 [00:00<00:00, 184.47it/s] 44%|████▎     | 72/165 [00:00<00:00, 167.32it/s] 24%|██▎       | 39/165 [00:00<00:00, 187.62it/s] 43%|████▎     | 71/165 [00:00<00:00, 165.47it/s] 58%|█████▊    | 95/164 [00:00<00:00, 188.08it/s] 60%|██████    | 99/165 [00:00<00:00, 193.02it/s] 60%|██████    | 99/165 [00:00<00:00, 188.15it/s] 35%|███▌      | 58/165 [00:00<00:00, 186.73it/s] 56%|█████▌    | 92/165 [00:00<00:00, 175.53it/s] 55%|█████▍    | 90/165 [00:00<00:00, 172.21it/s] 70%|██████▉   | 114/164 [00:00<00:00, 187.13it/s] 72%|███████▏  | 119/165 [00:00<00:00, 190.73it/s] 72%|███████▏  | 118/165 [00:00<00:00, 188.37it/s] 68%|██████▊   | 112/165 [00:00<00:00, 182.29it/s] 47%|████▋     | 78/165 [00:00<00:00, 188.90it/s] 67%|██████▋   | 110/165 [00:00<00:00, 179.00it/s] 82%|████████▏ | 134/164 [00:00<00:00, 187.23it/s] 83%|████████▎ | 137/165 [00:00<00:00, 188.54it/s] 84%|████████▍ | 139/165 [00:00<00:00, 190.58it/s] 59%|█████▉    | 97/165 [00:00<00:00, 188.58it/s] 80%|████████  | 132/165 [00:00<00:00, 185.11it/s] 78%|███████▊  | 129/165 [00:00<00:00, 181.71it/s] 93%|█████████▎| 153/164 [00:00<00:00, 188.01it/s] 95%|█████████▌| 157/165 [00:00<00:00, 190.29it/s] 96%|█████████▋| 159/165 [00:00<00:00, 191.65it/s] 71%|███████   | 117/165 [00:00<00:00, 189.94it/s] 92%|█████████▏| 152/165 [00:00<00:00, 188.01it/s] 90%|█████████ | 149/165 [00:00<00:00, 185.06it/s]100%|██████████| 165/165 [00:00<00:00, 191.34it/s]
100%|██████████| 165/165 [00:00<00:00, 189.17it/s]
100%|██████████| 164/164 [00:00<00:00, 187.49it/s]
100%|██████████| 165/165 [00:00<00:00, 179.31it/s]
100%|██████████| 165/165 [00:00<00:00, 175.35it/s]
 83%|████████▎ | 137/165 [00:00<00:00, 190.69it/s] 95%|█████████▌| 157/165 [00:00<00:00, 189.43it/s]100%|██████████| 165/165 [00:00<00:00, 189.02it/s]
2024-07-06:21:04:29,572 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s]  8%|▊         | 13/165 [00:00<00:01, 125.32it/s] 16%|█▌        | 26/165 [00:00<00:01, 126.77it/s] 24%|██▎       | 39/165 [00:00<00:00, 127.38it/s] 32%|███▏      | 52/165 [00:00<00:00, 127.70it/s] 39%|███▉      | 65/165 [00:00<00:00, 127.88it/s] 47%|████▋     | 78/165 [00:00<00:00, 127.92it/s] 55%|█████▌    | 91/165 [00:00<00:00, 128.47it/s] 63%|██████▎   | 104/165 [00:00<00:00, 128.69it/s] 71%|███████   | 117/165 [00:00<00:00, 128.92it/s] 79%|███████▉  | 130/165 [00:01<00:00, 128.61it/s] 87%|████████▋ | 143/165 [00:01<00:00, 128.78it/s] 95%|█████████▍| 156/165 [00:01<00:00, 128.59it/s]100%|██████████| 165/165 [00:01<00:00, 128.27it/s]
2024-07-06:21:04:31,878 INFO     [xhuggingface.py:323] Using 8 devices with data parallelism
2024-07-06:21:04:33,117 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 19/165 [00:00<00:00, 187.52it/s] 24%|██▎       | 39/165 [00:00<00:00, 190.61it/s] 36%|███▌      | 59/165 [00:00<00:00, 191.55it/s] 48%|████▊     | 79/165 [00:00<00:00, 192.47it/s] 60%|██████    | 99/165 [00:00<00:00, 192.96it/s] 72%|███████▏  | 119/165 [00:00<00:00, 193.48it/s] 84%|████████▍ | 139/165 [00:00<00:00, 193.35it/s] 96%|█████████▋| 159/165 [00:00<00:00, 192.31it/s]100%|██████████| 165/165 [00:00<00:00, 192.25it/s]
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
2024-07-06:21:04:47,204 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/165 [00:39<1:46:45, 39.06s/it]Running generate_until requests:   1%|          | 2/165 [01:01<1:19:05, 29.11s/it]Running generate_until requests:   2%|▏         | 3/165 [01:15<1:00:26, 22.39s/it]Running generate_until requests:   2%|▏         | 4/165 [01:45<1:08:01, 25.35s/it]Running generate_until requests:   3%|▎         | 5/165 [02:07<1:04:23, 24.15s/it]Running generate_until requests:   4%|▎         | 6/165 [02:29<1:02:16, 23.50s/it]Running generate_until requests:   4%|▍         | 7/165 [02:43<53:36, 20.36s/it]  Running generate_until requests:   5%|▍         | 8/165 [02:49<41:24, 15.83s/it]Running generate_until requests:   5%|▌         | 9/165 [02:55<33:11, 12.77s/it]Running generate_until requests:   6%|▌         | 10/165 [03:27<48:07, 18.63s/it]Running generate_until requests:   7%|▋         | 11/165 [03:56<56:15, 21.92s/it]Running generate_until requests:   7%|▋         | 12/165 [04:06<46:33, 18.26s/it]Running generate_until requests:   8%|▊         | 13/165 [04:16<39:57, 15.77s/it]Running generate_until requests:   8%|▊         | 14/165 [04:46<50:18, 19.99s/it]Running generate_until requests:   9%|▉         | 15/165 [05:10<52:47, 21.12s/it]Running generate_until requests:  10%|▉         | 16/165 [05:32<52:52, 21.29s/it]Running generate_until requests:  10%|█         | 17/165 [05:47<48:28, 19.65s/it]Running generate_until requests:  11%|█         | 18/165 [06:05<46:40, 19.05s/it]Running generate_until requests:  12%|█▏        | 19/165 [06:23<45:21, 18.64s/it]Running generate_until requests:  12%|█▏        | 20/165 [06:33<38:39, 16.00s/it]Running generate_until requests:  13%|█▎        | 21/165 [06:46<36:50, 15.35s/it]Running generate_until requests:  13%|█▎        | 22/165 [07:00<35:23, 14.85s/it]Running generate_until requests:  14%|█▍        | 23/165 [07:24<41:14, 17.43s/it]Running generate_until requests:  15%|█▍        | 24/165 [07:51<48:14, 20.53s/it]Running generate_until requests:  15%|█▌        | 25/165 [08:07<44:22, 19.02s/it]Running generate_until requests:  16%|█▌        | 26/165 [08:38<52:35, 22.70s/it]Running generate_until requests:  16%|█▋        | 27/165 [08:54<47:27, 20.63s/it]Running generate_until requests:  17%|█▋        | 28/165 [09:15<47:38, 20.86s/it]Running generate_until requests:  18%|█▊        | 29/165 [09:31<43:44, 19.30s/it]Running generate_until requests:  18%|█▊        | 30/165 [09:52<44:51, 19.94s/it]Running generate_until requests:  19%|█▉        | 31/165 [10:06<40:27, 18.12s/it]Running generate_until requests:  19%|█▉        | 32/165 [10:20<37:15, 16.80s/it]Running generate_until requests:  20%|██        | 33/165 [10:26<29:46, 13.53s/it]Running generate_until requests:  21%|██        | 34/165 [10:45<33:18, 15.25s/it]Running generate_until requests:  21%|██        | 35/165 [10:57<30:42, 14.17s/it]Running generate_until requests:  22%|██▏       | 36/165 [11:28<41:25, 19.27s/it]Running generate_until requests:  22%|██▏       | 37/165 [11:41<37:23, 17.53s/it]Running generate_until requests:  23%|██▎       | 38/165 [12:13<45:45, 21.62s/it]Running generate_until requests:  24%|██▎       | 39/165 [12:43<51:16, 24.41s/it]Running generate_until requests:  24%|██▍       | 40/165 [12:57<44:07, 21.18s/it]Running generate_until requests:  25%|██▍       | 41/165 [13:07<36:39, 17.74s/it]Running generate_until requests:  25%|██▌       | 42/165 [13:28<38:36, 18.84s/it]Running generate_until requests:  26%|██▌       | 43/165 [13:42<35:01, 17.23s/it]Running generate_until requests:  27%|██▋       | 44/165 [14:09<40:37, 20.14s/it]Running generate_until requests:  27%|██▋       | 45/165 [14:26<38:43, 19.36s/it]Running generate_until requests:  28%|██▊       | 46/165 [14:57<45:12, 22.79s/it]Running generate_until requests:  28%|██▊       | 47/165 [15:03<34:50, 17.71s/it]Running generate_until requests:  29%|██▉       | 48/165 [15:34<42:19, 21.71s/it]Running generate_until requests:  30%|██▉       | 49/165 [15:38<31:41, 16.39s/it]Running generate_until requests:  30%|███       | 50/165 [16:09<39:36, 20.67s/it]Running generate_until requests:  31%|███       | 51/165 [16:22<35:09, 18.51s/it]Running generate_until requests:  32%|███▏      | 52/165 [16:36<32:09, 17.08s/it]Running generate_until requests:  32%|███▏      | 53/165 [16:59<35:09, 18.84s/it]Running generate_until requests:  33%|███▎      | 54/165 [17:18<35:05, 18.97s/it]Running generate_until requests:  33%|███▎      | 55/165 [17:33<32:50, 17.91s/it]Running generate_until requests:  34%|███▍      | 56/165 [18:04<39:34, 21.79s/it]Running generate_until requests:  35%|███▍      | 57/165 [18:16<33:43, 18.74s/it]Running generate_until requests:  35%|███▌      | 58/165 [18:35<33:39, 18.88s/it]Running generate_until requests:  36%|███▌      | 59/165 [18:47<29:34, 16.74s/it]Running generate_until requests:  36%|███▋      | 60/165 [18:53<23:35, 13.48s/it]Running generate_until requests:  37%|███▋      | 61/165 [19:04<22:21, 12.90s/it]Running generate_until requests:  38%|███▊      | 62/165 [19:20<23:24, 13.63s/it]Running generate_until requests:  38%|███▊      | 63/165 [19:31<22:07, 13.01s/it]Running generate_until requests:  39%|███▉      | 64/165 [19:43<21:11, 12.59s/it]Running generate_until requests:  39%|███▉      | 65/165 [19:55<20:34, 12.35s/it]Running generate_until requests:  40%|████      | 66/165 [20:12<22:51, 13.85s/it]Running generate_until requests:  41%|████      | 67/165 [20:27<23:25, 14.35s/it]Running generate_until requests:  41%|████      | 68/165 [20:33<19:04, 11.79s/it]Running generate_until requests:  42%|████▏     | 69/165 [20:53<22:33, 14.09s/it]Running generate_until requests:  42%|████▏     | 70/165 [21:23<30:13, 19.09s/it]Running generate_until requests:  43%|████▎     | 71/165 [21:54<35:20, 22.56s/it]Running generate_until requests:  44%|████▎     | 72/165 [22:17<35:14, 22.73s/it]Running generate_until requests:  44%|████▍     | 73/165 [22:23<27:07, 17.69s/it]Running generate_until requests:  45%|████▍     | 74/165 [22:31<22:16, 14.69s/it]Running generate_until requests:  45%|████▌     | 75/165 [22:54<25:45, 17.17s/it]Running generate_until requests:  46%|████▌     | 76/165 [23:11<25:32, 17.22s/it]Running generate_until requests:  47%|████▋     | 77/165 [23:42<31:08, 21.23s/it]Running generate_until requests:  47%|████▋     | 78/165 [23:49<24:55, 17.18s/it]Running generate_until requests:  48%|████▊     | 79/165 [24:05<23:53, 16.67s/it]Running generate_until requests:  48%|████▊     | 80/165 [24:22<23:54, 16.88s/it]Running generate_until requests:  49%|████▉     | 81/165 [24:32<20:35, 14.71s/it]Running generate_until requests:  50%|████▉     | 82/165 [24:51<22:08, 16.01s/it]Running generate_until requests:  50%|█████     | 83/165 [25:16<25:33, 18.71s/it]Running generate_until requests:  51%|█████     | 84/165 [25:29<23:06, 17.12s/it]Running generate_until requests:  52%|█████▏    | 85/165 [25:45<22:05, 16.57s/it]Running generate_until requests:  52%|█████▏    | 86/165 [25:58<20:32, 15.60s/it]Running generate_until requests:  53%|█████▎    | 87/165 [26:14<20:14, 15.58s/it]Running generate_until requests:  53%|█████▎    | 88/165 [26:25<18:27, 14.38s/it]Running generate_until requests:  54%|█████▍    | 89/165 [26:42<19:14, 15.20s/it]Running generate_until requests:  55%|█████▍    | 90/165 [26:50<16:11, 12.95s/it]Running generate_until requests:  55%|█████▌    | 91/165 [27:05<16:49, 13.64s/it]Running generate_until requests:  56%|█████▌    | 92/165 [27:28<20:03, 16.48s/it]Running generate_until requests:  56%|█████▋    | 93/165 [27:40<17:57, 14.96s/it]Running generate_until requests:  57%|█████▋    | 94/165 [28:10<23:11, 19.59s/it]Running generate_until requests:  58%|█████▊    | 95/165 [28:29<22:45, 19.50s/it]Running generate_until requests:  58%|█████▊    | 96/165 [28:39<18:58, 16.51s/it]Running generate_until requests:  59%|█████▉    | 97/165 [29:09<23:26, 20.69s/it]Running generate_until requests:  59%|█████▉    | 98/165 [29:27<21:59, 19.69s/it]Running generate_until requests:  60%|██████    | 99/165 [29:44<20:46, 18.89s/it]Running generate_until requests:  61%|██████    | 100/165 [29:53<17:25, 16.09s/it]Running generate_until requests:  61%|██████    | 101/165 [30:14<18:45, 17.58s/it]Running generate_until requests:  62%|██████▏   | 102/165 [30:22<15:20, 14.61s/it]Running generate_until requests:  62%|██████▏   | 103/165 [30:28<12:22, 11.98s/it]Running generate_until requests:  63%|██████▎   | 104/165 [30:36<10:56, 10.76s/it]Running generate_until requests:  64%|██████▎   | 105/165 [31:06<16:35, 16.59s/it]Running generate_until requests:  64%|██████▍   | 106/165 [31:21<15:56, 16.21s/it]Running generate_until requests:  65%|██████▍   | 107/165 [31:37<15:24, 15.95s/it]Running generate_until requests:  65%|██████▌   | 108/165 [32:03<18:09, 19.12s/it]Running generate_until requests:  66%|██████▌   | 109/165 [32:13<15:10, 16.25s/it]Running generate_until requests:  67%|██████▋   | 110/165 [32:30<15:07, 16.50s/it]Running generate_until requests:  67%|██████▋   | 111/165 [32:43<14:01, 15.57s/it]Running generate_until requests:  68%|██████▊   | 112/165 [32:57<13:08, 14.88s/it]Running generate_until requests:  68%|██████▊   | 113/165 [33:08<11:58, 13.82s/it]Running generate_until requests:  69%|██████▉   | 114/165 [33:14<09:41, 11.41s/it]Running generate_until requests:  70%|██████▉   | 115/165 [33:25<09:30, 11.41s/it]Running generate_until requests:  70%|███████   | 116/165 [33:31<07:55,  9.71s/it]Running generate_until requests:  71%|███████   | 117/165 [33:42<08:09, 10.21s/it]Running generate_until requests:  72%|███████▏  | 118/165 [34:12<12:43, 16.25s/it]Running generate_until requests:  72%|███████▏  | 119/165 [34:24<11:20, 14.79s/it]Running generate_until requests:  73%|███████▎  | 120/165 [34:35<10:17, 13.73s/it]Running generate_until requests:  73%|███████▎  | 121/165 [34:43<08:42, 11.88s/it]Running generate_until requests:  74%|███████▍  | 122/165 [35:02<10:02, 14.00s/it]Running generate_until requests:  75%|███████▍  | 123/165 [35:19<10:25, 14.89s/it]Running generate_until requests:  75%|███████▌  | 124/165 [35:32<09:48, 14.36s/it]Running generate_until requests:  76%|███████▌  | 125/165 [35:43<08:57, 13.43s/it]Running generate_until requests:  76%|███████▋  | 126/165 [35:53<07:59, 12.30s/it]Running generate_until requests:  77%|███████▋  | 127/165 [36:08<08:17, 13.10s/it]Running generate_until requests:  78%|███████▊  | 128/165 [36:32<10:10, 16.49s/it]Running generate_until requests:  78%|███████▊  | 129/165 [36:43<08:56, 14.91s/it]Running generate_until requests:  79%|███████▉  | 130/165 [37:14<11:22, 19.51s/it]Running generate_until requests:  79%|███████▉  | 131/165 [37:27<09:58, 17.61s/it]Running generate_until requests:  80%|████████  | 132/165 [37:40<08:56, 16.25s/it]Running generate_until requests:  81%|████████  | 133/165 [37:55<08:28, 15.88s/it]Running generate_until requests:  81%|████████  | 134/165 [38:12<08:23, 16.23s/it]Running generate_until requests:  82%|████████▏ | 135/165 [38:23<07:22, 14.74s/it]Running generate_until requests:  82%|████████▏ | 136/165 [38:32<06:20, 13.12s/it]Running generate_until requests:  83%|████████▎ | 137/165 [38:57<07:40, 16.45s/it]Running generate_until requests:  84%|████████▎ | 138/165 [39:27<09:15, 20.59s/it]Running generate_until requests:  84%|████████▍ | 139/165 [39:38<07:41, 17.77s/it]Running generate_until requests:  85%|████████▍ | 140/165 [39:49<06:35, 15.81s/it]Running generate_until requests:  85%|████████▌ | 141/165 [40:04<06:14, 15.61s/it]Running generate_until requests:  86%|████████▌ | 142/165 [40:14<05:16, 13.76s/it]Running generate_until requests:  87%|████████▋ | 143/165 [40:25<04:46, 13.00s/it]Running generate_until requests:  87%|████████▋ | 144/165 [40:36<04:21, 12.46s/it]Running generate_until requests:  88%|████████▊ | 145/165 [40:47<04:01, 12.07s/it]Running generate_until requests:  88%|████████▊ | 146/165 [41:04<04:15, 13.45s/it]Running generate_until requests:  89%|████████▉ | 147/165 [41:17<04:01, 13.40s/it]Running generate_until requests:  90%|████████▉ | 148/165 [41:31<03:46, 13.30s/it]Running generate_until requests:  90%|█████████ | 149/165 [41:38<03:04, 11.54s/it]Running generate_until requests:  91%|█████████ | 150/165 [41:49<02:51, 11.43s/it]Running generate_until requests:  92%|█████████▏| 151/165 [41:58<02:31, 10.79s/it]Running generate_until requests:  92%|█████████▏| 152/165 [42:02<01:53,  8.70s/it]Running generate_until requests:  93%|█████████▎| 153/165 [42:32<03:01, 15.11s/it]Running generate_until requests:  93%|█████████▎| 154/165 [42:49<02:51, 15.57s/it]Running generate_until requests:  94%|█████████▍| 155/165 [42:56<02:11, 13.13s/it]Running generate_until requests:  95%|█████████▍| 156/165 [43:04<01:42, 11.42s/it]Running generate_until requests:  95%|█████████▌| 157/165 [43:09<01:17,  9.69s/it]Running generate_until requests:  96%|█████████▌| 158/165 [43:28<01:26, 12.41s/it]Running generate_until requests:  96%|█████████▋| 159/165 [43:49<01:28, 14.78s/it]Running generate_until requests:  97%|█████████▋| 160/165 [44:07<01:19, 15.90s/it]Running generate_until requests:  98%|█████████▊| 161/165 [44:15<00:53, 13.37s/it]Running generate_until requests:  98%|█████████▊| 162/165 [44:35<00:46, 15.54s/it]Running generate_until requests:  99%|█████████▉| 163/165 [44:46<00:28, 14.18s/it]Running generate_until requests:  99%|█████████▉| 164/165 [45:01<00:14, 14.34s/it]Running generate_until requests: 100%|██████████| 165/165 [45:19<00:00, 15.56s/it]Running generate_until requests: 100%|██████████| 165/165 [45:19<00:00, 16.48s/it]
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/main.py", line 465, in <module>
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/main.py", line 465, in <module>
    cli_evaluate()
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/main.py", line 384, in cli_evaluate
    cli_evaluate()
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/main.py", line 384, in cli_evaluate
    results = xevaluator.simple_evaluate(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/lm_eval/utils.py", line 288, in _wrapper
    results = xevaluator.simple_evaluate(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/lm_eval/utils.py", line 288, in _wrapper
    return fn(*args, **kwargs)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/xevaluator.py", line 262, in simple_evaluate
    return fn(*args, **kwargs)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/xevaluator.py", line 262, in simple_evaluate
    results = evaluate(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/lm_eval/utils.py", line 288, in _wrapper
    results = evaluate(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/lm_eval/utils.py", line 288, in _wrapper
    return fn(*args, **kwargs)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/xevaluator.py", line 485, in evaluate
    return fn(*args, **kwargs)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/xevaluator.py", line 485, in evaluate
    torch.distributed.gather_object(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 72, in wrapper
    torch.distributed.gather_object(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2316, in gather_object
    return func(*args, **kwargs)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2316, in gather_object
    gather(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 72, in wrapper
    gather(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2890, in gather
    return func(*args, **kwargs)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2890, in gather
    work = default_pg.gather(output_tensors, input_tensors, opts)
RuntimeError: NCCL Error 3: internal error - please report this issue to the NCCL developers
    work = default_pg.gather(output_tensors, input_tensors, opts)
RuntimeError: NCCL Error 1: unhandled cuda error (run with NCCL_DEBUG=INFO for details)
[2024-07-06 21:54:26,311] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3342870 closing signal SIGTERM
[2024-07-06 21:54:26,312] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3342871 closing signal SIGTERM
[2024-07-06 21:54:26,312] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3342872 closing signal SIGTERM
[2024-07-06 21:54:26,313] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3342874 closing signal SIGTERM
[2024-07-06 21:54:26,313] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3342875 closing signal SIGTERM
[2024-07-06 21:54:26,313] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3342876 closing signal SIGTERM
[2024-07-06 21:54:28,043] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3342869) of binary: /fsx-storygen/beidic/anaconda3/envs/griffin/bin/python3.9
Traceback (most recent call last):
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-07-06_21:54:26
  host      : a100-st-p4de24xlarge-866.fair-a100.hpcaas
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 3342873)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-06_21:54:26
  host      : a100-st-p4de24xlarge-866.fair-a100.hpcaas
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3342869)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
