Already on 'addinggriffin'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.76s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:47<01:35, 47.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:47<01:35, 47.65s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:47<01:35, 47.65s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:48<01:37, 48.66s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:47<01:35, 47.65s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:47<01:35, 47.67s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:47<01:35, 47.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:36<00:48, 48.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:38<00:49, 49.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:38<00:49, 49.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:38<00:49, 49.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:38<00:49, 49.31s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:38<00:49, 49.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:39<00:49, 49.74s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:38<00:49, 49.46s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:08<00:00, 40.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:08<00:00, 42.83s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 41.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 43.21s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 41.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 43.21s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 41.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 43.21s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:10<00:00, 41.40s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:10<00:00, 43.54s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 41.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 43.21s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 41.19s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 43.22s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 41.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:09<00:00, 43.23s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/153 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  1%|          | 1/153 [00:25<1:05:39, 25.92s/it]  1%|          | 1/153 [00:26<1:07:35, 26.68s/it]  1%|          | 1/153 [00:27<1:09:24, 27.40s/it]  1%|          | 1/153 [00:29<1:14:32, 29.43s/it]  1%|          | 1/153 [00:29<1:14:34, 29.44s/it]  1%|          | 1/153 [00:34<1:27:07, 34.39s/it]  1%|          | 1/153 [00:42<1:47:43, 42.52s/it]  1%|          | 1/153 [00:44<1:53:39, 44.87s/it]  1%|▏         | 2/153 [00:51<1:03:52, 25.38s/it]  1%|▏         | 2/153 [00:52<1:06:04, 26.26s/it]  1%|▏         | 2/153 [00:52<1:06:22, 26.38s/it]  1%|▏         | 2/153 [00:55<1:09:32, 27.64s/it]  1%|▏         | 2/153 [00:58<1:12:56, 28.98s/it]  1%|▏         | 2/153 [01:09<1:28:09, 35.03s/it]  2%|▏         | 3/153 [01:17<1:04:05, 25.64s/it]  2%|▏         | 3/153 [01:18<1:05:48, 26.33s/it]  2%|▏         | 3/153 [01:21<1:08:05, 27.24s/it]  2%|▏         | 3/153 [01:23<1:09:11, 27.68s/it]  2%|▏         | 3/153 [01:24<1:09:34, 27.83s/it]  1%|▏         | 2/153 [01:26<1:49:46, 43.62s/it]  1%|▏         | 2/153 [01:29<1:52:02, 44.52s/it]  2%|▏         | 3/153 [01:41<1:23:53, 33.56s/it]  3%|▎         | 4/153 [01:43<1:04:14, 25.87s/it]  3%|▎         | 4/153 [01:46<1:07:37, 27.23s/it]  3%|▎         | 4/153 [01:49<1:08:49, 27.71s/it]  3%|▎         | 4/153 [01:52<1:10:24, 28.36s/it]  3%|▎         | 4/153 [01:53<1:10:00, 28.19s/it]  3%|▎         | 5/153 [02:06<1:01:13, 24.82s/it]  2%|▏         | 3/153 [02:10<1:48:47, 43.52s/it]  3%|▎         | 4/153 [02:13<1:21:36, 32.86s/it]  3%|▎         | 5/153 [02:13<1:06:46, 27.07s/it]  2%|▏         | 3/153 [02:16<1:54:03, 45.62s/it]  3%|▎         | 5/153 [02:19<1:08:20, 27.70s/it]  3%|▎         | 5/153 [02:19<1:07:56, 27.54s/it]  3%|▎         | 5/153 [02:20<1:11:35, 29.02s/it]  4%|▍         | 6/153 [02:32<1:01:45, 25.21s/it]  4%|▍         | 6/153 [02:44<1:09:09, 28.23s/it]  4%|▍         | 6/153 [02:46<1:07:32, 27.57s/it]  4%|▍         | 6/153 [02:46<1:07:15, 27.45s/it]  3%|▎         | 5/153 [02:49<1:23:27, 33.84s/it]  4%|▍         | 6/153 [02:49<1:10:51, 28.92s/it]  3%|▎         | 4/153 [02:52<1:46:37, 42.94s/it]  5%|▍         | 7/153 [03:00<1:03:11, 25.97s/it]  3%|▎         | 4/153 [03:05<1:56:57, 47.10s/it]  5%|▍         | 7/153 [03:09<1:06:20, 27.27s/it]  5%|▍         | 7/153 [03:12<1:05:26, 26.89s/it]  5%|▍         | 7/153 [03:14<1:07:27, 27.72s/it]  5%|▍         | 7/153 [03:18<1:10:33, 28.99s/it]  4%|▍         | 6/153 [03:22<1:22:49, 33.81s/it]  5%|▌         | 8/153 [03:27<1:03:57, 26.47s/it]  5%|▌         | 8/153 [03:34<1:03:52, 26.43s/it]  5%|▌         | 8/153 [03:37<1:02:59, 26.06s/it]  3%|▎         | 5/153 [03:39<1:49:39, 44.46s/it]  5%|▌         | 8/153 [03:39<1:04:58, 26.89s/it]  5%|▌         | 8/153 [03:44<1:07:24, 27.90s/it]  3%|▎         | 5/153 [03:47<1:51:36, 45.25s/it]  5%|▍         | 7/153 [03:53<1:20:03, 32.90s/it]  6%|▌         | 9/153 [03:56<1:04:52, 27.03s/it]  6%|▌         | 9/153 [03:59<1:02:36, 26.09s/it]  6%|▌         | 9/153 [04:03<1:02:04, 25.87s/it]  6%|▌         | 9/153 [04:04<1:03:58, 26.66s/it]  6%|▌         | 9/153 [04:12<1:07:16, 28.03s/it]  7%|▋         | 10/153 [04:23<1:04:14, 26.96s/it]  7%|▋         | 10/153 [04:24<1:01:38, 25.86s/it]  4%|▍         | 6/153 [04:29<1:53:23, 46.28s/it]  7%|▋         | 10/153 [04:29<1:01:38, 25.86s/it]  4%|▍         | 6/153 [04:29<1:48:08, 44.14s/it]  5%|▌         | 8/153 [04:32<1:23:45, 34.66s/it]  7%|▋         | 10/153 [04:32<1:04:28, 27.05s/it]  7%|▋         | 10/153 [04:45<1:10:14, 29.47s/it]  7%|▋         | 11/153 [04:49<1:03:15, 26.73s/it]  7%|▋         | 11/153 [04:52<1:02:22, 26.36s/it]  7%|▋         | 11/153 [04:58<1:03:18, 26.75s/it]  7%|▋         | 11/153 [05:00<1:04:40, 27.33s/it]  6%|▌         | 9/153 [05:05<1:21:48, 34.08s/it]  7%|▋         | 11/153 [05:10<1:06:23, 28.05s/it]  8%|▊         | 12/153 [05:15<1:02:26, 26.57s/it]  5%|▍         | 7/153 [05:16<1:53:05, 46.48s/it]  5%|▍         | 7/153 [05:17<1:50:30, 45.41s/it]  8%|▊         | 12/153 [05:20<1:03:18, 26.94s/it]  8%|▊         | 12/153 [05:24<1:02:14, 26.48s/it]  8%|▊         | 12/153 [05:29<1:05:15, 27.77s/it]  8%|▊         | 12/153 [05:35<1:04:12, 27.32s/it]  7%|▋         | 10/153 [05:38<1:20:24, 33.74s/it]  8%|▊         | 13/153 [05:39<1:00:13, 25.81s/it]  8%|▊         | 13/153 [05:46<1:01:47, 26.48s/it]  8%|▊         | 13/153 [05:47<59:50, 25.65s/it]    8%|▊         | 13/153 [05:56<1:04:28, 27.63s/it]  5%|▌         | 8/153 [05:57<1:48:07, 44.74s/it]  5%|▌         | 8/153 [06:02<1:49:22, 45.26s/it]  9%|▉         | 14/153 [06:03<58:32, 25.27s/it]    8%|▊         | 13/153 [06:03<1:03:59, 27.42s/it]  7%|▋         | 11/153 [06:12<1:20:39, 34.08s/it]  9%|▉         | 14/153 [06:13<1:02:05, 26.80s/it]  9%|▉         | 14/153 [06:15<1:01:00, 26.34s/it]  9%|▉         | 14/153 [06:24<1:03:38, 27.47s/it]  9%|▉         | 14/153 [06:28<1:01:41, 26.63s/it] 10%|▉         | 15/153 [06:30<59:11, 25.74s/it]  6%|▌         | 9/153 [06:39<1:45:09, 43.81s/it] 10%|▉         | 15/153 [06:38<1:00:34, 26.33s/it] 10%|▉         | 15/153 [06:44<1:02:14, 27.06s/it]  8%|▊         | 12/153 [06:45<1:19:10, 33.69s/it] 10%|▉         | 15/153 [06:49<1:02:00, 26.96s/it]  6%|▌         | 9/153 [06:49<1:50:11, 45.91s/it] 10%|▉         | 15/153 [06:55<1:01:28, 26.73s/it] 10%|█         | 16/153 [06:58<1:00:29, 26.50s/it] 10%|█         | 16/153 [07:03<58:55, 25.80s/it]   10%|█         | 16/153 [07:11<1:01:55, 27.12s/it] 10%|█         | 16/153 [07:16<1:01:12, 26.81s/it]  8%|▊         | 13/153 [07:20<1:19:14, 33.96s/it] 10%|█         | 16/153 [07:20<1:00:12, 26.37s/it] 11%|█         | 17/153 [07:24<59:24, 26.21s/it]   11%|█         | 17/153 [07:31<59:42, 26.34s/it]  7%|▋         | 10/153 [07:31<1:50:42, 46.45s/it]  7%|▋         | 10/153 [07:36<1:50:22, 46.31s/it] 11%|█         | 17/153 [07:41<1:03:08, 27.86s/it] 11%|█         | 17/153 [07:41<59:38, 26.31s/it]   11%|█         | 17/153 [07:45<58:46, 25.93s/it]    9%|▉         | 14/153 [07:52<1:17:15, 33.35s/it] 12%|█▏        | 18/153 [07:53<1:01:07, 27.17s/it] 12%|█▏        | 18/153 [07:56<58:36, 26.04s/it] 12%|█▏        | 18/153 [08:07<58:48, 26.14s/it] 12%|█▏        | 18/153 [08:07<1:01:47, 27.46s/it] 12%|█▏        | 18/153 [08:11<58:03, 25.80s/it] 12%|█▏        | 19/153 [08:18<59:14, 26.53s/it]    7%|▋         | 11/153 [08:19<1:51:21, 47.05s/it] 10%|▉         | 15/153 [08:23<1:15:01, 32.62s/it] 12%|█▏        | 19/153 [08:23<58:38, 26.26s/it]  7%|▋         | 11/153 [08:26<1:52:16, 47.44s/it] 12%|█▏        | 19/153 [08:34<59:08, 26.48s/it] 12%|█▏        | 19/153 [08:36<1:02:14, 27.87s/it] 12%|█▏        | 19/153 [08:40<59:53, 26.82s/it] 13%|█▎        | 20/153 [08:44<58:06, 26.22s/it] 13%|█▎        | 20/153 [08:49<58:34, 26.43s/it] 10%|█         | 16/153 [08:55<1:13:58, 32.39s/it] 13%|█▎        | 20/153 [09:01<59:08, 26.68s/it] 13%|█▎        | 20/153 [09:05<1:02:19, 28.12s/it] 13%|█▎        | 20/153 [09:06<59:02, 26.63s/it]  8%|▊         | 12/153 [09:09<1:52:19, 47.80s/it] 14%|█▎        | 21/153 [09:11<58:36, 26.64s/it] 14%|█▎        | 21/153 [09:13<56:27, 25.66s/it]  8%|▊         | 12/153 [09:17<1:53:57, 48.49s/it] 14%|█▎        | 21/153 [09:26<57:38, 26.20s/it] 11%|█         | 17/153 [09:29<1:15:02, 33.10s/it] 14%|█▎        | 21/153 [09:31<57:29, 26.13s/it] 14%|█▎        | 21/153 [09:34<1:02:17, 28.31s/it] 14%|█▍        | 22/153 [09:37<57:23, 26.28s/it] 14%|█▍        | 22/153 [09:39<55:48, 25.56s/it]  8%|▊         | 13/153 [09:53<1:49:08, 46.77s/it] 14%|█▍        | 22/153 [09:54<57:59, 26.56s/it] 14%|█▍        | 22/153 [09:58<57:33, 26.36s/it] 14%|█▍        | 22/153 [09:59<1:00:10, 27.56s/it] 12%|█▏        | 18/153 [10:01<1:13:42, 32.76s/it] 15%|█▌        | 23/153 [10:02<56:22, 26.02s/it] 15%|█▌        | 23/153 [10:04<55:13, 25.49s/it]  8%|▊         | 13/153 [10:10<1:56:08, 49.78s/it] 15%|█▌        | 23/153 [10:17<55:40, 25.69s/it] 15%|█▌        | 23/153 [10:23<57:15, 26.43s/it]   15%|█▌        | 23/153 [10:24<57:10, 26.39s/it] 16%|█▌        | 24/153 [10:28<55:39, 25.88s/it] 16%|█▌        | 24/153 [10:31<55:44, 25.93s/it] 12%|█▏        | 19/153 [10:37<1:15:11, 33.67s/it]  9%|▉         | 14/153 [10:38<1:46:40, 46.05s/it] 16%|█▌        | 24/153 [10:45<56:46, 26.41s/it] 16%|█▌        | 24/153 [10:48<54:47, 25.48s/it] 16%|█▋        | 25/153 [10:52<53:58, 25.30s/it] 16%|█▌        | 24/153 [10:53<58:44, 27.32s/it]  9%|▉         | 14/153 [10:59<1:54:26, 49.40s/it] 16%|█▋        | 25/153 [11:01<57:40, 27.03s/it] 13%|█▎        | 20/153 [11:11<1:14:38, 33.67s/it] 16%|█▋        | 25/153 [11:15<58:14, 27.30s/it] 16%|█▋        | 25/153 [11:15<55:14, 25.90s/it] 17%|█▋        | 26/153 [11:15<52:33, 24.83s/it] 16%|█▋        | 25/153 [11:18<57:15, 26.84s/it] 10%|▉         | 15/153 [11:22<1:44:41, 45.52s/it] 17%|█▋        | 26/153 [11:25<55:43, 26.33s/it] 17%|█▋        | 26/153 [11:41<56:52, 26.87s/it] 14%|█▎        | 21/153 [11:42<1:12:23, 32.90s/it] 10%|▉         | 15/153 [11:41<1:49:04, 47.42s/it] 17%|█▋        | 26/153 [11:42<55:57, 26.44s/it] 18%|█▊        | 27/153 [11:43<53:43, 25.59s/it] 17%|█▋        | 26/153 [11:46<57:33, 27.20s/it] 18%|█▊        | 27/153 [11:53<55:59, 26.66s/it] 18%|█▊        | 27/153 [12:06<55:43, 26.54s/it] 10%|█         | 16/153 [12:09<1:45:15, 46.10s/it] 18%|█▊        | 27/153 [12:09<55:51, 26.60s/it] 18%|█▊        | 27/153 [12:10<54:52, 26.13s/it] 18%|█▊        | 28/153 [12:10<54:22, 26.10s/it] 14%|█▍        | 22/153 [12:16<1:12:57, 33.42s/it] 18%|█▊        | 28/153 [12:22<56:56, 27.33s/it] 10%|█         | 16/153 [12:24<1:44:39, 45.83s/it] 18%|█▊        | 28/153 [12:32<54:27, 26.14s/it] 18%|█▊        | 28/153 [12:34<53:22, 25.62s/it] 18%|█▊        | 28/153 [12:37<56:08, 26.95s/it] 19%|█▉        | 29/153 [12:38<55:01, 26.63s/it] 19%|█▉        | 29/153 [12:46<54:53, 26.56s/it] 15%|█▌        | 23/153 [12:54<1:15:04, 34.65s/it] 19%|█▉        | 29/153 [12:55<52:28, 25.39s/it] 20%|█▉        | 30/153 [13:01<52:25, 25.57s/it] 11%|█         | 17/153 [13:01<1:48:31, 47.88s/it] 19%|█▉        | 29/153 [13:02<54:25, 26.34s/it] 19%|█▉        | 29/153 [13:05<56:36, 27.39s/it] 11%|█         | 17/153 [13:08<1:43:01, 45.45s/it] 20%|█▉        | 30/153 [13:12<54:05, 26.39s/it] 20%|█▉        | 30/153 [13:24<54:02, 26.36s/it] 16%|█▌        | 24/153 [13:25<1:12:05, 33.53s/it] 20%|██        | 31/153 [13:28<52:47, 25.96s/it] 20%|█▉        | 30/153 [13:32<55:30, 27.07s/it] 20%|█▉        | 30/153 [13:38<59:29, 29.02s/it] 20%|██        | 31/153 [13:40<54:19, 26.72s/it] 12%|█▏        | 18/153 [13:45<1:44:44, 46.55s/it] 20%|██        | 31/153 [13:51<54:12, 26.66s/it] 21%|██        | 32/153 [13:53<51:39, 25.61s/it] 12%|█▏        | 18/153 [13:54<1:42:44, 45.66s/it] 20%|██        | 31/153 [13:55<52:46, 25.96s/it] 16%|█▋        | 25/153 [13:59<1:11:39, 33.59s/it] 20%|██        | 31/153 [14:02<56:08, 27.61s/it] 21%|██        | 32/153 [14:06<53:24, 26.48s/it] 22%|██▏       | 33/153 [14:18<51:07, 25.57s/it] 21%|██        | 32/153 [14:20<55:01, 27.28s/it] 21%|██        | 32/153 [14:20<51:42, 25.64s/it] 12%|█▏        | 19/153 [14:27<1:40:51, 45.16s/it] 21%|██        | 32/153 [14:27<54:10, 26.86s/it] 22%|██▏       | 33/153 [14:33<53:14, 26.62s/it] 17%|█▋        | 26/153 [14:36<1:13:34, 34.76s/it] 12%|█▏        | 19/153 [14:41<1:43:01, 46.13s/it] 22%|██▏       | 34/153 [14:42<49:48, 25.12s/it] 22%|██▏       | 33/153 [14:45<53:16, 26.64s/it] 22%|██▏       | 33/153 [14:45<50:52, 25.43s/it] 22%|██▏       | 33/153 [14:54<53:31, 26.77s/it] 22%|██▏       | 34/153 [15:00<52:59, 26.72s/it] 23%|██▎       | 35/153 [15:09<50:22, 25.62s/it] 22%|██▏       | 34/153 [15:09<51:24, 25.92s/it] 18%|█▊        | 27/153 [15:13<1:14:06, 35.29s/it] 13%|█▎        | 20/153 [15:13<1:41:10, 45.64s/it] 22%|██▏       | 34/153 [15:14<52:39, 26.55s/it] 22%|██▏       | 34/153 [15:19<52:30, 26.47s/it] 23%|██▎       | 35/153 [15:28<53:34, 27.24s/it] 13%|█▎        | 20/153 [15:32<1:45:15, 47.48s/it] 24%|██▎       | 36/153 [15:33<49:00, 25.13s/it] 23%|██▎       | 35/153 [15:38<50:20, 25.60s/it] 23%|██▎       | 35/153 [15:38<52:36, 26.75s/it] 23%|██▎       | 35/153 [15:43<50:24, 25.63s/it] 18%|█▊        | 28/153 [15:46<1:12:35, 34.84s/it] 24%|██▎       | 36/153 [15:54<52:08, 26.74s/it] 14%|█▎        | 21/153 [15:57<1:38:42, 44.86s/it] 24%|██▍       | 37/153 [15:58<48:17, 24.98s/it] 24%|██▎       | 36/153 [16:02<50:45, 26.03s/it] 24%|██▎       | 36/153 [16:02<49:28, 25.37s/it] 24%|██▎       | 36/153 [16:10<50:27, 25.88s/it] 14%|█▎        | 21/153 [16:18<1:43:24, 47.01s/it] 24%|██▍       | 37/153 [16:20<51:27, 26.62s/it] 19%|█▉        | 29/153 [16:21<1:11:53, 34.78s/it] 25%|██▍       | 38/153 [16:24<48:30, 25.31s/it] 24%|██▍       | 37/153 [16:29<49:34, 25.64s/it] 24%|██▍       | 37/153 [16:30<51:27, 26.62s/it] 14%|█▍        | 22/153 [16:37<1:35:11, 43.60s/it] 24%|██▍       | 37/153 [16:38<51:19, 26.55s/it] 25%|██▍       | 38/153 [16:48<51:42, 26.97s/it] 25%|██▌       | 39/153 [16:49<48:07, 25.33s/it] 25%|██▍       | 38/153 [16:54<49:03, 25.60s/it] 25%|██▍       | 38/153 [16:58<51:20, 26.79s/it] 20%|█▉        | 30/153 [16:59<1:12:58, 35.60s/it] 14%|█▍        | 22/153 [17:00<1:39:26, 45.55s/it] 25%|██▍       | 38/153 [17:01<49:08, 25.64s/it] 26%|██▌       | 40/153 [17:14<47:42, 25.33s/it] 25%|██▌       | 39/153 [17:16<52:06, 27.43s/it] 25%|██▌       | 39/153 [17:19<48:14, 25.39s/it] 25%|██▌       | 39/153 [17:24<50:43, 26.69s/it] 15%|█▌        | 23/153 [17:25<1:37:29, 45.00s/it] 25%|██▌       | 39/153 [17:27<48:46, 25.67s/it] 20%|██        | 31/153 [17:30<1:09:34, 34.22s/it] 26%|██▌       | 40/153 [17:40<49:40, 26.38s/it] 27%|██▋       | 41/153 [17:41<48:11, 25.82s/it] 15%|█▌        | 23/153 [17:42<1:36:35, 44.58s/it] 26%|██▌       | 40/153 [17:43<47:08, 25.03s/it] 26%|██▌       | 40/153 [17:52<51:00, 27.08s/it] 26%|██▌       | 40/153 [17:53<48:49, 25.92s/it] 21%|██        | 32/153 [18:05<1:09:53, 34.66s/it] 27%|██▋       | 42/153 [18:07<47:50, 25.86s/it] 27%|██▋       | 41/153 [18:08<50:12, 26.90s/it] 27%|██▋       | 41/153 [18:09<46:57, 25.16s/it] 16%|█▌        | 24/153 [18:11<1:37:12, 45.21s/it] 27%|██▋       | 41/153 [18:19<47:55, 25.67s/it] 27%|██▋       | 41/153 [18:19<50:36, 27.11s/it] 16%|█▌        | 24/153 [18:29<1:37:20, 45.27s/it] 27%|██▋       | 42/153 [18:32<47:45, 25.82s/it] 28%|██▊       | 43/153 [18:33<47:08, 25.72s/it] 27%|██▋       | 42/153 [18:34<46:21, 25.06s/it] 22%|██▏       | 33/153 [18:39<1:08:48, 34.41s/it] 27%|██▋       | 42/153 [18:44<47:06, 25.46s/it] 27%|██▋       | 42/153 [18:46<50:04, 27.07s/it] 28%|██▊       | 43/153 [18:57<44:58, 24.54s/it] 28%|██▊       | 43/153 [18:58<47:25, 25.87s/it] 29%|██▉       | 44/153 [18:58<46:30, 25.60s/it] 16%|█▋        | 25/153 [18:59<1:37:59, 45.94s/it] 28%|██▊       | 43/153 [19:09<46:46, 25.51s/it] 28%|██▊       | 43/153 [19:14<49:53, 27.22s/it] 22%|██▏       | 34/153 [19:17<1:10:34, 35.58s/it] 16%|█▋        | 25/153 [19:20<1:39:49, 46.79s/it] 29%|██▉       | 44/153 [19:21<45:31, 25.06s/it] 29%|██▉       | 45/153 [19:21<44:49, 24.90s/it] 29%|██▉       | 44/153 [19:22<45:05, 24.82s/it] 29%|██▉       | 44/153 [19:34<46:05, 25.37s/it] 29%|██▉       | 44/153 [19:41<49:38, 27.32s/it] 30%|███       | 46/153 [19:46<44:17, 24.84s/it] 29%|██▉       | 45/153 [19:47<45:40, 25.37s/it] 23%|██▎       | 35/153 [19:49<1:07:51, 34.51s/it] 17%|█▋        | 26/153 [19:50<1:40:21, 47.41s/it] 29%|██▉       | 45/153 [19:51<47:00, 26.11s/it] 29%|██▉       | 45/153 [20:01<46:35, 25.88s/it] 29%|██▉       | 45/153 [20:06<48:02, 26.69s/it] 17%|█▋        | 26/153 [20:11<1:41:47, 48.09s/it] 30%|███       | 46/153 [20:14<46:04, 25.84s/it] 31%|███       | 47/153 [20:15<46:07, 26.11s/it] 30%|███       | 46/153 [20:16<45:59, 25.79s/it] 24%|██▎       | 36/153 [20:23<1:06:53, 34.30s/it] 30%|███       | 46/153 [20:25<44:56, 25.20s/it] 30%|███       | 46/153 [20:33<47:46, 26.79s/it] 18%|█▊        | 27/153 [20:34<1:37:35, 46.48s/it] 31%|███▏      | 48/153 [20:40<45:17, 25.88s/it] 31%|███       | 47/153 [20:43<45:50, 25.94s/it] 31%|███       | 47/153 [20:43<47:39, 26.97s/it] 31%|███       | 47/153 [20:51<45:09, 25.57s/it] 18%|█▊        | 27/153 [20:55<1:38:47, 47.04s/it] 24%|██▍       | 37/153 [20:57<1:06:00, 34.15s/it] 31%|███       | 47/153 [21:00<46:56, 26.57s/it] 31%|███▏      | 48/153 [21:07<44:44, 25.56s/it] 32%|███▏      | 49/153 [21:08<45:40, 26.35s/it] 31%|███▏      | 48/153 [21:08<45:54, 26.23s/it] 18%|█▊        | 28/153 [21:16<1:33:48, 45.03s/it] 31%|███▏      | 48/153 [21:18<45:09, 25.81s/it] 31%|███▏      | 48/153 [21:23<45:05, 25.76s/it] 32%|███▏      | 49/153 [21:32<43:32, 25.12s/it] 25%|██▍       | 38/153 [21:34<1:07:20, 35.13s/it] 33%|███▎      | 50/153 [21:36<46:14, 26.93s/it] 32%|███▏      | 49/153 [21:38<47:15, 27.26s/it] 32%|███▏      | 49/153 [21:41<43:31, 25.11s/it] 18%|█▊        | 28/153 [21:45<1:39:29, 47.75s/it] 32%|███▏      | 49/153 [21:52<45:55, 26.50s/it] 33%|███▎      | 50/153 [21:56<42:34, 24.80s/it] 19%|█▉        | 29/153 [21:57<1:31:01, 44.04s/it] 33%|███▎      | 51/153 [22:01<44:56, 26.44s/it] 33%|███▎      | 50/153 [22:04<46:12, 26.92s/it] 25%|██▌       | 39/153 [22:08<1:05:54, 34.69s/it] 33%|███▎      | 50/153 [22:10<44:51, 26.13s/it] 33%|███▎      | 50/153 [22:17<44:52, 26.14s/it] 33%|███▎      | 51/153 [22:21<42:29, 25.00s/it] 34%|███▍      | 52/153 [22:28<44:42, 26.56s/it] 33%|███▎      | 51/153 [22:32<46:26, 27.32s/it] 19%|█▉        | 29/153 [22:33<1:39:05, 47.95s/it] 33%|███▎      | 51/153 [22:37<44:59, 26.47s/it] 20%|█▉        | 30/153 [22:43<1:31:26, 44.61s/it] 33%|███▎      | 51/153 [22:43<44:30, 26.18s/it] 26%|██▌       | 40/153 [22:44<1:05:54, 34.99s/it] 34%|███▍      | 52/153 [22:48<43:06, 25.61s/it]