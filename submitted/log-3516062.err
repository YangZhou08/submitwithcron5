wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:23, 27.92s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:27, 29.19s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:29, 29.88s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:27, 29.17s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:27, 29.16s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:27, 29.17s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:27, 29.12s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:27, 29.16s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:49, 24.92s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:50, 25.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:50, 25.37s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:50, 25.43s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:50, 25.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:51, 25.71s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:50, 25.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:50, 25.41s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:13<00:23, 23.76s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.25s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:15<00:24, 24.44s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.28s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.28s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.28s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 15.11s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.89s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 15.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.93s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:16<00:00, 15.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:16<00:00, 19.12s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 15.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.94s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 15.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.94s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 15.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.93s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 15.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 18.98s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 15.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:15<00:00, 19.00s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [00:43<14:28, 43.42s/it]  5%|▍         | 1/21 [00:43<14:28, 43.44s/it]  5%|▍         | 1/21 [00:43<14:24, 43.22s/it]  5%|▍         | 1/21 [00:43<14:24, 43.23s/it]  5%|▍         | 1/21 [00:43<14:29, 43.47s/it]  5%|▍         | 1/21 [00:22<07:37, 22.86s/it]  5%|▍         | 1/21 [00:43<14:27, 43.36s/it]  5%|▍         | 1/21 [00:22<07:30, 22.52s/it] 10%|▉         | 2/21 [00:46<06:20, 20.01s/it] 10%|▉         | 2/21 [00:47<06:21, 20.10s/it] 10%|▉         | 2/21 [00:47<06:21, 20.09s/it] 10%|▉         | 2/21 [00:46<06:20, 20.01s/it] 10%|▉         | 2/21 [00:26<03:40, 11.63s/it] 10%|▉         | 2/21 [00:47<06:21, 20.07s/it] 10%|▉         | 2/21 [00:47<06:22, 20.11s/it] 10%|▉         | 2/21 [00:26<03:38, 11.49s/it] 14%|█▍        | 3/21 [01:11<06:35, 21.96s/it] 14%|█▍        | 3/21 [01:11<06:36, 22.01s/it] 14%|█▍        | 3/21 [01:11<06:36, 22.00s/it] 14%|█▍        | 3/21 [01:11<06:35, 21.96s/it] 14%|█▍        | 3/21 [01:11<06:35, 21.99s/it] 14%|█▍        | 3/21 [00:50<05:11, 17.33s/it] 14%|█▍        | 3/21 [01:11<06:36, 22.01s/it] 14%|█▍        | 3/21 [00:50<05:13, 17.40s/it] 19%|█▉        | 4/21 [01:38<06:51, 24.22s/it] 19%|█▉        | 4/21 [01:39<06:52, 24.25s/it] 19%|█▉        | 4/21 [01:39<06:52, 24.26s/it] 19%|█▉        | 4/21 [01:39<06:52, 24.25s/it] 19%|█▉        | 4/21 [01:39<06:52, 24.24s/it] 19%|█▉        | 4/21 [01:38<06:51, 24.22s/it] 19%|█▉        | 4/21 [01:18<06:04, 21.46s/it] 19%|█▉        | 4/21 [01:18<06:04, 21.42s/it] 24%|██▍       | 5/21 [01:40<04:15, 15.99s/it] 24%|██▍       | 5/21 [01:40<04:15, 15.99s/it] 24%|██▍       | 5/21 [01:40<04:15, 15.97s/it] 24%|██▍       | 5/21 [01:40<04:15, 15.97s/it] 24%|██▍       | 5/21 [01:40<04:15, 15.99s/it] 24%|██▍       | 5/21 [01:19<03:46, 14.18s/it] 24%|██▍       | 5/21 [01:40<04:15, 15.98s/it] 24%|██▍       | 5/21 [01:19<03:47, 14.21s/it] 29%|██▊       | 6/21 [01:55<03:56, 15.76s/it] 29%|██▊       | 6/21 [01:55<03:56, 15.76s/it] 29%|██▊       | 6/21 [01:55<03:56, 15.75s/it] 29%|██▊       | 6/21 [01:55<03:56, 15.76s/it] 29%|██▊       | 6/21 [01:55<03:56, 15.76s/it] 29%|██▊       | 6/21 [01:55<03:56, 15.75s/it] 29%|██▊       | 6/21 [01:34<03:38, 14.56s/it] 29%|██▊       | 6/21 [01:35<03:38, 14.58s/it] 33%|███▎      | 7/21 [01:58<02:39, 11.42s/it] 33%|███▎      | 7/21 [01:58<02:39, 11.41s/it] 33%|███▎      | 7/21 [01:58<02:39, 11.41s/it] 33%|███▎      | 7/21 [01:58<02:39, 11.42s/it] 33%|███▎      | 7/21 [01:58<02:39, 11.42s/it] 33%|███▎      | 7/21 [01:58<02:39, 11.42s/it] 33%|███▎      | 7/21 [01:37<02:28, 10.61s/it] 33%|███▎      | 7/21 [01:37<02:28, 10.63s/it] 38%|███▊      | 8/21 [02:00<01:50,  8.49s/it] 38%|███▊      | 8/21 [02:00<01:50,  8.49s/it] 38%|███▊      | 8/21 [02:00<01:50,  8.48s/it] 38%|███▊      | 8/21 [02:00<01:50,  8.49s/it] 38%|███▊      | 8/21 [02:00<01:50,  8.48s/it] 38%|███▊      | 8/21 [01:39<01:43,  7.94s/it] 38%|███▊      | 8/21 [01:39<01:43,  7.95s/it] 38%|███▊      | 8/21 [02:00<01:50,  8.49s/it] 43%|████▎     | 9/21 [02:09<01:45,  8.83s/it] 43%|████▎     | 9/21 [02:10<01:45,  8.83s/it] 43%|████▎     | 9/21 [02:10<01:46,  8.83s/it] 43%|████▎     | 9/21 [02:10<01:46,  8.84s/it] 43%|████▎     | 9/21 [02:10<01:46,  8.83s/it] 43%|████▎     | 9/21 [02:09<01:45,  8.83s/it] 43%|████▎     | 9/21 [01:49<01:41,  8.46s/it] 43%|████▎     | 9/21 [01:49<01:41,  8.46s/it] 48%|████▊     | 10/21 [04:20<08:28, 46.21s/it] 48%|████▊     | 10/21 [04:20<08:28, 46.21s/it] 48%|████▊     | 10/21 [04:20<08:28, 46.21s/it] 48%|████▊     | 10/21 [04:19<08:28, 46.21s/it] 48%|████▊     | 10/21 [04:19<08:28, 46.21s/it] 48%|████▊     | 10/21 [04:19<08:28, 46.21s/it] 48%|████▊     | 10/21 [03:59<08:25, 45.95s/it] 48%|████▊     | 10/21 [03:59<08:25, 45.96s/it] 52%|█████▏    | 11/21 [04:42<06:29, 38.93s/it] 52%|█████▏    | 11/21 [04:42<06:29, 38.93s/it] 52%|█████▏    | 11/21 [04:42<06:29, 38.93s/it] 52%|█████▏    | 11/21 [04:42<06:29, 38.93s/it] 52%|█████▏    | 11/21 [04:42<06:29, 38.93s/it] 52%|█████▏    | 11/21 [04:42<06:29, 38.93s/it] 52%|█████▏    | 11/21 [04:21<06:27, 38.75s/it] 52%|█████▏    | 11/21 [04:21<06:27, 38.75s/it] 57%|█████▋    | 12/21 [04:49<04:24, 29.34s/it] 57%|█████▋    | 12/21 [04:49<04:24, 29.34s/it] 57%|█████▋    | 12/21 [04:49<04:24, 29.34s/it] 57%|█████▋    | 12/21 [04:49<04:24, 29.34s/it] 57%|█████▋    | 12/21 [04:28<04:22, 29.22s/it] 57%|█████▋    | 12/21 [04:29<04:22, 29.22s/it] 57%|█████▋    | 12/21 [04:49<04:24, 29.34s/it] 57%|█████▋    | 12/21 [04:49<04:24, 29.34s/it] 62%|██████▏   | 13/21 [04:56<02:59, 22.39s/it] 62%|██████▏   | 13/21 [04:56<02:59, 22.39s/it] 62%|██████▏   | 13/21 [04:56<02:59, 22.39s/it] 62%|██████▏   | 13/21 [04:56<02:59, 22.39s/it] 62%|██████▏   | 13/21 [04:56<02:59, 22.39s/it] 62%|██████▏   | 13/21 [04:56<02:59, 22.39s/it] 62%|██████▏   | 13/21 [04:35<02:58, 22.30s/it] 62%|██████▏   | 13/21 [04:35<02:58, 22.30s/it] 67%|██████▋   | 14/21 [04:58<01:53, 16.22s/it] 67%|██████▋   | 14/21 [04:58<01:53, 16.22s/it] 67%|██████▋   | 14/21 [04:57<01:53, 16.22s/it] 67%|██████▋   | 14/21 [04:58<01:53, 16.22s/it] 67%|██████▋   | 14/21 [04:58<01:53, 16.22s/it] 67%|██████▋   | 14/21 [04:37<01:53, 16.16s/it] 67%|██████▋   | 14/21 [04:57<01:53, 16.22s/it] 67%|██████▋   | 14/21 [04:37<01:53, 16.16s/it] 71%|███████▏  | 15/21 [05:05<01:21, 13.50s/it] 71%|███████▏  | 15/21 [05:05<01:21, 13.50s/it] 71%|███████▏  | 15/21 [05:05<01:21, 13.50s/it] 71%|███████▏  | 15/21 [05:05<01:21, 13.50s/it] 71%|███████▏  | 15/21 [05:05<01:21, 13.50s/it] 71%|███████▏  | 15/21 [05:05<01:21, 13.50s/it] 71%|███████▏  | 15/21 [04:44<01:20, 13.46s/it] 71%|███████▏  | 15/21 [04:44<01:20, 13.46s/it] 76%|███████▌  | 16/21 [05:31<01:26, 17.34s/it] 76%|███████▌  | 16/21 [05:31<01:26, 17.34s/it] 76%|███████▌  | 16/21 [05:31<01:26, 17.34s/it] 76%|███████▌  | 16/21 [05:31<01:26, 17.34s/it] 76%|███████▌  | 16/21 [05:31<01:26, 17.34s/it] 76%|███████▌  | 16/21 [05:31<01:26, 17.34s/it] 76%|███████▌  | 16/21 [05:10<01:26, 17.31s/it] 76%|███████▌  | 16/21 [05:11<01:26, 17.31s/it] 81%|████████  | 17/21 [05:35<00:53, 13.28s/it] 81%|████████  | 17/21 [05:35<00:53, 13.28s/it] 81%|████████  | 17/21 [05:35<00:53, 13.28s/it] 81%|████████  | 17/21 [05:35<00:53, 13.28s/it] 81%|████████  | 17/21 [05:35<00:53, 13.28s/it] 81%|████████  | 17/21 [05:35<00:53, 13.28s/it] 81%|████████  | 17/21 [05:14<00:53, 13.26s/it] 81%|████████  | 17/21 [05:14<00:53, 13.26s/it] 86%|████████▌ | 18/21 [05:38<00:30, 10.28s/it] 86%|████████▌ | 18/21 [05:38<00:30, 10.28s/it] 86%|████████▌ | 18/21 [05:38<00:30, 10.28s/it] 86%|████████▌ | 18/21 [05:38<00:30, 10.28s/it] 86%|████████▌ | 18/21 [05:38<00:30, 10.28s/it] 86%|████████▌ | 18/21 [05:17<00:30, 10.27s/it] 86%|████████▌ | 18/21 [05:38<00:30, 10.28s/it] 86%|████████▌ | 18/21 [05:18<00:30, 10.27s/it] 90%|█████████ | 19/21 [05:42<00:16,  8.19s/it] 90%|█████████ | 19/21 [05:42<00:16,  8.19s/it] 90%|█████████ | 19/21 [05:41<00:16,  8.19s/it] 90%|█████████ | 19/21 [05:42<00:16,  8.19s/it] 90%|█████████ | 19/21 [05:42<00:16,  8.19s/it] 90%|█████████ | 19/21 [05:21<00:16,  8.18s/it] 90%|█████████ | 19/21 [05:21<00:16,  8.18s/it] 90%|█████████ | 19/21 [05:41<00:16,  8.19s/it] 95%|█████████▌| 20/21 [05:43<00:06,  6.21s/it] 95%|█████████▌| 20/21 [05:43<00:06,  6.21s/it] 95%|█████████▌| 20/21 [05:43<00:06,  6.21s/it] 95%|█████████▌| 20/21 [05:43<00:06,  6.21s/it] 95%|█████████▌| 20/21 [05:43<00:06,  6.21s/it] 95%|█████████▌| 20/21 [05:43<00:06,  6.21s/it] 95%|█████████▌| 20/21 [05:23<00:06,  6.20s/it] 95%|█████████▌| 20/21 [05:22<00:06,  6.20s/it]100%|██████████| 21/21 [05:50<00:00,  6.60s/it]100%|██████████| 21/21 [05:51<00:00,  6.60s/it]100%|██████████| 21/21 [05:51<00:00,  6.60s/it]100%|██████████| 21/21 [05:50<00:00,  6.60s/it]100%|██████████| 21/21 [05:30<00:00,  6.59s/it]100%|██████████| 21/21 [05:30<00:00,  6.59s/it]100%|██████████| 21/21 [05:51<00:00,  6.60s/it]100%|██████████| 21/21 [05:51<00:00,  6.60s/it]22it [05:54,  5.52s/it]                        22it [05:54,  5.52s/it]                        22it [05:54,  5.52s/it]                        22it [05:54,  5.52s/it]                        22it [05:54,  5.52s/it]                        22it [05:33,  5.52s/it]                        22it [05:54,  5.52s/it]                        22it [05:33,  5.52s/it]                        23it [06:18, 11.14s/it]23it [06:18, 11.14s/it]23it [06:18, 11.14s/it]23it [06:18, 11.14s/it]23it [05:57, 11.14s/it]23it [06:18, 11.14s/it]23it [06:18, 11.14s/it]23it [05:57, 11.14s/it]24it [06:20,  8.38s/it]24it [06:20,  8.38s/it]24it [06:20,  8.38s/it]24it [06:20,  8.38s/it]24it [06:20,  8.38s/it]24it [06:20,  8.38s/it]24it [05:59,  8.38s/it]24it [05:59,  8.38s/it]25it [06:40, 11.96s/it]25it [06:40, 11.96s/it]25it [06:40, 11.96s/it]25it [06:40, 11.96s/it]25it [06:40, 11.96s/it]25it [06:40, 11.96s/it]25it [06:19, 11.96s/it]25it [06:20, 11.96s/it]26it [06:44,  9.48s/it]26it [06:44,  9.48s/it]26it [06:44,  9.48s/it]26it [06:44,  9.48s/it]26it [06:44,  9.48s/it]26it [06:23,  9.48s/it]26it [06:23,  9.48s/it]26it [06:44,  9.48s/it]27it [06:47,  7.63s/it]27it [06:47,  7.63s/it]27it [06:47,  7.63s/it]27it [06:47,  7.63s/it]27it [06:47,  7.63s/it]27it [06:26,  7.63s/it]27it [06:47,  7.63s/it]27it [06:27,  7.63s/it]28it [07:04, 10.32s/it]28it [07:04, 10.32s/it]28it [07:04, 10.32s/it]28it [07:04, 10.32s/it]28it [07:04, 10.32s/it]28it [06:43, 10.32s/it]28it [07:04, 10.32s/it]28it [06:43, 10.32s/it]29it [07:15, 10.60s/it]29it [07:15, 10.60s/it]29it [07:15, 10.60s/it]29it [07:15, 10.60s/it]29it [07:15, 10.60s/it]29it [06:55, 10.60s/it]29it [07:15, 10.60s/it]29it [06:54, 10.60s/it]30it [07:17,  8.05s/it]30it [06:57,  8.05s/it]30it [07:17,  8.05s/it]30it [07:17,  8.05s/it]30it [07:17,  8.05s/it]30it [07:17,  8.05s/it]30it [06:56,  8.05s/it]30it [07:17,  8.05s/it]31it [07:38, 11.98s/it]31it [07:38, 11.98s/it]31it [07:38, 11.98s/it]31it [07:38, 11.98s/it]31it [07:38, 11.98s/it]31it [07:38, 11.98s/it]31it [07:18, 11.98s/it]31it [07:17, 11.98s/it]32it [07:49, 11.70s/it]32it [07:49, 11.70s/it]32it [07:49, 11.70s/it]32it [07:49, 11.70s/it]32it [07:49, 11.70s/it]32it [07:49, 11.70s/it]32it [07:29, 11.70s/it]32it [07:28, 11.70s/it]33it [08:07, 13.48s/it]33it [08:07, 13.48s/it]33it [08:07, 13.48s/it]33it [08:07, 13.48s/it]33it [08:07, 13.48s/it]33it [08:07, 13.48s/it]33it [07:46, 13.48s/it]33it [07:46, 13.48s/it]34it [08:27, 15.41s/it]34it [08:27, 15.41s/it]34it [08:27, 15.41s/it]34it [08:27, 15.41s/it]34it [08:27, 15.41s/it]34it [08:27, 15.41s/it]34it [08:06, 15.41s/it]34it [08:06, 15.41s/it]35it [08:44, 16.03s/it]35it [08:44, 16.03s/it]35it [08:44, 16.03s/it]35it [08:44, 16.03s/it]35it [08:44, 16.03s/it]35it [08:44, 16.03s/it]35it [08:24, 16.03s/it]35it [08:23, 16.03s/it]36it [08:46, 11.78s/it]36it [08:46, 11.78s/it]36it [08:46, 11.78s/it]36it [08:46, 11.78s/it]36it [08:46, 11.78s/it]36it [08:26, 11.78s/it]36it [08:25, 11.78s/it]36it [08:46, 11.78s/it]37it [08:49,  9.16s/it]37it [08:49,  9.16s/it]37it [08:49,  9.16s/it]37it [08:49,  9.16s/it]37it [08:49,  9.16s/it]37it [08:28,  9.16s/it]37it [08:29,  9.16s/it]37it [08:49,  9.16s/it]38it [08:56,  8.38s/it]38it [08:56,  8.38s/it]38it [08:56,  8.38s/it]38it [08:56,  8.38s/it]38it [08:56,  8.38s/it]38it [08:56,  8.38s/it]38it [08:35,  8.38s/it]38it [08:35,  8.38s/it]39it [08:58,  6.63s/it]39it [08:58,  6.63s/it]39it [08:58,  6.63s/it]39it [08:58,  6.63s/it]39it [08:58,  6.63s/it]39it [08:58,  6.63s/it]39it [08:38,  6.63s/it]39it [08:38,  6.63s/it]40it [09:01,  5.40s/it]40it [09:01,  5.40s/it]40it [09:01,  5.40s/it]40it [09:01,  5.40s/it]40it [08:40,  5.40s/it]40it [08:40,  5.40s/it]40it [09:01,  5.40s/it]40it [09:01,  5.40s/it]41it [09:04,  4.68s/it]41it [09:04,  4.68s/it]41it [09:04,  4.68s/it]41it [09:04,  4.68s/it]41it [09:04,  4.68s/it]41it [09:04,  4.68s/it]41it [08:43,  4.68s/it]41it [08:43,  4.68s/it]41it [09:04, 13.27s/it]41it [09:04, 13.28s/it]41it [09:04, 13.28s/it]41it [09:04, 13.28s/it]41it [09:04, 13.28s/it]




41it [09:04, 13.27s/it]
41it [08:43, 12.77s/it]41it [08:43, 12.78s/it]

/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
