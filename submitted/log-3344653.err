wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:51<00:51, 51.40s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:53<00:53, 53.37s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.79s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.68s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.55s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.79s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.68s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.69s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.74s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.68s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.75s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.80s/it]
  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [01:38<32:44, 98.22s/it]  5%|▍         | 1/21 [01:38<32:56, 98.83s/it]  5%|▍         | 1/21 [01:39<33:00, 99.01s/it]  5%|▍         | 1/21 [01:38<32:55, 98.78s/it]  5%|▍         | 1/21 [01:39<33:12, 99.63s/it]  5%|▍         | 1/21 [01:14<24:57, 74.89s/it]  5%|▍         | 1/21 [01:38<32:54, 98.71s/it]  5%|▍         | 1/21 [01:15<25:08, 75.44s/it] 10%|▉         | 2/21 [02:23<21:13, 67.03s/it] 10%|▉         | 2/21 [02:22<21:07, 66.71s/it] 10%|▉         | 2/21 [02:23<21:11, 66.94s/it] 10%|▉         | 2/21 [02:24<21:18, 67.28s/it] 10%|▉         | 2/21 [01:59<18:04, 57.10s/it] 10%|▉         | 2/21 [02:23<21:12, 66.96s/it] 10%|▉         | 2/21 [02:00<18:09, 57.33s/it] 10%|▉         | 2/21 [02:23<21:11, 66.91s/it] 14%|█▍        | 3/21 [03:11<17:28, 58.23s/it] 14%|█▍        | 3/21 [03:12<17:30, 58.37s/it] 14%|█▍        | 3/21 [03:11<17:27, 58.18s/it] 14%|█▍        | 3/21 [02:47<15:53, 52.96s/it] 14%|█▍        | 3/21 [03:10<17:25, 58.06s/it] 14%|█▍        | 3/21 [03:11<17:27, 58.19s/it] 14%|█▍        | 3/21 [02:47<15:51, 52.84s/it] 14%|█▍        | 3/21 [03:11<17:26, 58.17s/it] 19%|█▉        | 4/21 [04:21<17:46, 62.76s/it] 19%|█▉        | 4/21 [04:20<17:45, 62.65s/it] 19%|█▉        | 4/21 [04:20<17:46, 62.74s/it] 19%|█▉        | 4/21 [03:56<16:51, 59.49s/it] 19%|█▉        | 4/21 [03:57<16:52, 59.57s/it] 19%|█▉        | 4/21 [04:21<17:48, 62.84s/it] 19%|█▉        | 4/21 [04:20<17:46, 62.72s/it] 19%|█▉        | 4/21 [04:20<17:46, 62.73s/it] 24%|██▍       | 5/21 [04:56<15:53, 59.58s/it] 24%|██▍       | 5/21 [05:20<16:26, 61.67s/it] 24%|██▍       | 5/21 [05:20<16:26, 61.65s/it] 24%|██▍       | 5/21 [05:20<16:25, 61.60s/it] 24%|██▍       | 5/21 [05:20<16:26, 61.64s/it] 24%|██▍       | 5/21 [05:21<16:27, 61.72s/it] 24%|██▍       | 5/21 [05:20<16:26, 61.65s/it] 24%|██▍       | 5/21 [04:57<15:54, 59.63s/it] 29%|██▊       | 6/21 [06:08<14:13, 56.91s/it] 29%|██▊       | 6/21 [06:07<14:12, 56.86s/it] 29%|██▊       | 6/21 [06:08<14:13, 56.89s/it] 29%|██▊       | 6/21 [06:09<14:14, 56.94s/it] 29%|██▊       | 6/21 [06:08<14:13, 56.89s/it] 29%|██▊       | 6/21 [05:44<13:52, 55.53s/it] 29%|██▊       | 6/21 [05:44<13:53, 55.56s/it] 29%|██▊       | 6/21 [06:08<14:13, 56.89s/it] 33%|███▎      | 7/21 [07:02<13:01, 55.79s/it] 33%|███▎      | 7/21 [07:01<13:00, 55.75s/it] 33%|███▎      | 7/21 [07:01<13:00, 55.76s/it] 33%|███▎      | 7/21 [07:01<13:00, 55.76s/it] 33%|███▎      | 7/21 [06:37<12:47, 54.84s/it] 33%|███▎      | 7/21 [06:38<12:47, 54.86s/it] 33%|███▎      | 7/21 [07:01<13:00, 55.75s/it] 33%|███▎      | 7/21 [07:01<13:00, 55.73s/it] 38%|███▊      | 8/21 [07:54<11:49, 54.56s/it] 38%|███▊      | 8/21 [07:53<11:48, 54.53s/it] 38%|███▊      | 8/21 [07:53<11:48, 54.54s/it] 38%|███▊      | 8/21 [07:30<11:40, 53.92s/it] 38%|███▊      | 8/21 [07:53<11:48, 54.52s/it] 38%|███▊      | 8/21 [07:53<11:48, 54.53s/it] 38%|███▊      | 8/21 [07:29<11:40, 53.91s/it] 38%|███▊      | 8/21 [07:53<11:49, 54.54s/it] 43%|████▎     | 9/21 [09:07<12:05, 60.49s/it] 43%|████▎     | 9/21 [09:08<12:05, 60.50s/it] 43%|████▎     | 9/21 [09:07<12:05, 60.49s/it] 43%|████▎     | 9/21 [09:07<12:05, 60.48s/it] 43%|████▎     | 9/21 [09:07<12:05, 60.48s/it] 43%|████▎     | 9/21 [09:06<12:05, 60.47s/it] 43%|████▎     | 9/21 [08:43<12:00, 60.05s/it] 43%|████▎     | 9/21 [08:43<12:00, 60.06s/it] 48%|████▊     | 10/21 [10:08<11:07, 60.67s/it] 48%|████▊     | 10/21 [10:07<11:07, 60.67s/it] 48%|████▊     | 10/21 [10:08<11:07, 60.67s/it] 48%|████▊     | 10/21 [10:09<11:07, 60.68s/it] 48%|████▊     | 10/21 [10:08<11:07, 60.67s/it] 48%|████▊     | 10/21 [10:08<11:07, 60.67s/it] 48%|████▊     | 10/21 [09:44<11:04, 60.38s/it] 48%|████▊     | 10/21 [09:44<11:04, 60.37s/it] 52%|█████▏    | 11/21 [10:55<09:24, 56.50s/it] 52%|█████▏    | 11/21 [10:54<09:24, 56.49s/it] 52%|█████▏    | 11/21 [10:55<09:24, 56.50s/it] 52%|█████▏    | 11/21 [10:55<09:24, 56.50s/it] 52%|█████▏    | 11/21 [10:31<09:22, 56.29s/it] 52%|█████▏    | 11/21 [10:31<09:22, 56.30s/it] 52%|█████▏    | 11/21 [10:56<09:25, 56.50s/it] 52%|█████▏    | 11/21 [10:55<09:24, 56.50s/it] 57%|█████▋    | 12/21 [11:51<08:26, 56.28s/it] 57%|█████▋    | 12/21 [11:50<08:26, 56.28s/it] 57%|█████▋    | 12/21 [11:51<08:26, 56.28s/it] 57%|█████▋    | 12/21 [11:51<08:26, 56.28s/it] 57%|█████▋    | 12/21 [11:51<08:26, 56.28s/it] 57%|█████▋    | 12/21 [11:51<08:26, 56.29s/it] 57%|█████▋    | 12/21 [11:27<08:25, 56.14s/it] 57%|█████▋    | 12/21 [11:27<08:25, 56.14s/it] 62%|██████▏   | 13/21 [12:45<07:25, 55.72s/it] 62%|██████▏   | 13/21 [12:45<07:25, 55.72s/it] 62%|██████▏   | 13/21 [12:21<07:24, 55.62s/it] 62%|██████▏   | 13/21 [12:45<07:25, 55.72s/it] 62%|██████▏   | 13/21 [12:44<07:25, 55.71s/it] 62%|██████▏   | 13/21 [12:46<07:25, 55.72s/it] 62%|██████▏   | 13/21 [12:22<07:24, 55.62s/it] 62%|██████▏   | 13/21 [12:45<07:25, 55.72s/it] 67%|██████▋   | 14/21 [13:44<06:37, 56.74s/it] 67%|██████▋   | 14/21 [13:21<06:36, 56.68s/it] 67%|██████▋   | 14/21 [13:44<06:37, 56.75s/it] 67%|██████▋   | 14/21 [13:44<06:37, 56.75s/it] 67%|██████▋   | 14/21 [13:44<06:37, 56.75s/it] 67%|██████▋   | 14/21 [13:20<06:36, 56.68s/it] 67%|██████▋   | 14/21 [13:45<06:37, 56.75s/it] 67%|██████▋   | 14/21 [13:44<06:37, 56.75s/it] 71%|███████▏  | 15/21 [14:33<05:27, 54.61s/it] 71%|███████▏  | 15/21 [14:34<05:27, 54.61s/it] 71%|███████▏  | 15/21 [14:35<05:27, 54.61s/it] 71%|███████▏  | 15/21 [14:10<05:27, 54.56s/it] 71%|███████▏  | 15/21 [14:34<05:27, 54.61s/it] 71%|███████▏  | 15/21 [14:34<05:27, 54.61s/it] 71%|███████▏  | 15/21 [14:10<05:27, 54.56s/it] 71%|███████▏  | 15/21 [14:34<05:27, 54.61s/it] 76%|███████▌  | 16/21 [15:31<04:37, 55.40s/it] 76%|███████▌  | 16/21 [15:31<04:37, 55.40s/it] 76%|███████▌  | 16/21 [15:08<04:36, 55.37s/it] 76%|███████▌  | 16/21 [15:32<04:37, 55.40s/it] 76%|███████▌  | 16/21 [15:31<04:37, 55.40s/it] 76%|███████▌  | 16/21 [15:07<04:36, 55.37s/it] 76%|███████▌  | 16/21 [15:31<04:37, 55.40s/it] 76%|███████▌  | 16/21 [15:30<04:37, 55.40s/it] 81%|████████  | 17/21 [16:25<03:39, 54.96s/it] 81%|████████  | 17/21 [16:01<03:39, 54.94s/it] 81%|████████  | 17/21 [16:26<03:39, 54.96s/it] 81%|████████  | 17/21 [16:25<03:39, 54.96s/it] 81%|████████  | 17/21 [16:25<03:39, 54.96s/it] 81%|████████  | 17/21 [16:02<03:39, 54.94s/it] 81%|████████  | 17/21 [16:24<03:39, 54.96s/it] 81%|████████  | 17/21 [16:25<03:39, 54.96s/it] 86%|████████▌ | 18/21 [17:01<02:48, 56.22s/it] 86%|████████▌ | 18/21 [17:00<02:48, 56.22s/it] 86%|████████▌ | 18/21 [17:24<02:48, 56.24s/it] 86%|████████▌ | 18/21 [17:24<02:48, 56.24s/it] 86%|████████▌ | 18/21 [17:24<02:48, 56.24s/it] 86%|████████▌ | 18/21 [17:24<02:48, 56.24s/it] 86%|████████▌ | 18/21 [17:24<02:48, 56.24s/it] 86%|████████▌ | 18/21 [17:25<02:48, 56.24s/it] 90%|█████████ | 19/21 [18:14<01:48, 54.32s/it] 90%|█████████ | 19/21 [18:14<01:48, 54.32s/it] 90%|█████████ | 19/21 [17:51<01:48, 54.30s/it] 90%|█████████ | 19/21 [18:15<01:48, 54.32s/it] 90%|█████████ | 19/21 [17:50<01:48, 54.30s/it] 90%|█████████ | 19/21 [18:13<01:48, 54.32s/it] 90%|█████████ | 19/21 [18:14<01:48, 54.32s/it] 90%|█████████ | 19/21 [18:14<01:48, 54.32s/it] 95%|█████████▌| 20/21 [18:56<00:50, 50.62s/it] 95%|█████████▌| 20/21 [18:56<00:50, 50.62s/it] 95%|█████████▌| 20/21 [18:56<00:50, 50.62s/it] 95%|█████████▌| 20/21 [18:33<00:50, 50.62s/it] 95%|█████████▌| 20/21 [18:55<00:50, 50.62s/it] 95%|█████████▌| 20/21 [18:32<00:50, 50.62s/it] 95%|█████████▌| 20/21 [18:57<00:50, 50.62s/it] 95%|█████████▌| 20/21 [18:56<00:50, 50.62s/it]100%|██████████| 21/21 [19:54<00:00, 52.84s/it]100%|██████████| 21/21 [19:53<00:00, 52.84s/it]100%|██████████| 21/21 [19:54<00:00, 52.84s/it]100%|██████████| 21/21 [19:55<00:00, 52.84s/it]100%|██████████| 21/21 [19:30<00:00, 52.83s/it]100%|██████████| 21/21 [19:54<00:00, 52.84s/it]100%|██████████| 21/21 [19:54<00:00, 52.84s/it]100%|██████████| 21/21 [19:31<00:00, 52.83s/it]22it [20:55, 55.36s/it]                        22it [20:32, 55.35s/it]                        22it [20:31, 55.35s/it]                        22it [20:55, 55.36s/it]                        22it [20:55, 55.36s/it]                        22it [20:55, 55.36s/it]                        22it [20:56, 55.36s/it]                        22it [20:56, 55.36s/it]                        23it [21:50, 55.30s/it]23it [21:27, 55.30s/it]23it [21:50, 55.30s/it]23it [21:50, 55.30s/it]23it [21:50, 55.30s/it]23it [21:51, 55.30s/it]23it [21:27, 55.30s/it]23it [21:51, 55.30s/it]24it [22:33, 51.39s/it]24it [22:32, 51.39s/it]24it [22:33, 51.39s/it]24it [22:33, 51.39s/it]24it [22:09, 51.39s/it]24it [22:34, 51.39s/it]24it [22:33, 51.39s/it]24it [22:09, 51.39s/it]25it [23:36, 54.91s/it]25it [23:13, 54.91s/it]25it [23:36, 54.91s/it]25it [23:36, 54.91s/it]25it [23:12, 54.91s/it]25it [23:35, 54.91s/it]25it [23:36, 54.91s/it]25it [23:37, 54.91s/it]26it [24:31, 54.84s/it]26it [24:07, 54.83s/it]26it [24:31, 54.84s/it]26it [24:31, 54.84s/it]26it [24:30, 54.84s/it]26it [24:30, 54.84s/it]26it [24:07, 54.83s/it]26it [24:30, 54.84s/it]27it [25:19, 52.61s/it]27it [25:18, 52.61s/it]27it [24:54, 52.61s/it]27it [25:18, 52.61s/it]27it [25:18, 52.61s/it]27it [24:55, 52.61s/it]27it [25:17, 52.61s/it]27it [25:18, 52.61s/it]28it [26:02, 50.14s/it]28it [26:02, 50.14s/it]28it [26:02, 50.14s/it]28it [25:38, 50.14s/it]28it [26:03, 50.14s/it]28it [26:02, 50.14s/it]28it [26:03, 50.14s/it]28it [25:39, 50.14s/it]29it [26:48, 55.93s/it]29it [26:48, 55.93s/it]29it [27:12, 55.93s/it]29it [27:12, 55.93s/it]29it [27:12, 55.93s/it]29it [27:13, 55.93s/it]29it [27:11, 55.93s/it]29it [27:12, 55.93s/it]30it [27:57, 52.73s/it]30it [27:57, 52.73s/it]30it [27:56, 52.73s/it]30it [27:33, 52.73s/it]30it [27:57, 52.73s/it]30it [27:34, 52.73s/it]30it [27:58, 52.73s/it]30it [27:57, 52.73s/it]31it [28:57, 54.94s/it]31it [28:57, 54.94s/it]31it [28:33, 54.94s/it]31it [28:34, 54.94s/it]31it [28:57, 54.94s/it]31it [28:57, 54.94s/it]31it [28:57, 54.94s/it]31it [28:58, 54.94s/it]32it [29:38, 50.62s/it]32it [29:37, 50.62s/it]32it [29:38, 50.62s/it]32it [29:38, 50.62s/it]32it [29:38, 50.62s/it]32it [29:14, 50.62s/it]32it [29:38, 50.62s/it]32it [29:14, 50.62s/it]33it [30:11, 45.08s/it]33it [30:10, 45.08s/it]33it [30:10, 45.08s/it]33it [30:10, 45.08s/it]33it [30:10, 45.08s/it]33it [30:09, 45.08s/it]33it [29:46, 45.08s/it]33it [29:46, 45.08s/it]34it [30:48, 43.28s/it]34it [30:49, 43.28s/it]34it [30:49, 43.28s/it]34it [30:25, 43.28s/it]34it [30:49, 43.28s/it]34it [30:49, 43.28s/it]34it [30:50, 43.28s/it]34it [30:26, 43.28s/it]35it [31:36, 44.56s/it]35it [31:36, 44.56s/it]35it [31:37, 44.56s/it]35it [31:36, 44.56s/it]35it [31:13, 44.56s/it]35it [31:37, 44.56s/it]35it [31:13, 44.56s/it]35it [31:36, 44.56s/it]36it [32:22, 44.95s/it]36it [32:23, 44.95s/it]36it [31:59, 44.95s/it]36it [32:22, 44.95s/it]36it [32:22, 44.95s/it]36it [32:22, 44.95s/it]36it [31:58, 44.95s/it]36it [32:22, 44.95s/it]37it [33:02, 50.33s/it]37it [33:25, 50.33s/it]37it [33:25, 50.33s/it]37it [33:25, 50.33s/it]37it [33:26, 50.33s/it]37it [33:25, 50.33s/it]37it [33:01, 50.33s/it]37it [33:25, 50.33s/it]38it [34:23, 52.57s/it]38it [34:23, 52.57s/it]38it [34:23, 52.57s/it]38it [33:59, 52.57s/it]38it [34:23, 52.57s/it]38it [34:22, 52.57s/it]38it [34:24, 52.57s/it]38it [34:00, 52.57s/it]39it [35:08, 50.38s/it]39it [34:44, 50.38s/it]39it [35:08, 50.38s/it]39it [35:08, 50.38s/it]39it [34:45, 50.38s/it]39it [35:08, 50.38s/it]39it [35:08, 50.38s/it]39it [35:09, 50.38s/it]40it [35:52, 48.52s/it]40it [35:52, 48.52s/it]40it [35:52, 48.52s/it]40it [35:29, 48.52s/it]40it [35:28, 48.52s/it]40it [35:52, 48.52s/it]40it [35:53, 48.52s/it]40it [35:53, 48.52s/it]41it [36:33, 53.46s/it]41it [36:34, 53.46s/it]41it [36:57, 53.46s/it]41it [36:57, 53.46s/it]41it [36:57, 53.46s/it]41it [36:57, 53.46s/it]41it [36:58, 53.46s/it]41it [36:34, 53.53s/it]41it [36:33, 53.51s/it]

41it [36:57, 54.10s/it]41it [36:57, 54.08s/it]

41it [36:58, 53.46s/it]41it [36:57, 54.09s/it]
41it [36:57, 54.09s/it]
41it [36:58, 54.10s/it]
41it [36:58, 54.12s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
