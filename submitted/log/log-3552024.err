Already on 'yangexp2threee'
From github.com:Infini-AI-Lab/GRIFFIN2
   599e6cd..c20612c  yangexp2threee -> origin/yangexp2threee
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-07-28:02:11:06,663 INFO     [main.py:288] Verbosity set to INFO
2024-07-28:02:11:16,284 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-28:02:11:16,285 INFO     [main.py:378] Selected Tasks: ['gsm8k_cot']
2024-07-28:02:11:16,309 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-28:02:11:16,309 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1500, 'kernel_size': 10, 'thr': 0.05, 'attentionimplementation': 'sdpa'}
2024-07-28:02:11:16,318 INFO     [xhuggingface.py:168] Using device 'cuda'
Traceback (most recent call last):
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/main.py", line 465, in <module>
    cli_evaluate()
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/main.py", line 384, in cli_evaluate
    results = xevaluator.simple_evaluate(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/lm_eval/utils.py", line 288, in _wrapper
    return fn(*args, **kwargs)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/xevaluator.py", line 188, in simple_evaluate
    lm = XHFLM.create_from_arg_string(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/lm_eval/api/model.py", line 133, in create_from_arg_string
    return cls(**args, **args2)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/xhuggingface.py", line 207, in __init__
    self._create_model(
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/xhuggingface.py", line 530, in _create_model
    self._model = LlamaForCausalLM.from_pretrained(
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3375, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/llama12_static_cache_sdpa_with_check.py", line 1111, in __init__
    self.model = LlamaModel(config)
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/llama12_static_cache_sdpa_with_check.py", line 986, in __init__
    [LlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/llama12_static_cache_sdpa_with_check.py", line 986, in <listcomp>
    [LlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]
  File "/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/GRIFFIN2/llama12_static_cache_sdpa_with_check.py", line 901, in __init__
    if self.config._attn_implementation == "general": 
  File "/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1688, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'LlamaDecoderLayer' object has no attribute 'config'
