fatal: Unable to create '/fsx-storygen/beidic/yang/CommonSenseReasoning/.git/index.lock': File exists.

Another git process seems to be running in this repository, e.g.
an editor opened by 'git commit'. Please make sure all processes
are terminated then try again. If it still fails, a git process
may have crashed in this repository earlier:
remove the file manually to continue.
error: cannot lock ref 'refs/remotes/origin/addinggriffin': is at 0bdd3fb5ef07ca57725777fc9dc6714d60d133ac but expected 528dee3d6fdcfa2326ab17cb55d250fedcd14657
From github.com:YangZhou08/CommonSenseReasoning
 ! 528dee3..0bdd3fb  addinggriffin -> origin/addinggriffin  (unable to update local ref)
warning: fetch updated the current branch head.
fast-forwarding your working tree from
commit 528dee3d6fdcfa2326ab17cb55d250fedcd14657.
error: Your local changes to the following files would be overwritten by merge:
	runtest.sh
Please commit your changes or stash them before you merge.
Aborting
fatal: Cannot fast-forward your working tree.
After making sure that you saved anything precious from
$ git diff 528dee3d6fdcfa2326ab17cb55d250fedcd14657
output, run
$ git reset --hard
to recover.
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:18, 26.07s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.44s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.40s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.51s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:18, 26.30s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.46s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.42s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:20, 26.69s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:43, 21.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.50s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.96s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.56s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.58s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.57s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.41s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.59s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.41s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.42s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:01<00:19, 19.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.41s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.87s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.37s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.88s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.87s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.90s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.89s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.86s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.41s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.91s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 12.40s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.91s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]  0%|          | 0/32 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:397: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  3%|▎         | 1/32 [00:03<01:35,  3.07s/it]  3%|▎         | 1/32 [00:03<01:51,  3.59s/it]  3%|▎         | 1/32 [00:03<01:51,  3.61s/it]  6%|▋         | 2/32 [00:04<00:58,  1.95s/it]  3%|▎         | 1/32 [00:04<02:20,  4.53s/it]  6%|▋         | 2/32 [00:05<01:15,  2.53s/it]  6%|▋         | 2/32 [00:05<01:22,  2.74s/it]  3%|▎         | 1/32 [00:06<03:07,  6.06s/it]  3%|▎         | 1/32 [00:06<03:21,  6.51s/it]  6%|▋         | 2/32 [00:06<01:34,  3.15s/it]  3%|▎         | 1/32 [00:07<03:40,  7.10s/it]  6%|▋         | 2/32 [00:07<01:46,  3.55s/it]  9%|▉         | 3/32 [00:08<01:15,  2.61s/it]  6%|▋         | 2/32 [00:08<01:59,  3.99s/it]  9%|▉         | 3/32 [00:09<01:33,  3.21s/it]  9%|▉         | 3/32 [00:10<01:20,  2.77s/it]  9%|▉         | 3/32 [00:09<01:33,  3.21s/it] 12%|█▎        | 4/32 [00:11<01:17,  2.78s/it]  3%|▎         | 1/32 [00:12<06:19, 12.24s/it] 12%|█▎        | 4/32 [00:13<01:34,  3.37s/it] 12%|█▎        | 4/32 [00:13<01:29,  3.20s/it]  9%|▉         | 3/32 [00:14<02:24,  4.99s/it]  6%|▋         | 2/32 [00:14<03:40,  7.35s/it] 16%|█▌        | 5/32 [00:15<01:27,  3.24s/it] 16%|█▌        | 5/32 [00:16<01:21,  3.03s/it]  9%|▉         | 3/32 [00:17<02:33,  5.29s/it] 16%|█▌        | 5/32 [00:18<01:42,  3.81s/it]  6%|▋         | 2/32 [00:18<04:21,  8.72s/it] 19%|█▉        | 6/32 [00:19<01:14,  2.85s/it]  9%|▉         | 3/32 [00:19<03:48,  7.88s/it] 12%|█▎        | 4/32 [00:19<02:24,  5.15s/it] 12%|█▎        | 4/32 [00:20<02:52,  6.16s/it] 12%|█▎        | 4/32 [00:22<02:48,  6.03s/it]  9%|▉         | 3/32 [00:22<03:15,  6.73s/it] 16%|█▌        | 5/32 [00:23<02:18,  5.12s/it] 19%|█▉        | 6/32 [00:24<01:59,  4.60s/it] 12%|█▎        | 4/32 [00:24<02:51,  6.13s/it] 19%|█▉        | 6/32 [00:25<02:27,  5.69s/it] 16%|█▌        | 5/32 [00:25<02:16,  5.05s/it] 19%|█▉        | 6/32 [00:26<01:55,  4.43s/it] 16%|█▌        | 5/32 [00:27<02:39,  5.90s/it] 22%|██▏       | 7/32 [00:27<01:43,  4.14s/it] 12%|█▎        | 4/32 [00:27<02:49,  6.07s/it] 19%|█▉        | 6/32 [00:28<01:54,  4.39s/it] 22%|██▏       | 7/32 [00:29<02:04,  4.97s/it] 16%|█▌        | 5/32 [00:29<02:30,  5.57s/it] 22%|██▏       | 7/32 [00:29<02:14,  5.38s/it] 25%|██▌       | 8/32 [00:30<01:31,  3.79s/it] 22%|██▏       | 7/32 [00:30<01:49,  4.36s/it] 25%|██▌       | 8/32 [00:30<01:34,  3.92s/it] 22%|██▏       | 7/32 [00:31<01:31,  3.64s/it] 25%|██▌       | 8/32 [00:31<01:40,  4.19s/it] 19%|█▉        | 6/32 [00:31<01:51,  4.31s/it] 19%|█▉        | 6/32 [00:32<02:30,  5.79s/it] 28%|██▊       | 9/32 [00:32<01:16,  3.33s/it] 28%|██▊       | 9/32 [00:33<01:17,  3.39s/it] 25%|██▌       | 8/32 [00:33<01:31,  3.83s/it] 28%|██▊       | 9/32 [00:33<01:21,  3.55s/it] 25%|██▌       | 8/32 [00:33<01:21,  3.40s/it] 31%|███▏      | 10/32 [00:34<01:00,  2.75s/it] 31%|███▏      | 10/32 [00:35<01:05,  3.00s/it] 34%|███▍      | 11/32 [00:35<00:47,  2.25s/it] 31%|███▏      | 10/32 [00:35<01:10,  3.23s/it] 28%|██▊       | 9/32 [00:36<01:20,  3.48s/it] 38%|███▊      | 12/32 [00:36<00:36,  1.82s/it] 22%|██▏       | 7/32 [00:36<01:55,  4.63s/it] 34%|███▍      | 11/32 [00:37<00:56,  2.68s/it] 31%|███▏      | 10/32 [00:37<01:02,  2.83s/it] 41%|████      | 13/32 [00:37<00:32,  1.72s/it] 34%|███▍      | 11/32 [00:38<01:02,  2.96s/it] 16%|█▌        | 5/32 [00:38<03:27,  7.69s/it] 22%|██▏       | 7/32 [00:39<02:34,  6.17s/it] 38%|███▊      | 12/32 [00:39<00:51,  2.56s/it] 34%|███▍      | 11/32 [00:41<01:08,  3.25s/it] 44%|████▍     | 14/32 [00:42<00:46,  2.56s/it] 19%|█▉        | 6/32 [00:42<02:51,  6.59s/it] 25%|██▌       | 8/32 [00:43<02:06,  5.28s/it] 25%|██▌       | 8/32 [00:43<02:10,  5.43s/it] 47%|████▋     | 15/32 [00:43<00:37,  2.21s/it] 28%|██▊       | 9/32 [00:44<02:10,  5.66s/it] 22%|██▏       | 7/32 [00:45<02:08,  5.13s/it] 38%|███▊      | 12/32 [00:45<01:10,  3.52s/it] 28%|██▊       | 9/32 [00:45<01:42,  4.44s/it] 50%|█████     | 16/32 [00:46<00:36,  2.25s/it] 38%|███▊      | 12/32 [00:47<01:40,  5.04s/it] 31%|███▏      | 10/32 [00:47<01:22,  3.74s/it] 28%|██▊       | 9/32 [00:48<01:59,  5.19s/it] 25%|██▌       | 8/32 [00:48<01:53,  4.71s/it] 41%|████      | 13/32 [00:49<01:10,  3.71s/it] 41%|████      | 13/32 [00:50<01:34,  4.99s/it] 28%|██▊       | 9/32 [00:50<01:29,  3.87s/it] 34%|███▍      | 11/32 [00:51<01:18,  3.73s/it] 44%|████▍     | 14/32 [00:52<01:02,  3.46s/it] 31%|███▏      | 10/32 [00:53<02:23,  6.52s/it] 31%|███▏      | 10/32 [00:53<01:52,  5.11s/it] 31%|███▏      | 10/32 [00:54<01:24,  3.82s/it] 34%|███▍      | 11/32 [00:54<01:23,  3.98s/it] 34%|███▍      | 11/32 [00:55<01:48,  5.16s/it] 34%|███▍      | 11/32 [00:56<01:04,  3.09s/it] 44%|████▍     | 14/32 [00:56<01:33,  5.19s/it] 47%|████▋     | 15/32 [00:56<01:00,  3.58s/it] 41%|████      | 13/32 [00:58<02:07,  6.70s/it] 38%|███▊      | 12/32 [00:58<00:55,  2.79s/it] 38%|███▊      | 12/32 [00:58<01:19,  3.98s/it] 41%|████      | 13/32 [01:00<00:50,  2.64s/it] 50%|█████     | 16/32 [01:00<00:58,  3.63s/it] 47%|████▋     | 15/32 [01:01<01:27,  5.13s/it] 44%|████▍     | 14/32 [01:01<01:42,  5.68s/it] 44%|████▍     | 14/32 [01:02<00:43,  2.44s/it] 50%|█████     | 16/32 [01:02<01:04,  4.03s/it] 47%|████▋     | 15/32 [01:03<00:36,  2.16s/it] 47%|████▋     | 15/32 [01:03<01:20,  4.74s/it] 38%|███▊      | 12/32 [01:04<02:07,  6.40s/it] 41%|████      | 13/32 [01:04<01:26,  4.56s/it] 38%|███▊      | 12/32 [01:05<02:17,  6.86s/it] 50%|█████     | 16/32 [01:06<00:34,  2.17s/it] 50%|█████     | 16/32 [01:07<01:07,  4.25s/it] 41%|████      | 13/32 [01:08<01:46,  5.61s/it] 41%|████      | 13/32 [01:08<01:49,  5.79s/it] 44%|████▍     | 14/32 [01:10<01:23,  4.62s/it] 44%|████▍     | 14/32 [01:11<01:35,  5.28s/it] 47%|████▋     | 15/32 [01:13<01:11,  4.18s/it] 44%|████▍     | 14/32 [01:17<01:58,  6.59s/it] 50%|█████     | 16/32 [01:18<01:10,  4.43s/it] 47%|████▋     | 15/32 [01:21<01:49,  6.42s/it] 47%|████▋     | 15/32 [01:21<01:42,  6.02s/it] 50%|█████     | 16/32 [01:23<01:19,  4.96s/it] 50%|█████     | 16/32 [01:27<01:35,  5.94s/it] 53%|█████▎    | 17/32 [01:30<01:15,  5.03s/it] 53%|█████▎    | 17/32 [01:30<02:53, 11.56s/it] 53%|█████▎    | 17/32 [01:30<02:12,  8.85s/it] 53%|█████▎    | 17/32 [01:30<01:25,  5.71s/it] 53%|█████▎    | 17/32 [01:30<02:30, 10.01s/it] 53%|█████▎    | 17/32 [01:30<01:41,  6.78s/it] 53%|█████▎    | 17/32 [01:30<03:43, 14.90s/it] 53%|█████▎    | 17/32 [01:30<02:48, 11.22s/it] 56%|█████▋    | 18/32 [01:31<01:32,  6.59s/it] 56%|█████▋    | 18/32 [01:32<02:34, 11.03s/it] 56%|█████▋    | 18/32 [01:33<02:04,  8.89s/it] 56%|█████▋    | 18/32 [01:33<02:01,  8.70s/it] 56%|█████▋    | 18/32 [01:33<01:50,  7.88s/it] 56%|█████▋    | 18/32 [01:33<01:08,  4.91s/it] 59%|█████▉    | 19/32 [01:34<01:48,  8.36s/it] 59%|█████▉    | 19/32 [01:34<01:16,  5.88s/it] 59%|█████▉    | 19/32 [01:35<00:50,  3.90s/it] 56%|█████▋    | 18/32 [01:36<01:30,  6.45s/it] 62%|██████▎   | 20/32 [01:36<01:16,  6.34s/it] 59%|█████▉    | 19/32 [01:36<01:31,  7.06s/it] 62%|██████▎   | 20/32 [01:37<00:58,  4.89s/it] 56%|█████▋    | 18/32 [01:38<01:21,  5.80s/it] 59%|█████▉    | 19/32 [01:38<01:40,  7.75s/it] 62%|██████▎   | 20/32 [01:38<01:07,  5.60s/it] 66%|██████▌   | 21/32 [01:39<00:59,  5.37s/it] 66%|██████▌   | 21/32 [01:40<00:48,  4.37s/it] 62%|██████▎   | 20/32 [01:40<01:13,  6.10s/it] 66%|██████▌   | 21/32 [01:41<00:51,  4.68s/it] 69%|██████▉   | 22/32 [01:41<00:43,  4.33s/it] 59%|█████▉    | 19/32 [01:42<01:41,  7.79s/it] 62%|██████▎   | 20/32 [01:42<01:00,  5.04s/it] 66%|██████▌   | 21/32 [01:43<00:56,  5.11s/it] 59%|█████▉    | 19/32 [01:43<01:13,  5.63s/it] 72%|███████▏  | 23/32 [01:43<00:33,  3.68s/it] 69%|██████▉   | 22/32 [01:43<00:40,  4.00s/it] 62%|██████▎   | 20/32 [01:43<01:09,  5.79s/it] 72%|███████▏  | 23/32 [01:45<00:29,  3.26s/it] 69%|██████▉   | 22/32 [01:45<00:44,  4.45s/it] 66%|██████▌   | 21/32 [01:45<00:50,  4.57s/it] 75%|███████▌  | 24/32 [01:45<00:25,  3.17s/it] 59%|█████▉    | 19/32 [01:45<01:35,  7.36s/it] 69%|██████▉   | 22/32 [01:45<00:42,  4.28s/it] 66%|██████▌   | 21/32 [01:46<00:49,  4.49s/it] 72%|███████▏  | 23/32 [01:46<00:30,  3.37s/it] 62%|██████▎   | 20/32 [01:47<01:04,  5.33s/it] 78%|███████▊  | 25/32 [01:48<00:17,  2.45s/it] 62%|██████▎   | 20/32 [01:49<01:17,  6.46s/it] 78%|███████▊  | 25/32 [01:49<00:25,  3.59s/it] 81%|████████▏ | 26/32 [01:50<00:14,  2.36s/it] 72%|███████▏  | 23/32 [01:51<00:41,  4.62s/it] 66%|██████▌   | 21/32 [01:51<00:51,  4.71s/it] 84%|████████▍ | 27/32 [01:52<00:11,  2.33s/it] 75%|███████▌  | 24/32 [01:53<00:31,  3.93s/it] 69%|██████▉   | 22/32 [01:53<00:56,  5.66s/it] 81%|████████▏ | 26/32 [01:53<00:21,  3.56s/it] 78%|███████▊  | 25/32 [01:55<00:23,  3.29s/it] 69%|██████▉   | 22/32 [01:55<00:47,  4.71s/it] 66%|██████▌   | 21/32 [01:56<01:10,  6.38s/it] 84%|████████▍ | 27/32 [01:56<00:16,  3.31s/it] 88%|████████▊ | 28/32 [01:56<00:11,  2.76s/it] 75%|███████▌  | 24/32 [01:56<00:44,  5.54s/it] 69%|██████▉   | 22/32 [01:56<01:03,  6.35s/it] 88%|████████▊ | 28/32 [01:57<00:10,  2.67s/it] 81%|████████▏ | 26/32 [01:57<00:18,  3.14s/it] 78%|███████▊  | 25/32 [01:58<00:30,  4.42s/it] 72%|███████▏  | 23/32 [01:59<00:46,  5.20s/it] 69%|██████▉   | 22/32 [02:00<00:57,  5.71s/it] 84%|████████▍ | 27/32 [02:00<00:14,  2.93s/it] 91%|█████████ | 29/32 [02:00<00:08,  2.88s/it] 91%|█████████ | 29/32 [02:01<00:10,  3.44s/it] 72%|███████▏  | 23/32 [02:01<00:40,  4.45s/it] 81%|████████▏ | 26/32 [02:02<00:25,  4.19s/it] 88%|████████▊ | 28/32 [02:03<00:11,  2.97s/it] 94%|█████████▍| 30/32 [02:03<00:05,  2.89s/it] 72%|███████▏  | 23/32 [02:04<01:04,  7.17s/it] 84%|████████▍ | 27/32 [02:05<00:19,  3.96s/it] 91%|█████████ | 29/32 [02:05<00:08,  2.77s/it] 75%|███████▌  | 24/32 [02:06<00:44,  5.58s/it] 97%|█████████▋| 31/32 [02:07<00:03,  3.15s/it] 88%|████████▊ | 28/32 [02:07<00:13,  3.47s/it] 75%|███████▌  | 24/32 [02:07<00:39,  4.95s/it] 78%|███████▊  | 25/32 [02:08<00:33,  4.75s/it] 94%|█████████▍| 30/32 [02:09<00:05,  2.95s/it] 75%|███████▌  | 24/32 [02:09<00:54,  6.85s/it] 81%|████████▏ | 26/32 [02:10<00:22,  3.77s/it] 97%|█████████▋| 31/32 [02:10<00:02,  2.57s/it] 94%|█████████▍| 30/32 [02:11<00:10,  5.47s/it] 84%|████████▍ | 27/32 [02:12<00:16,  3.29s/it]100%|██████████| 32/32 [02:13<00:00,  3.93s/it]100%|██████████| 32/32 [02:13<00:00,  4.16s/it]
 78%|███████▊  | 25/32 [02:13<00:40,  5.80s/it] 94%|█████████▍| 30/32 [02:13<00:06,  3.26s/it]100%|██████████| 32/32 [02:13<00:00,  2.73s/it]100%|██████████| 32/32 [02:13<00:00,  4.18s/it]
 97%|█████████▋| 31/32 [02:14<00:04,  4.47s/it] 72%|███████▏  | 23/32 [02:14<01:19,  8.85s/it] 78%|███████▊  | 25/32 [02:14<00:38,  5.43s/it] 88%|████████▊ | 28/32 [02:14<00:12,  3.04s/it] 97%|█████████▋| 31/32 [02:15<00:02,  2.91s/it]100%|██████████| 32/32 [02:16<00:00,  2.40s/it]100%|██████████| 32/32 [02:16<00:00,  4.27s/it]
100%|██████████| 32/32 [02:17<00:00,  4.19s/it]100%|██████████| 32/32 [02:17<00:00,  4.30s/it]
 91%|█████████ | 29/32 [02:17<00:08,  2.98s/it] 81%|████████▏ | 26/32 [02:18<00:30,  5.10s/it] 75%|███████▌  | 24/32 [02:21<01:06,  8.26s/it] 94%|█████████▍| 30/32 [02:21<00:06,  3.18s/it] 81%|████████▏ | 26/32 [02:23<00:43,  7.25s/it] 84%|████████▍ | 27/32 [02:26<00:28,  5.76s/it] 97%|█████████▋| 31/32 [02:26<00:03,  3.88s/it] 84%|████████▍ | 27/32 [02:28<00:32,  6.41s/it] 78%|███████▊  | 25/32 [02:32<01:03,  9.04s/it]100%|██████████| 32/32 [02:32<00:00,  4.51s/it]100%|██████████| 32/32 [02:32<00:00,  4.78s/it]
 88%|████████▊ | 28/32 [02:34<00:25,  6.44s/it] 91%|█████████ | 29/32 [02:36<00:15,  5.13s/it] 88%|████████▊ | 28/32 [02:37<00:29,  7.33s/it] 94%|█████████▍| 30/32 [02:40<00:09,  4.79s/it] 91%|█████████ | 29/32 [02:40<00:18,  6.14s/it] 94%|█████████▍| 30/32 [02:43<00:10,  5.13s/it] 97%|█████████▋| 31/32 [02:45<00:04,  4.85s/it]100%|██████████| 32/32 [02:46<00:00,  3.77s/it]100%|██████████| 32/32 [02:46<00:00,  5.20s/it]
 97%|█████████▋| 31/32 [02:48<00:04,  4.88s/it] 81%|████████▏ | 26/32 [02:50<01:11, 11.84s/it]100%|██████████| 32/32 [02:57<00:00,  6.18s/it]100%|██████████| 32/32 [02:57<00:00,  5.54s/it]
 84%|████████▍ | 27/32 [03:04<01:02, 12.55s/it] 88%|████████▊ | 28/32 [03:09<00:41, 10.35s/it] 91%|█████████ | 29/32 [03:11<00:23,  7.76s/it] 94%|█████████▍| 30/32 [03:14<00:12,  6.17s/it] 97%|█████████▋| 31/32 [03:15<00:04,  4.62s/it]100%|██████████| 32/32 [03:17<00:00,  4.04s/it]100%|██████████| 32/32 [03:17<00:00,  6.18s/it]
