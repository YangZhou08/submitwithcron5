Your branch is up to date with 'origin/addinggriffin'.
Updating 207605f..13208b8
Fast-forward
 llama12addingtree.py | 5 ++++-
 runtest.sh           | 3 ++-
 2 files changed, 6 insertions(+), 2 deletions(-)
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /data/home/beidic/.cache/huggingface/token
Login successful
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
We now use eos_token as pad token
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
is_distributed True
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device=None, limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
beam width is 8
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
beam width is 8
tasks ['aqua']
tasks ['aqua']
tasks ['aqua']tasks ['aqua']

tasks ['aqua']tasks ['aqua']

tasks ['aqua']
tasks ['aqua']
beamwidth is 6beamwidth is 6
beamwidth is 6
beamwidth is 6

beamwidth is 6
beamwidth is 6
beamwidth is 6
beamwidth is 6
Answer  expected e
Answer b expected c
Answer e expected e
Answer  expected b
Answer  expected a
Answer c expected d
Answer 0 expected b
Answer c expected c
Answer b expected b
Answer c expected e
Answer b expected b
Skipping the batch
Answer c expected c
Answer a expected b
index 4 start communication
Answer a expected d
Answer b expected d
Answer a expected d
Answer a expected a
index 7 start communication
Answer b expected d
Answer b expected b
Answer a expected a
Answer d expected b
Answer e expected e
index 2 start communication
index 6 start communication
Answer  expected a
Answer b expected a
index 3 start communication
index 1 start communication
Answer  expected c
Answer a expected a
Answer d expected d
Answer e expected c
Answer c expected d
Answer e expected a
Answer c expected b
Answer b expected c
index 0 start communication
Skipping the batch
index 5 start communication
Here are the statistics for inferenceHere are the statistics for inferenceHere are the statistics for inferenceHere are the statistics for inferenceHere are the statistics for inferenceHere are the statistics for inference

Here are the statistics for inference
Here are the statistics for inference




+--------+----------------+---------------------------+-----------------------------+---------------+-------------+---------+--------------------------------+------------------+----------------------------------+-----------------------+----------------------+
| Task   |   Num Sentence |   Total Generation Length |   Average Generation Length |   Total Steps |   Num Steps |     AAL |   Total Roll Back Length Error |   Error Instance |   Average Roll Back Length Error |   Effective Tree Size |   Drafting Tree Size |
+========+================+===========================+=============================+===============+=============+=========+================================+==================+==================================+=======================+======================+
| aqua   |            254 |                     36580 |                     144.016 |         32329 |        2359 | 13.7045 |                           5415 |              594 |                          9.11616 |               40.2675 |              3.69924 |
+--------+----------------+---------------------------+-----------------------------+---------------+-------------+---------+--------------------------------+------------------+----------------------------------+-----------------------+----------------------+
Namespace(tasks='aqua', model='meta-llama/Meta-Llama-3-8B', device='cuda:0', limit=None, griffin=True, cats=False, check=True, kernel_size=16, spr=0.5, thr=0.1, widthtree=6, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=True)
+--------+---------+-----------+--------------+
| Task   |   Total |   Correct |   Solve Rate |
+========+=========+===========+==============+
| aqua   |     254 |        92 |     0.362205 |
+--------+---------+-----------+--------------+
