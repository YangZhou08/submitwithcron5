Already on 'addinggriffin'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.70s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.58s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.58s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.57s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.78s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.57s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:46<01:33, 46.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.61s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.74s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.74s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.75s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:46, 46.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.82s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.21s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.16s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.15s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.18s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.21s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.14s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.15s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 37.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.14s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  3%|▎         | 1/32 [00:25<12:56, 25.06s/it]  3%|▎         | 1/32 [00:25<13:22, 25.88s/it]  3%|▎         | 1/32 [00:26<13:28, 26.07s/it]  3%|▎         | 1/32 [00:26<13:40, 26.45s/it]  3%|▎         | 1/32 [00:27<14:13, 27.53s/it]  3%|▎         | 1/32 [00:30<15:38, 30.26s/it]  3%|▎         | 1/32 [00:37<19:26, 37.62s/it]  3%|▎         | 1/32 [00:38<19:51, 38.43s/it]  6%|▋         | 2/32 [00:50<12:42, 25.42s/it]  6%|▋         | 2/32 [00:51<12:47, 25.58s/it]  6%|▋         | 2/32 [00:53<13:19, 26.65s/it]  6%|▋         | 2/32 [00:53<13:39, 27.32s/it]  6%|▋         | 2/32 [00:54<13:40, 27.36s/it]  6%|▋         | 2/32 [01:01<14:48, 29.60s/it]  6%|▋         | 2/32 [01:12<18:44, 37.49s/it]  9%|▉         | 3/32 [01:15<11:58, 24.78s/it]  9%|▉         | 3/32 [01:15<12:07, 25.08s/it]  9%|▉         | 3/32 [01:19<12:42, 26.28s/it]  9%|▉         | 3/32 [01:20<12:56, 26.79s/it]  9%|▉         | 3/32 [01:22<13:20, 27.61s/it]  6%|▋         | 2/32 [01:27<22:12, 44.41s/it]  9%|▉         | 3/32 [01:30<14:15, 29.50s/it] 12%|█▎        | 4/32 [01:40<11:39, 25.00s/it] 12%|█▎        | 4/32 [01:41<11:49, 25.34s/it] 12%|█▎        | 4/32 [01:44<12:01, 25.75s/it] 12%|█▎        | 4/32 [01:44<12:05, 25.90s/it] 12%|█▎        | 4/32 [01:47<12:23, 26.54s/it] 12%|█▎        | 4/32 [02:00<13:44, 29.46s/it]  9%|▉         | 3/32 [02:02<20:54, 43.26s/it] 16%|█▌        | 5/32 [02:05<11:11, 24.88s/it] 16%|█▌        | 5/32 [02:06<11:21, 25.24s/it] 16%|█▌        | 5/32 [02:09<11:28, 25.50s/it] 16%|█▌        | 5/32 [02:10<11:36, 25.78s/it] 16%|█▌        | 5/32 [02:11<11:33, 25.70s/it]  9%|▉         | 3/32 [02:19<23:14, 48.09s/it] 16%|█▌        | 5/32 [02:26<12:44, 28.30s/it] 19%|█▉        | 6/32 [02:30<10:44, 24.79s/it] 19%|█▉        | 6/32 [02:34<10:55, 25.21s/it] 19%|█▉        | 6/32 [02:35<11:33, 26.66s/it] 19%|█▉        | 6/32 [02:36<11:13, 25.90s/it] 19%|█▉        | 6/32 [02:37<11:13, 25.92s/it] 12%|█▎        | 4/32 [02:47<20:29, 43.92s/it] 19%|█▉        | 6/32 [02:52<11:53, 27.43s/it] 22%|██▏       | 7/32 [02:54<10:15, 24.63s/it] 22%|██▏       | 7/32 [02:58<10:24, 24.97s/it] 22%|██▏       | 7/32 [03:00<10:32, 25.30s/it] 22%|██▏       | 7/32 [03:03<10:46, 25.85s/it] 12%|█▎        | 4/32 [03:06<22:19, 47.83s/it] 22%|██▏       | 7/32 [03:09<12:02, 28.89s/it] 22%|██▏       | 7/32 [03:16<10:57, 26.29s/it] 25%|██▌       | 8/32 [03:19<09:56, 24.86s/it] 25%|██▌       | 8/32 [03:22<09:53, 24.72s/it] 25%|██▌       | 8/32 [03:24<09:56, 24.84s/it] 25%|██▌       | 8/32 [03:27<10:06, 25.29s/it] 16%|█▌        | 5/32 [03:30<19:30, 43.36s/it] 25%|██▌       | 8/32 [03:39<11:47, 29.46s/it] 25%|██▌       | 8/32 [03:40<10:14, 25.62s/it] 28%|██▊       | 9/32 [03:44<09:27, 24.66s/it] 16%|█▌        | 5/32 [03:48<20:26, 45.43s/it] 28%|██▊       | 9/32 [03:49<09:41, 25.30s/it] 28%|██▊       | 9/32 [03:50<09:46, 25.50s/it] 28%|██▊       | 9/32 [03:52<09:38, 25.16s/it] 28%|██▊       | 9/32 [04:04<09:37, 25.12s/it] 28%|██▊       | 9/32 [04:11<11:32, 30.12s/it] 31%|███▏      | 10/32 [04:14<09:43, 26.54s/it] 31%|███▏      | 10/32 [04:15<09:16, 25.30s/it] 31%|███▏      | 10/32 [04:16<09:25, 25.69s/it] 19%|█▉        | 6/32 [04:16<19:12, 44.34s/it] 31%|███▏      | 10/32 [04:20<09:36, 26.21s/it] 31%|███▏      | 10/32 [04:29<09:10, 25.03s/it] 19%|█▉        | 6/32 [04:30<19:13, 44.38s/it] 34%|███▍      | 11/32 [04:40<08:48, 25.16s/it] 34%|███▍      | 11/32 [04:40<09:14, 26.40s/it] 34%|███▍      | 11/32 [04:41<08:50, 25.27s/it] 31%|███▏      | 10/32 [04:41<11:04, 30.20s/it] 34%|███▍      | 11/32 [04:46<09:05, 25.99s/it] 34%|███▍      | 11/32 [04:55<08:50, 25.24s/it] 22%|██▏       | 7/32 [04:58<18:13, 43.73s/it] 38%|███▊      | 12/32 [05:04<08:18, 24.91s/it] 38%|███▊      | 12/32 [05:04<08:34, 25.72s/it] 38%|███▊      | 12/32 [05:08<08:36, 25.81s/it] 38%|███▊      | 12/32 [05:11<08:32, 25.63s/it] 22%|██▏       | 7/32 [05:12<18:13, 43.74s/it] 34%|███▍      | 11/32 [05:14<10:49, 30.92s/it] 38%|███▊      | 12/32 [05:19<08:17, 24.88s/it] 41%|████      | 13/32 [05:29<07:52, 24.85s/it] 41%|████      | 13/32 [05:29<08:02, 25.41s/it] 41%|████      | 13/32 [05:32<08:03, 25.44s/it] 41%|████      | 13/32 [05:37<08:10, 25.80s/it] 25%|██▌       | 8/32 [05:41<17:19, 43.31s/it] 41%|████      | 13/32 [05:44<07:53, 24.93s/it] 38%|███▊      | 12/32 [05:46<10:24, 31.21s/it] 44%|████▍     | 14/32 [05:53<07:24, 24.69s/it] 44%|████▍     | 14/32 [05:53<07:31, 25.06s/it] 25%|██▌       | 8/32 [05:57<17:38, 44.11s/it] 44%|████▍     | 14/32 [05:57<07:36, 25.34s/it] 44%|████▍     | 14/32 [06:02<07:40, 25.59s/it] 44%|████▍     | 14/32 [06:12<07:47, 26.00s/it] 47%|████▋     | 15/32 [06:17<06:56, 24.49s/it] 41%|████      | 13/32 [06:18<10:00, 31.60s/it] 47%|████▋     | 15/32 [06:20<07:11, 25.38s/it] 47%|████▋     | 15/32 [06:21<07:04, 24.95s/it] 28%|██▊       | 9/32 [06:24<16:36, 43.33s/it] 47%|████▋     | 15/32 [06:27<07:12, 25.42s/it] 47%|████▋     | 15/32 [06:41<07:36, 26.83s/it] 28%|██▊       | 9/32 [06:44<17:11, 44.83s/it] 50%|█████     | 16/32 [06:44<06:42, 25.13s/it] 50%|█████     | 16/32 [06:47<06:58, 26.14s/it] 50%|█████     | 16/32 [06:50<06:56, 26.00s/it] 44%|████▍     | 14/32 [06:51<09:37, 32.10s/it] 50%|█████     | 16/32 [06:53<06:49, 25.58s/it] 50%|█████     | 16/32 [07:05<06:56, 26.04s/it] 31%|███▏      | 10/32 [07:05<15:38, 42.65s/it] 53%|█████▎    | 17/32 [07:09<06:17, 25.19s/it] 53%|█████▎    | 17/32 [07:12<06:29, 25.97s/it] 53%|█████▎    | 17/32 [07:15<06:24, 25.63s/it] 53%|█████▎    | 17/32 [07:20<06:28, 25.87s/it] 47%|████▋     | 15/32 [07:22<08:57, 31.63s/it] 31%|███▏      | 10/32 [07:25<16:00, 43.66s/it] 53%|█████▎    | 17/32 [07:31<06:28, 25.90s/it] 56%|█████▋    | 18/32 [07:36<05:58, 25.62s/it] 56%|█████▋    | 18/32 [07:37<05:58, 25.57s/it] 56%|█████▋    | 18/32 [07:40<05:57, 25.55s/it] 56%|█████▋    | 18/32 [07:44<05:56, 25.45s/it] 34%|███▍      | 11/32 [07:47<14:46, 42.19s/it] 50%|█████     | 16/32 [07:55<08:34, 32.18s/it] 56%|█████▋    | 18/32 [07:59<06:14, 26.75s/it] 59%|█████▉    | 19/32 [08:01<05:29, 25.33s/it] 59%|█████▉    | 19/32 [08:01<05:26, 25.11s/it] 59%|█████▉    | 19/32 [08:05<05:31, 25.51s/it] 34%|███▍      | 11/32 [08:06<15:00, 42.86s/it] 59%|█████▉    | 19/32 [08:08<05:25, 25.07s/it] 59%|█████▉    | 19/32 [08:24<05:40, 26.21s/it] 62%|██████▎   | 20/32 [08:25<04:58, 24.91s/it] 62%|██████▎   | 20/32 [08:25<04:57, 24.81s/it] 53%|█████▎    | 17/32 [08:26<07:55, 31.70s/it] 62%|██████▎   | 20/32 [08:29<05:00, 25.07s/it] 62%|██████▎   | 20/32 [08:33<04:58, 24.85s/it] 38%|███▊      | 12/32 [08:35<14:43, 44.17s/it] 38%|███▊      | 12/32 [08:47<14:06, 42.31s/it] 66%|██████▌   | 21/32 [08:48<04:30, 24.58s/it] 62%|██████▎   | 20/32 [08:50<05:12, 26.02s/it] 66%|██████▌   | 21/32 [08:50<04:32, 24.76s/it] 66%|██████▌   | 21/32 [08:54<04:34, 24.92s/it] 66%|██████▌   | 21/32 [08:57<04:30, 24.63s/it] 56%|█████▋    | 18/32 [08:57<07:22, 31.57s/it] 69%|██████▉   | 22/32 [09:14<04:08, 24.81s/it] 66%|██████▌   | 21/32 [09:15<04:42, 25.69s/it] 69%|██████▉   | 22/32 [09:15<04:08, 24.81s/it] 69%|██████▉   | 22/32 [09:19<04:11, 25.11s/it] 41%|████      | 13/32 [09:20<14:03, 44.40s/it] 69%|██████▉   | 22/32 [09:21<04:05, 24.55s/it] 41%|████      | 13/32 [09:28<13:16, 41.91s/it] 59%|█████▉    | 19/32 [09:33<07:05, 32.70s/it] 72%|███████▏  | 23/32 [09:37<03:40, 24.45s/it] 69%|██████▉   | 22/32 [09:40<04:14, 25.45s/it] 72%|███████▏  | 23/32 [09:43<03:51, 25.67s/it] 72%|███████▏  | 23/32 [09:44<03:45, 25.04s/it] 72%|███████▏  | 23/32 [09:46<03:42, 24.73s/it] 75%|███████▌  | 24/32 [10:01<03:14, 24.32s/it] 62%|██████▎   | 20/32 [10:03<06:25, 32.10s/it] 44%|████▍     | 14/32 [10:04<13:15, 44.20s/it] 72%|███████▏  | 23/32 [10:06<03:49, 25.56s/it] 75%|███████▌  | 24/32 [10:07<03:21, 25.18s/it] 75%|███████▌  | 24/32 [10:09<03:19, 24.92s/it] 75%|███████▌  | 24/32 [10:10<03:16, 24.56s/it] 44%|████▍     | 14/32 [10:12<12:44, 42.50s/it] 78%|███████▊  | 25/32 [10:26<02:49, 24.26s/it] 75%|███████▌  | 24/32 [10:30<03:21, 25.20s/it] 78%|███████▊  | 25/32 [10:31<02:54, 24.89s/it] 78%|███████▊  | 25/32 [10:33<02:53, 24.74s/it] 78%|███████▊  | 25/32 [10:35<02:51, 24.53s/it] 66%|██████▌   | 21/32 [10:38<06:01, 32.86s/it] 47%|████▋     | 15/32 [10:45<12:16, 43.32s/it] 81%|████████▏ | 26/32 [10:50<02:26, 24.34s/it] 78%|███████▊  | 25/32 [10:54<02:54, 24.89s/it] 81%|████████▏ | 26/32 [10:57<02:31, 25.25s/it] 81%|████████▏ | 26/32 [10:57<02:26, 24.47s/it] 81%|████████▏ | 26/32 [10:59<02:26, 24.44s/it] 47%|████▋     | 15/32 [11:00<12:34, 44.41s/it] 69%|██████▉   | 22/32 [11:11<05:30, 33.02s/it] 84%|████████▍ | 27/32 [11:17<02:05, 25.10s/it] 81%|████████▏ | 26/32 [11:19<02:29, 24.91s/it] 84%|████████▍ | 27/32 [11:22<02:05, 25.16s/it] 84%|████████▍ | 27/32 [11:23<02:05, 25.00s/it] 84%|████████▍ | 27/32 [11:24<02:03, 24.62s/it] 50%|█████     | 16/32 [11:29<11:33, 43.36s/it] 88%|████████▊ | 28/32 [11:43<01:41, 25.34s/it] 84%|████████▍ | 27/32 [11:43<02:03, 24.66s/it] 72%|███████▏  | 23/32 [11:47<05:03, 33.70s/it] 88%|████████▊ | 28/32 [11:47<01:41, 25.32s/it] 88%|████████▊ | 28/32 [11:48<01:38, 24.74s/it] 50%|█████     | 16/32 [11:49<12:12, 45.76s/it] 88%|████████▊ | 28/32 [11:51<01:41, 25.25s/it] 94%|█████████▍| 30/32 [12:07<00:38, 19.30s/it] 88%|████████▊ | 28/32 [12:09<01:40, 25.17s/it] 53%|█████▎    | 17/32 [12:11<10:45, 43.05s/it] 91%|█████████ | 29/32 [12:12<01:13, 24.65s/it] 91%|█████████ | 29/32 [12:15<01:17, 25.92s/it] 91%|█████████ | 29/32 [12:16<01:15, 25.17s/it] 78%|███████▊  | 25/32 [12:17<02:56, 25.15s/it] 53%|█████▎    | 17/32 [12:30<11:04, 44.32s/it] 97%|█████████▋| 31/32 [12:34<00:21, 21.17s/it] 91%|█████████ | 29/32 [12:34<01:15, 25.11s/it] 94%|█████████▍| 30/32 [12:37<00:49, 24.70s/it] 94%|█████████▍| 30/32 [12:39<00:50, 25.31s/it] 94%|█████████▍| 30/32 [12:40<00:49, 24.93s/it] 81%|████████▏ | 26/32 [12:53<02:47, 27.89s/it] 56%|█████▋    | 18/32 [12:57<10:15, 43.99s/it]100%|██████████| 32/32 [12:58<00:00, 21.80s/it]100%|██████████| 32/32 [12:58<00:00, 24.32s/it]
 94%|█████████▍| 30/32 [13:00<00:50, 25.24s/it] 97%|█████████▋| 31/32 [13:01<00:24, 24.62s/it] 97%|█████████▋| 31/32 [13:03<00:25, 25.05s/it] 97%|█████████▋| 31/32 [13:07<00:25, 25.58s/it] 56%|█████▋    | 18/32 [13:13<10:12, 43.75s/it] 97%|█████████▋| 31/32 [13:25<00:25, 25.13s/it]100%|██████████| 32/32 [13:26<00:00, 24.64s/it]100%|██████████| 32/32 [13:26<00:00, 25.20s/it]
100%|██████████| 32/32 [13:27<00:00, 24.70s/it]100%|██████████| 32/32 [13:27<00:00, 25.24s/it]
100%|██████████| 32/32 [13:32<00:00, 25.37s/it]100%|██████████| 32/32 [13:32<00:00, 25.39s/it]
 84%|████████▍ | 27/32 [13:33<02:35, 31.04s/it] 59%|█████▉    | 19/32 [13:38<09:20, 43.10s/it]100%|██████████| 32/32 [13:53<00:00, 26.14s/it]100%|██████████| 32/32 [13:53<00:00, 26.06s/it]
