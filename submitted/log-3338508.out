Your branch is up to date with 'origin/addinggriffin'.
Already up to date.
Already up to date.
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
/fsx-storygen/beidic/anaconda3/envs/griffin/bin/python
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /data/home/beidic/.cache/huggingface/token
Login successful
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
NCCL_TIMEOUT 1800
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
We now use eos_token as pad token
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
is_distributed True
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device=None, limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
We now use eos_token as pad token
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
tasks ['strategyqa']
Answer no expected no
Answer no expected no
Answer no expected no
Answer yes expected yes
Answer no expected no
Skipping the batch
Answer no expected no
Answer no expected yes
Answer yes expected yes
Answer no expected yes
Answer yes expected no
Answer no expected no
Answer no expected no
Skipping the batch
Skipping the batch
Skipping the batch
Answer yes expected yes
Answer no expected yes
Answer no expected yes
Answer yes expected yes
Answer yes expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected no
Answer no expected yes
Answer no expected no
Answer no expected no
Answer no expected no
Answer yes expected yes
Answer no expected no
Answer no expected no
Skipping the batch
Answer no expected no
Answer no expected no
Skipping the batch
Answer no expected yes
Answer no expected no
Skipping the batch
Answer yes expected no
Answer yes expected yes
Answer no expected no
Answer no expected no
Answer no expected no
Answer yes expected yes
Answer yes expected yes
Answer no expected no
Answer no expected no
Answer means someone who is 40 years old. there is no such thing as a "quadragenarian" in the context of memory capacity. the answer is no, as the question is not about a person's age but about their memory capacity.

q expected no
Answer yes expected yes
Answer no expected no
Answer no expected no
Answer no expected no
Answer yes expected no
Answer  potter film grossed 1.2 billion. the first matrix film grossed 350 million. the first harry potter film was a commercial success. the first matrix film was a commercial success. the answer is yes.

q expected yes
Answer yes expected yes
Answer maybe, but it would be impractical expected yes
Answer no expected no
Answer yes expected yes
Answer no expected yes
Answer yes expected no
Answer , the author of "a christmas carol", was a christian. muslims fast during ramadan. the question is asking if the author of a christmas carol fasted during ramadan. the answer is no, as the author is not a muslim. 

q expected no
index 0 start communication
index 7 start communication
index 6 start communication
index 1 start communication
index 3 start communication
index 5 start communication
index 4 start communication
index 2 start communication
Here are the statistics for inferenceHere are the statistics for inference

Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
Here are the statistics for inference
+------------+----------------+---------------------------+-----------------------------+
| Task       |   Num Sentence |   Total Generation Length |   Average Generation Length |
+============+================+===========================+=============================+
| strategyqa |            457 |                     29002 |                     63.4617 |
+------------+----------------+---------------------------+-----------------------------+
Namespace(tasks='strategyqa', model='meta-llama/Meta-Llama-3-8B-Instruct', device='cuda:0', limit=None, griffin=False, cats=True, check=False, kernel_size=None, spr=0.4, thr=0.1, widthtree=8, patternstrict=False, shotfive=True, shottwo=False, filteractiveenabled=False)
+------------+---------+-----------+--------------+
| Task       |   Total |   Correct |   Solve Rate |
+============+=========+===========+==============+
| strategyqa |     457 |       326 |     0.713348 |
+------------+---------+-----------+--------------+
