Already on 'yangexp2threee'
From github.com:Infini-AI-Lab/GRIFFIN2
   74f6be7..42eba49  yangexp2threee -> origin/yangexp2threee
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-07-22:06:31:09,591 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:31:19,250 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:31:19,252 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:31:19,276 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:31:19,276 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 128}
2024-07-22:06:31:19,285 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:18,  6.32s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:12<00:12,  6.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:18<00:06,  6.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.92s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:31:41,866 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.17it/s] 10%|█         | 40/396 [00:00<00:01, 192.01it/s] 15%|█▌        | 60/396 [00:00<00:01, 191.95it/s] 20%|██        | 80/396 [00:00<00:01, 192.70it/s] 25%|██▌       | 100/396 [00:00<00:01, 193.30it/s] 30%|███       | 120/396 [00:00<00:01, 193.88it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.04it/s] 40%|████      | 160/396 [00:00<00:01, 194.10it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.24it/s] 51%|█████     | 200/396 [00:01<00:01, 194.31it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.30it/s] 61%|██████    | 240/396 [00:01<00:00, 194.21it/s] 66%|██████▌   | 260/396 [00:01<00:00, 194.12it/s] 71%|███████   | 280/396 [00:01<00:00, 193.99it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.99it/s] 81%|████████  | 320/396 [00:01<00:00, 193.95it/s] 86%|████████▌ | 340/396 [00:01<00:00, 193.76it/s] 91%|█████████ | 360/396 [00:01<00:00, 193.51it/s] 96%|█████████▌| 380/396 [00:01<00:00, 193.55it/s]100%|██████████| 396/396 [00:02<00:00, 193.57it/s]
2024-07-22:06:31:43,945 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:20<?, ?it/s]
2024-07-22:06:32:15,382 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:32:22,692 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:32:22,693 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:32:22,698 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:32:22,698 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 128}
2024-07-22:06:32:22,707 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.33s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.67s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:33:13,591 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 187.15it/s] 10%|▉         | 38/396 [00:00<00:01, 186.51it/s] 14%|█▍        | 57/396 [00:00<00:01, 172.34it/s] 19%|█▉        | 76/396 [00:00<00:01, 178.55it/s] 24%|██▍       | 95/396 [00:00<00:01, 182.48it/s] 29%|██▉       | 114/396 [00:00<00:01, 184.86it/s] 34%|███▎      | 133/396 [00:00<00:01, 185.93it/s] 38%|███▊      | 152/396 [00:00<00:01, 187.07it/s] 43%|████▎     | 171/396 [00:00<00:01, 187.77it/s] 48%|████▊     | 190/396 [00:01<00:01, 188.23it/s] 53%|█████▎    | 209/396 [00:01<00:00, 188.51it/s] 58%|█████▊    | 228/396 [00:01<00:00, 188.76it/s] 62%|██████▏   | 247/396 [00:01<00:00, 188.93it/s] 67%|██████▋   | 266/396 [00:01<00:00, 189.20it/s] 72%|███████▏  | 285/396 [00:01<00:00, 189.26it/s] 77%|███████▋  | 304/396 [00:01<00:00, 189.44it/s] 82%|████████▏ | 323/396 [00:01<00:00, 189.28it/s] 86%|████████▋ | 342/396 [00:01<00:00, 189.33it/s] 91%|█████████ | 361/396 [00:01<00:00, 189.45it/s] 96%|█████████▌| 380/396 [00:02<00:00, 189.40it/s]100%|██████████| 396/396 [00:02<00:00, 187.30it/s]
2024-07-22:06:33:15,715 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:17<?, ?it/s]
2024-07-22:06:33:43,933 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:33:51,159 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:33:51,160 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:33:51,165 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:33:51,165 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 256}
2024-07-22:06:33:51,174 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.28s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.52s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:34:03,367 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 188.18it/s] 10%|▉         | 38/396 [00:00<00:01, 189.00it/s] 14%|█▍        | 57/396 [00:00<00:01, 189.07it/s] 19%|█▉        | 77/396 [00:00<00:01, 189.77it/s] 24%|██▍       | 97/396 [00:00<00:01, 190.36it/s] 30%|██▉       | 117/396 [00:00<00:01, 190.56it/s] 35%|███▍      | 137/396 [00:00<00:01, 190.73it/s] 40%|███▉      | 157/396 [00:00<00:01, 190.70it/s] 45%|████▍     | 177/396 [00:00<00:01, 190.83it/s] 50%|████▉     | 197/396 [00:01<00:01, 190.87it/s] 55%|█████▍    | 217/396 [00:01<00:00, 190.90it/s] 60%|█████▉    | 237/396 [00:01<00:00, 190.88it/s] 65%|██████▍   | 257/396 [00:01<00:00, 190.80it/s] 70%|██████▉   | 277/396 [00:01<00:00, 190.89it/s] 75%|███████▌  | 297/396 [00:01<00:00, 190.85it/s] 80%|████████  | 317/396 [00:01<00:00, 190.80it/s] 85%|████████▌ | 337/396 [00:01<00:00, 190.68it/s] 90%|█████████ | 357/396 [00:01<00:00, 190.71it/s] 95%|█████████▌| 377/396 [00:01<00:00, 190.58it/s]100%|██████████| 396/396 [00:02<00:00, 190.54it/s]
2024-07-22:06:34:05,453 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:06:34:36,018 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:34:43,229 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:34:43,230 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:34:43,237 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:34:43,237 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 256}
2024-07-22:06:34:43,246 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.23s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.10s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.48s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:35:33,754 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 188.94it/s] 10%|▉         | 39/396 [00:00<00:01, 190.39it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.90it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.69it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.14it/s] 30%|███       | 119/396 [00:00<00:01, 192.52it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.80it/s] 40%|████      | 159/396 [00:00<00:01, 192.87it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.85it/s] 50%|█████     | 199/396 [00:01<00:01, 192.83it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.74it/s] 60%|██████    | 239/396 [00:01<00:00, 192.71it/s] 65%|██████▌   | 259/396 [00:01<00:00, 192.74it/s] 70%|███████   | 279/396 [00:01<00:00, 192.76it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.75it/s] 81%|████████  | 319/396 [00:01<00:00, 192.64it/s] 86%|████████▌ | 339/396 [00:01<00:00, 192.61it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.07it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.06it/s]100%|██████████| 396/396 [00:02<00:00, 192.07it/s]
2024-07-22:06:35:35,823 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:16<?, ?it/s]
2024-07-22:06:36:02,590 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:36:09,793 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:36:09,794 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:36:09,800 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:36:09,800 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 512}
2024-07-22:06:36:09,810 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.27s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.16s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.53s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:36:21,929 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.46it/s] 10%|█         | 40/396 [00:00<00:01, 192.04it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.31it/s] 20%|██        | 80/396 [00:00<00:01, 193.21it/s] 25%|██▌       | 100/396 [00:00<00:01, 193.78it/s] 30%|███       | 120/396 [00:00<00:01, 194.24it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.40it/s] 40%|████      | 160/396 [00:00<00:01, 194.39it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.35it/s] 51%|█████     | 200/396 [00:01<00:01, 194.37it/s] 56%|█████▌    | 220/396 [00:01<00:00, 193.61it/s] 61%|██████    | 240/396 [00:01<00:00, 193.71it/s] 66%|██████▌   | 260/396 [00:01<00:00, 193.78it/s] 71%|███████   | 280/396 [00:01<00:00, 193.87it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.93it/s] 81%|████████  | 320/396 [00:01<00:00, 193.92it/s] 86%|████████▌ | 340/396 [00:01<00:00, 193.76it/s] 91%|█████████ | 360/396 [00:01<00:00, 193.76it/s] 96%|█████████▌| 380/396 [00:01<00:00, 193.71it/s]100%|██████████| 396/396 [00:02<00:00, 193.73it/s]
2024-07-22:06:36:23,981 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:20<?, ?it/s]
2024-07-22:06:36:54,863 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:37:02,051 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:37:02,052 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:37:02,057 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:37:02,057 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 512}
2024-07-22:06:37:02,066 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:37:52,308 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 192.24it/s] 10%|█         | 40/396 [00:00<00:01, 193.22it/s] 15%|█▌        | 60/396 [00:00<00:01, 193.54it/s] 20%|██        | 80/396 [00:00<00:01, 194.36it/s] 25%|██▌       | 100/396 [00:00<00:01, 194.93it/s] 30%|███       | 120/396 [00:00<00:01, 195.26it/s] 35%|███▌      | 140/396 [00:00<00:01, 195.47it/s] 40%|████      | 160/396 [00:00<00:01, 195.42it/s] 45%|████▌     | 180/396 [00:00<00:01, 195.40it/s] 51%|█████     | 200/396 [00:01<00:01, 195.37it/s] 56%|█████▌    | 220/396 [00:01<00:00, 195.28it/s] 61%|██████    | 240/396 [00:01<00:00, 195.24it/s] 66%|██████▌   | 260/396 [00:01<00:00, 195.13it/s] 71%|███████   | 280/396 [00:01<00:00, 195.09it/s] 76%|███████▌  | 300/396 [00:01<00:00, 195.20it/s] 81%|████████  | 320/396 [00:01<00:00, 195.12it/s] 86%|████████▌ | 340/396 [00:01<00:00, 195.01it/s] 91%|█████████ | 360/396 [00:01<00:00, 194.89it/s] 96%|█████████▌| 380/396 [00:01<00:00, 194.77it/s]100%|██████████| 396/396 [00:02<00:00, 194.91it/s]
2024-07-22:06:37:54,348 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:16<?, ?it/s]
2024-07-22:06:38:21,727 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:38:28,940 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:38:28,941 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:38:28,947 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:38:28,947 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1024}
2024-07-22:06:38:28,955 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.22s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:38:40,843 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 188.92it/s] 10%|▉         | 39/396 [00:00<00:01, 189.59it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.01it/s] 20%|█▉        | 79/396 [00:00<00:01, 190.86it/s] 25%|██▌       | 99/396 [00:00<00:01, 188.18it/s] 30%|███       | 119/396 [00:00<00:01, 189.27it/s] 35%|███▌      | 139/396 [00:00<00:01, 189.96it/s] 40%|████      | 159/396 [00:00<00:01, 190.44it/s] 45%|████▌     | 179/396 [00:00<00:01, 190.72it/s] 50%|█████     | 199/396 [00:01<00:01, 190.95it/s] 55%|█████▌    | 219/396 [00:01<00:00, 191.14it/s] 60%|██████    | 239/396 [00:01<00:00, 191.30it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.48it/s] 70%|███████   | 279/396 [00:01<00:00, 191.58it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.68it/s] 81%|████████  | 319/396 [00:01<00:00, 191.69it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.71it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.72it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.77it/s]100%|██████████| 396/396 [00:02<00:00, 190.97it/s]
2024-07-22:06:38:42,924 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:21<?, ?it/s]
2024-07-22:06:39:14,877 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:39:22,111 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:39:22,112 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:39:22,118 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:39:22,118 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1024}
2024-07-22:06:39:22,128 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.34s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.14s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.51s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:40:12,498 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.35it/s] 10%|▉         | 39/396 [00:00<00:01, 190.60it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.09it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.94it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.54it/s] 30%|███       | 119/396 [00:00<00:01, 192.90it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.12it/s] 40%|████      | 159/396 [00:00<00:01, 193.09it/s] 45%|████▌     | 179/396 [00:00<00:01, 193.06it/s] 50%|█████     | 199/396 [00:01<00:01, 193.01it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.03it/s] 60%|██████    | 239/396 [00:01<00:00, 190.96it/s] 65%|██████▌   | 259/396 [00:01<00:00, 180.20it/s] 70%|███████   | 279/396 [00:01<00:00, 183.11it/s] 76%|███████▌  | 299/396 [00:01<00:00, 185.78it/s] 81%|████████  | 319/396 [00:01<00:00, 187.14it/s] 86%|████████▌ | 339/396 [00:01<00:00, 188.46it/s] 91%|█████████ | 359/396 [00:01<00:00, 189.48it/s] 96%|█████████▌| 379/396 [00:01<00:00, 190.20it/s]100%|██████████| 396/396 [00:02<00:00, 189.86it/s]
2024-07-22:06:40:14,591 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:17<?, ?it/s]
2024-07-22:06:40:43,196 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:40:50,509 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:40:50,510 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:40:50,515 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:40:50,516 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1536}
2024-07-22:06:40:50,525 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.50s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.66s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.14s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:41:05,251 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 188.28it/s] 10%|▉         | 39/396 [00:00<00:01, 189.55it/s] 15%|█▍        | 59/396 [00:00<00:01, 189.78it/s] 20%|█▉        | 79/396 [00:00<00:01, 190.73it/s] 25%|██▌       | 99/396 [00:00<00:01, 191.26it/s] 30%|███       | 119/396 [00:00<00:01, 191.74it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.00it/s] 40%|████      | 159/396 [00:00<00:01, 191.93it/s] 45%|████▌     | 179/396 [00:00<00:01, 191.99it/s] 50%|█████     | 199/396 [00:01<00:01, 191.81it/s] 55%|█████▌    | 219/396 [00:01<00:00, 191.84it/s] 60%|██████    | 239/396 [00:01<00:00, 191.05it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.15it/s] 70%|███████   | 279/396 [00:01<00:00, 191.28it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.40it/s] 81%|████████  | 319/396 [00:01<00:00, 191.51it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.41it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.41it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.34it/s]100%|██████████| 396/396 [00:02<00:00, 191.29it/s]
2024-07-22:06:41:07,331 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:23<?, ?it/s]
2024-07-22:06:41:41,840 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:41:49,046 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:41:49,047 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:41:49,053 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:41:49,053 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1536}
2024-07-22:06:41:49,061 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.17s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.56s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:42:40,012 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.60it/s] 10%|█         | 40/396 [00:00<00:01, 192.54it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.98it/s] 20%|██        | 80/396 [00:00<00:01, 193.65it/s] 25%|██▌       | 100/396 [00:00<00:01, 194.09it/s] 30%|███       | 120/396 [00:00<00:01, 194.38it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.48it/s] 40%|████      | 160/396 [00:00<00:01, 194.42it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.51it/s] 51%|█████     | 200/396 [00:01<00:01, 194.59it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.62it/s] 61%|██████    | 240/396 [00:01<00:00, 194.59it/s] 66%|██████▌   | 260/396 [00:01<00:00, 194.51it/s] 71%|███████   | 280/396 [00:01<00:00, 194.58it/s] 76%|███████▌  | 300/396 [00:01<00:00, 194.63it/s] 81%|████████  | 320/396 [00:01<00:00, 194.61it/s] 86%|████████▌ | 340/396 [00:01<00:00, 194.44it/s] 91%|█████████ | 360/396 [00:01<00:00, 194.37it/s] 96%|█████████▌| 380/396 [00:01<00:00, 194.20it/s]100%|██████████| 396/396 [00:02<00:00, 194.24it/s]
2024-07-22:06:42:42,059 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:06:43:11,863 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:43:19,046 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:43:19,047 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:43:19,053 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:43:19,053 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 2048}
2024-07-22:06:43:19,061 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.30s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.51s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:43:31,146 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 188.53it/s] 10%|▉         | 38/396 [00:00<00:01, 188.56it/s] 15%|█▍        | 58/396 [00:00<00:01, 189.30it/s] 20%|█▉        | 78/396 [00:00<00:01, 190.18it/s] 25%|██▍       | 98/396 [00:00<00:01, 190.12it/s] 30%|██▉       | 118/396 [00:00<00:01, 187.77it/s] 35%|███▍      | 138/396 [00:00<00:01, 188.66it/s] 40%|███▉      | 157/396 [00:00<00:01, 189.05it/s] 45%|████▍     | 177/396 [00:00<00:01, 189.47it/s] 50%|████▉     | 197/396 [00:01<00:01, 189.74it/s] 55%|█████▍    | 217/396 [00:01<00:00, 189.85it/s] 60%|█████▉    | 237/396 [00:01<00:00, 189.99it/s] 65%|██████▍   | 257/396 [00:01<00:00, 190.16it/s] 70%|██████▉   | 277/396 [00:01<00:00, 190.33it/s] 75%|███████▌  | 297/396 [00:01<00:00, 190.38it/s] 80%|████████  | 317/396 [00:01<00:00, 190.43it/s] 85%|████████▌ | 337/396 [00:01<00:00, 190.52it/s] 90%|█████████ | 357/396 [00:01<00:00, 190.71it/s] 95%|█████████▌| 377/396 [00:01<00:00, 190.69it/s]100%|██████████| 396/396 [00:02<00:00, 189.94it/s]
2024-07-22:06:43:33,239 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:24<?, ?it/s]
2024-07-22:06:44:08,167 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:44:15,448 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:44:15,449 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:44:15,455 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:44:15,455 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 2048}
2024-07-22:06:44:15,463 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.33s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.15s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.52s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:45:05,866 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.64it/s] 10%|▉         | 39/396 [00:00<00:01, 190.80it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.04it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.88it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.50it/s] 30%|███       | 119/396 [00:00<00:01, 192.81it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.06it/s] 40%|████      | 159/396 [00:00<00:01, 193.23it/s] 45%|████▌     | 179/396 [00:00<00:01, 193.23it/s] 50%|█████     | 199/396 [00:01<00:01, 193.23it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.31it/s] 60%|██████    | 239/396 [00:01<00:00, 186.94it/s] 65%|██████▌   | 259/396 [00:01<00:00, 188.43it/s] 70%|███████   | 279/396 [00:01<00:00, 189.07it/s] 76%|███████▌  | 299/396 [00:01<00:00, 190.16it/s] 81%|████████  | 319/396 [00:01<00:00, 190.98it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.46it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.76it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.93it/s]100%|██████████| 396/396 [00:02<00:00, 191.46it/s]
2024-07-22:06:45:07,942 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:20<?, ?it/s]
2024-07-22:06:45:39,316 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:45:46,498 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:45:46,499 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:45:46,505 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:45:46,505 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 3072}
2024-07-22:06:45:46,513 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.07s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.47s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:45:58,556 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 18/396 [00:00<00:02, 179.51it/s] 10%|▉         | 38/396 [00:00<00:01, 186.82it/s] 15%|█▍        | 58/396 [00:00<00:01, 188.96it/s] 20%|█▉        | 78/396 [00:00<00:01, 190.27it/s] 25%|██▍       | 98/396 [00:00<00:01, 191.13it/s] 30%|██▉       | 118/396 [00:00<00:01, 191.78it/s] 35%|███▍      | 138/396 [00:00<00:01, 191.14it/s] 40%|███▉      | 158/396 [00:00<00:01, 190.96it/s] 45%|████▍     | 178/396 [00:00<00:01, 191.34it/s] 50%|█████     | 198/396 [00:01<00:01, 191.42it/s] 55%|█████▌    | 218/396 [00:01<00:00, 191.58it/s] 60%|██████    | 238/396 [00:01<00:00, 191.54it/s] 65%|██████▌   | 258/396 [00:01<00:00, 191.54it/s] 70%|███████   | 278/396 [00:01<00:00, 191.16it/s] 75%|███████▌  | 298/396 [00:01<00:00, 191.22it/s] 80%|████████  | 318/396 [00:01<00:00, 191.28it/s] 85%|████████▌ | 338/396 [00:01<00:00, 188.74it/s] 90%|█████████ | 358/396 [00:01<00:00, 189.08it/s] 95%|█████████▌| 378/396 [00:01<00:00, 189.38it/s]100%|██████████| 396/396 [00:02<00:00, 190.22it/s]
2024-07-22:06:46:00,648 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:28<?, ?it/s]
2024-07-22:06:46:39,480 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:46:46,779 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:46:46,780 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:46:46,785 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:46:46,785 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 3072}
2024-07-22:06:46:46,794 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.34s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.15s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.52s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:47:37,500 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 186.35it/s] 10%|▉         | 38/396 [00:00<00:01, 187.75it/s] 14%|█▍        | 57/396 [00:00<00:01, 187.99it/s] 19%|█▉        | 76/396 [00:00<00:01, 188.57it/s] 24%|██▍       | 96/396 [00:00<00:01, 189.23it/s] 29%|██▉       | 116/396 [00:00<00:01, 189.48it/s] 34%|███▍      | 135/396 [00:00<00:01, 189.61it/s] 39%|███▉      | 154/396 [00:00<00:01, 189.15it/s] 44%|████▎     | 173/396 [00:00<00:01, 189.24it/s] 48%|████▊     | 192/396 [00:01<00:01, 189.27it/s] 53%|█████▎    | 211/396 [00:01<00:00, 189.24it/s] 58%|█████▊    | 230/396 [00:01<00:00, 189.31it/s] 63%|██████▎   | 249/396 [00:01<00:00, 189.18it/s] 68%|██████▊   | 268/396 [00:01<00:00, 189.14it/s] 72%|███████▏  | 287/396 [00:01<00:00, 189.19it/s] 77%|███████▋  | 306/396 [00:01<00:00, 189.23it/s] 82%|████████▏ | 325/396 [00:01<00:00, 189.16it/s] 87%|████████▋ | 344/396 [00:01<00:00, 188.75it/s] 92%|█████████▏| 363/396 [00:01<00:00, 186.92it/s] 96%|█████████▋| 382/396 [00:02<00:00, 187.11it/s]100%|██████████| 396/396 [00:02<00:00, 188.58it/s]
2024-07-22:06:47:39,610 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:24<?, ?it/s]
2024-07-22:06:48:14,478 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:48:21,726 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:48:21,727 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:48:21,733 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:48:21,733 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 4096}
2024-07-22:06:48:21,741 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.23s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.12s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.50s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:48:33,694 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.06it/s] 10%|█         | 40/396 [00:00<00:01, 191.71it/s] 15%|█▌        | 60/396 [00:00<00:01, 191.97it/s] 20%|██        | 80/396 [00:00<00:01, 189.66it/s] 25%|██▌       | 100/396 [00:00<00:01, 190.72it/s] 30%|███       | 120/396 [00:00<00:01, 191.54it/s] 35%|███▌      | 140/396 [00:00<00:01, 192.01it/s] 40%|████      | 160/396 [00:00<00:01, 192.35it/s] 45%|████▌     | 180/396 [00:00<00:01, 192.54it/s] 51%|█████     | 200/396 [00:01<00:01, 192.72it/s] 56%|█████▌    | 220/396 [00:01<00:00, 192.84it/s] 61%|██████    | 240/396 [00:01<00:00, 192.88it/s] 66%|██████▌   | 260/396 [00:01<00:00, 192.88it/s] 71%|███████   | 280/396 [00:01<00:00, 192.92it/s] 76%|███████▌  | 300/396 [00:01<00:00, 192.95it/s] 81%|████████  | 320/396 [00:01<00:00, 192.90it/s] 86%|████████▌ | 340/396 [00:01<00:00, 192.90it/s] 91%|█████████ | 360/396 [00:01<00:00, 192.94it/s] 96%|█████████▌| 380/396 [00:01<00:00, 192.83it/s]100%|██████████| 396/396 [00:02<00:00, 192.43it/s]
2024-07-22:06:48:35,759 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:29<?, ?it/s]
2024-07-22:06:49:16,015 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:06:49:23,206 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:06:49:23,207 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:06:49:23,213 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:06:49:23,213 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 4096}
2024-07-22:06:49:23,222 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.30s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.17s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.52s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:06:50:13,533 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 187.78it/s] 10%|▉         | 38/396 [00:00<00:01, 188.36it/s] 14%|█▍        | 57/396 [00:00<00:01, 180.93it/s] 19%|█▉        | 76/396 [00:00<00:01, 175.79it/s] 24%|██▍       | 96/396 [00:00<00:01, 181.35it/s] 29%|██▉       | 116/396 [00:00<00:01, 184.77it/s] 34%|███▍      | 136/396 [00:00<00:01, 187.04it/s] 39%|███▉      | 156/396 [00:00<00:01, 188.36it/s] 44%|████▍     | 176/396 [00:00<00:01, 189.22it/s] 49%|████▉     | 196/396 [00:01<00:01, 189.59it/s] 54%|█████▍    | 215/396 [00:01<00:00, 189.44it/s] 59%|█████▉    | 234/396 [00:01<00:00, 187.78it/s] 64%|██████▍   | 253/396 [00:01<00:00, 188.09it/s] 69%|██████▊   | 272/396 [00:01<00:00, 188.35it/s] 74%|███████▎  | 292/396 [00:01<00:00, 188.89it/s] 79%|███████▉  | 312/396 [00:01<00:00, 189.35it/s] 84%|████████▍ | 332/396 [00:01<00:00, 189.64it/s] 89%|████████▊ | 351/396 [00:01<00:00, 189.45it/s] 94%|█████████▎| 371/396 [00:01<00:00, 189.71it/s] 99%|█████████▊| 391/396 [00:02<00:00, 189.92it/s]100%|██████████| 396/396 [00:02<00:00, 187.73it/s]
2024-07-22:06:50:15,651 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:28<?, ?it/s]
