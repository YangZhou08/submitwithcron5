wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.82s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:01<01:01, 61.07s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.98s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.99s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:01<01:01, 61.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 61.00s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.92s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 31.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.62s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 31.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.77s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 31.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.73s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 31.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.73s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 31.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.77s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 31.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.74s/it]
  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 33.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.79s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 33.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.70s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [00:38<12:46, 38.34s/it]  5%|▍         | 1/21 [00:38<12:42, 38.11s/it]  5%|▍         | 1/21 [00:38<12:43, 38.19s/it]  5%|▍         | 1/21 [00:39<13:00, 39.02s/it]  5%|▍         | 1/21 [00:38<12:57, 38.88s/it]  5%|▍         | 1/21 [00:38<12:44, 38.22s/it]  5%|▍         | 1/21 [00:34<11:30, 34.53s/it]  5%|▍         | 1/21 [00:34<11:23, 34.16s/it] 10%|▉         | 2/21 [00:54<07:56, 25.07s/it] 10%|▉         | 2/21 [00:54<07:58, 25.16s/it] 10%|▉         | 2/21 [00:54<08:03, 25.44s/it] 10%|▉         | 2/21 [00:54<07:56, 25.10s/it] 10%|▉         | 2/21 [00:54<08:02, 25.39s/it] 10%|▉         | 2/21 [00:54<07:57, 25.11s/it] 10%|▉         | 2/21 [00:50<07:28, 23.60s/it] 10%|▉         | 2/21 [00:50<07:25, 23.44s/it] 14%|█▍        | 3/21 [01:04<05:30, 18.36s/it] 14%|█▍        | 3/21 [01:03<05:26, 18.16s/it] 14%|█▍        | 3/21 [01:04<05:27, 18.21s/it] 14%|█▍        | 3/21 [01:04<05:27, 18.18s/it] 14%|█▍        | 3/21 [01:04<05:27, 18.18s/it] 14%|█▍        | 3/21 [01:00<05:12, 17.36s/it] 14%|█▍        | 3/21 [01:04<05:29, 18.33s/it] 14%|█▍        | 3/21 [01:00<05:10, 17.27s/it] 19%|█▉        | 4/21 [01:06<03:22, 11.93s/it] 19%|█▉        | 4/21 [01:07<03:24, 12.02s/it] 19%|█▉        | 4/21 [01:06<03:22, 11.91s/it] 19%|█▉        | 4/21 [01:07<03:23, 12.00s/it] 19%|█▉        | 4/21 [01:06<03:22, 11.91s/it] 19%|█▉        | 4/21 [01:06<03:22, 11.90s/it] 19%|█▉        | 4/21 [01:02<03:13, 11.41s/it] 19%|█▉        | 4/21 [01:02<03:13, 11.36s/it] 24%|██▍       | 5/21 [01:11<02:28,  9.30s/it] 24%|██▍       | 5/21 [01:10<02:27,  9.24s/it] 24%|██▍       | 5/21 [01:10<02:27,  9.22s/it] 24%|██▍       | 5/21 [01:11<02:28,  9.29s/it] 24%|██▍       | 5/21 [01:10<02:27,  9.23s/it] 24%|██▍       | 5/21 [01:06<02:22,  8.88s/it] 24%|██▍       | 5/21 [01:10<02:27,  9.23s/it] 24%|██▍       | 5/21 [01:07<02:22,  8.91s/it] 29%|██▊       | 6/21 [01:15<01:54,  7.61s/it] 29%|██▊       | 6/21 [01:15<01:53,  7.60s/it] 29%|██▊       | 6/21 [01:11<01:50,  7.35s/it] 29%|██▊       | 6/21 [01:15<01:53,  7.55s/it] 29%|██▊       | 6/21 [01:15<01:53,  7.57s/it] 29%|██▊       | 6/21 [01:11<01:49,  7.33s/it] 29%|██▊       | 6/21 [01:15<01:53,  7.56s/it] 29%|██▊       | 6/21 [01:15<01:53,  7.56s/it] 33%|███▎      | 7/21 [01:23<01:49,  7.84s/it] 33%|███▎      | 7/21 [01:24<01:50,  7.88s/it] 33%|███▎      | 7/21 [01:23<01:49,  7.85s/it] 33%|███▎      | 7/21 [01:23<01:49,  7.85s/it] 33%|███▎      | 7/21 [01:23<01:49,  7.85s/it] 33%|███▎      | 7/21 [01:24<01:50,  7.87s/it] 33%|███▎      | 7/21 [01:19<01:47,  7.71s/it] 33%|███▎      | 7/21 [01:19<01:47,  7.69s/it] 38%|███▊      | 8/21 [01:25<01:18,  6.05s/it] 38%|███▊      | 8/21 [01:26<01:18,  6.07s/it] 38%|███▊      | 8/21 [01:25<01:18,  6.05s/it] 38%|███▊      | 8/21 [01:26<01:18,  6.07s/it] 38%|███▊      | 8/21 [01:25<01:18,  6.05s/it] 38%|███▊      | 8/21 [01:25<01:18,  6.05s/it] 38%|███▊      | 8/21 [01:21<01:17,  5.94s/it] 38%|███▊      | 8/21 [01:22<01:17,  5.95s/it] 43%|████▎     | 9/21 [01:30<01:08,  5.70s/it] 43%|████▎     | 9/21 [01:31<01:08,  5.72s/it] 43%|████▎     | 9/21 [01:31<01:08,  5.72s/it] 43%|████▎     | 9/21 [01:30<01:08,  5.71s/it] 43%|████▎     | 9/21 [01:26<01:07,  5.63s/it] 43%|████▎     | 9/21 [01:27<01:07,  5.64s/it] 43%|████▎     | 9/21 [01:30<01:08,  5.70s/it] 43%|████▎     | 9/21 [01:30<01:08,  5.70s/it] 48%|████▊     | 10/21 [01:48<01:44,  9.46s/it] 48%|████▊     | 10/21 [01:48<01:44,  9.46s/it] 48%|████▊     | 10/21 [01:49<01:44,  9.47s/it] 48%|████▊     | 10/21 [01:48<01:44,  9.46s/it] 48%|████▊     | 10/21 [01:48<01:44,  9.46s/it] 48%|████▊     | 10/21 [01:44<01:43,  9.41s/it] 48%|████▊     | 10/21 [01:49<01:44,  9.47s/it] 48%|████▊     | 10/21 [01:44<01:43,  9.41s/it] 52%|█████▏    | 11/21 [01:51<01:12,  7.26s/it] 52%|█████▏    | 11/21 [01:50<01:12,  7.26s/it] 52%|█████▏    | 11/21 [01:51<01:12,  7.26s/it] 52%|█████▏    | 11/21 [01:51<01:12,  7.26s/it] 52%|█████▏    | 11/21 [01:50<01:12,  7.26s/it] 52%|█████▏    | 11/21 [01:50<01:12,  7.26s/it] 52%|█████▏    | 11/21 [01:46<01:12,  7.22s/it] 52%|█████▏    | 11/21 [01:47<01:12,  7.22s/it] 57%|█████▋    | 12/21 [01:57<01:02,  6.91s/it] 57%|█████▋    | 12/21 [01:57<01:02,  6.90s/it] 57%|█████▋    | 12/21 [01:57<01:02,  6.90s/it] 57%|█████▋    | 12/21 [01:53<01:01,  6.88s/it] 57%|█████▋    | 12/21 [01:52<01:01,  6.88s/it] 57%|█████▋    | 12/21 [01:56<01:02,  6.90s/it] 57%|█████▋    | 12/21 [01:56<01:02,  6.90s/it] 57%|█████▋    | 12/21 [01:56<01:02,  6.90s/it] 62%|██████▏   | 13/21 [01:58<00:42,  5.34s/it] 62%|██████▏   | 13/21 [01:58<00:42,  5.33s/it] 62%|██████▏   | 13/21 [01:59<00:42,  5.34s/it] 62%|██████▏   | 13/21 [01:59<00:42,  5.34s/it] 62%|██████▏   | 13/21 [01:58<00:42,  5.33s/it] 62%|██████▏   | 13/21 [01:58<00:42,  5.33s/it] 62%|██████▏   | 13/21 [01:55<00:42,  5.32s/it] 62%|██████▏   | 13/21 [01:54<00:42,  5.32s/it] 67%|██████▋   | 14/21 [02:01<00:30,  4.43s/it] 67%|██████▋   | 14/21 [02:01<00:30,  4.43s/it] 67%|██████▋   | 14/21 [02:00<00:30,  4.43s/it] 67%|██████▋   | 14/21 [02:01<00:30,  4.43s/it] 67%|██████▋   | 14/21 [01:56<00:30,  4.41s/it] 67%|██████▋   | 14/21 [02:01<00:30,  4.43s/it] 67%|██████▋   | 14/21 [02:01<00:30,  4.43s/it] 67%|██████▋   | 14/21 [01:57<00:30,  4.41s/it] 71%|███████▏  | 15/21 [02:19<00:52,  8.79s/it] 71%|███████▏  | 15/21 [02:19<00:52,  8.79s/it] 71%|███████▏  | 15/21 [02:20<00:52,  8.80s/it] 71%|███████▏  | 15/21 [02:20<00:52,  8.79s/it] 71%|███████▏  | 15/21 [02:15<00:52,  8.79s/it] 71%|███████▏  | 15/21 [02:19<00:52,  8.79s/it] 71%|███████▏  | 15/21 [02:20<00:52,  8.80s/it] 71%|███████▏  | 15/21 [02:16<00:52,  8.79s/it] 76%|███████▌  | 16/21 [02:37<00:55, 11.13s/it] 76%|███████▌  | 16/21 [02:36<00:55, 11.13s/it] 76%|███████▌  | 16/21 [02:36<00:55, 11.13s/it] 76%|███████▌  | 16/21 [02:36<00:55, 11.13s/it] 76%|███████▌  | 16/21 [02:36<00:55, 11.13s/it] 76%|███████▌  | 16/21 [02:37<00:55, 11.13s/it] 76%|███████▌  | 16/21 [02:32<00:55, 11.13s/it] 76%|███████▌  | 16/21 [02:32<00:55, 11.13s/it] 81%|████████  | 17/21 [02:48<00:44, 11.18s/it] 81%|████████  | 17/21 [02:47<00:44, 11.18s/it] 81%|████████  | 17/21 [02:47<00:44, 11.18s/it] 81%|████████  | 17/21 [02:47<00:44, 11.18s/it] 81%|████████  | 17/21 [02:48<00:44, 11.18s/it] 81%|████████  | 17/21 [02:43<00:44, 11.17s/it] 81%|████████  | 17/21 [02:44<00:44, 11.17s/it] 81%|████████  | 17/21 [02:47<00:44, 11.18s/it] 86%|████████▌ | 18/21 [02:54<00:28,  9.50s/it] 86%|████████▌ | 18/21 [02:53<00:28,  9.49s/it] 86%|████████▌ | 18/21 [02:53<00:28,  9.49s/it] 86%|████████▌ | 18/21 [02:53<00:28,  9.49s/it] 86%|████████▌ | 18/21 [02:49<00:28,  9.49s/it] 86%|████████▌ | 18/21 [02:49<00:28,  9.49s/it] 86%|████████▌ | 18/21 [02:54<00:28,  9.49s/it] 86%|████████▌ | 18/21 [02:53<00:28,  9.49s/it] 90%|█████████ | 19/21 [03:08<00:22, 11.31s/it] 90%|█████████ | 19/21 [03:08<00:22, 11.31s/it] 90%|█████████ | 19/21 [03:09<00:22, 11.31s/it] 90%|█████████ | 19/21 [03:09<00:22, 11.31s/it] 90%|█████████ | 19/21 [03:05<00:22, 11.31s/it] 90%|█████████ | 19/21 [03:08<00:22, 11.31s/it] 90%|█████████ | 19/21 [03:09<00:22, 11.31s/it] 90%|█████████ | 19/21 [03:04<00:22, 11.31s/it] 95%|█████████▌| 20/21 [03:26<00:12, 12.92s/it] 95%|█████████▌| 20/21 [03:25<00:12, 12.92s/it] 95%|█████████▌| 20/21 [03:21<00:12, 12.92s/it] 95%|█████████▌| 20/21 [03:25<00:12, 12.92s/it] 95%|█████████▌| 20/21 [03:26<00:12, 12.92s/it] 95%|█████████▌| 20/21 [03:25<00:12, 12.92s/it] 95%|█████████▌| 20/21 [03:21<00:12, 12.92s/it] 95%|█████████▌| 20/21 [03:25<00:12, 12.92s/it]100%|██████████| 21/21 [03:43<00:00, 14.36s/it]100%|██████████| 21/21 [03:43<00:00, 14.36s/it]100%|██████████| 21/21 [03:44<00:00, 14.36s/it]100%|██████████| 21/21 [03:43<00:00, 14.36s/it]100%|██████████| 21/21 [03:43<00:00, 14.36s/it]100%|██████████| 21/21 [03:39<00:00, 14.36s/it]100%|██████████| 21/21 [03:43<00:00, 14.36s/it]100%|██████████| 21/21 [03:39<00:00, 14.36s/it]22it [03:55, 13.53s/it]                        22it [03:54, 13.53s/it]                        22it [03:55, 13.53s/it]                        22it [03:55, 13.53s/it]                        22it [03:54, 13.53s/it]                        22it [03:54, 13.53s/it]                        22it [03:50, 13.53s/it]                        22it [03:51, 13.53s/it]                        23it [04:11, 14.47s/it]23it [04:12, 14.47s/it]23it [04:07, 14.47s/it]23it [04:11, 14.47s/it]23it [04:07, 14.47s/it]23it [04:11, 14.47s/it]23it [04:11, 14.47s/it]23it [04:12, 14.47s/it]24it [04:19, 12.40s/it]24it [04:19, 12.40s/it]24it [04:19, 12.40s/it]24it [04:15, 12.40s/it]24it [04:19, 12.40s/it]24it [04:19, 12.40s/it]24it [04:19, 12.40s/it]24it [04:15, 12.40s/it]25it [04:40, 15.11s/it]25it [04:40, 15.11s/it]25it [04:40, 15.11s/it]25it [04:41, 15.11s/it]25it [04:36, 15.11s/it]25it [04:40, 15.11s/it]25it [04:41, 15.11s/it]25it [04:36, 15.11s/it]26it [04:55, 14.98s/it]26it [04:55, 14.98s/it]26it [04:55, 14.98s/it]26it [04:51, 14.98s/it]26it [04:55, 14.98s/it]26it [04:56, 14.98s/it]26it [04:55, 14.98s/it]26it [04:51, 14.98s/it]27it [05:00, 11.89s/it]27it [04:59, 11.89s/it]27it [04:59, 11.89s/it]27it [05:00, 11.89s/it]27it [04:55, 11.89s/it]27it [04:56, 11.89s/it]27it [04:59, 11.89s/it]27it [05:00, 11.89s/it]28it [05:17, 13.45s/it]28it [05:17, 13.45s/it]28it [05:13, 13.45s/it]28it [05:17, 13.45s/it]28it [05:16, 13.45s/it]28it [05:16, 13.45s/it]28it [05:12, 13.45s/it]28it [05:17, 13.45s/it]29it [05:34, 14.63s/it]29it [05:34, 14.63s/it]29it [05:34, 14.63s/it]29it [05:35, 14.63s/it]29it [05:34, 14.63s/it]29it [05:35, 14.63s/it]29it [05:30, 14.63s/it]29it [05:30, 14.63s/it]30it [05:45, 13.71s/it]30it [05:46, 13.71s/it]30it [05:46, 13.71s/it]30it [05:45, 13.71s/it]30it [05:42, 13.71s/it]30it [05:46, 13.71s/it]30it [05:45, 13.71s/it]30it [05:41, 13.71s/it]31it [05:50, 10.72s/it]31it [05:50, 10.72s/it]31it [05:49, 10.72s/it]31it [05:49, 10.72s/it]31it [05:49, 10.72s/it]31it [05:45, 10.72s/it]31it [05:46, 10.72s/it]31it [05:49, 10.72s/it]32it [06:01, 10.68s/it]32it [06:00, 10.68s/it]32it [06:00, 10.68s/it]32it [05:56, 10.68s/it]32it [06:00, 10.68s/it]32it [06:00, 10.68s/it]32it [05:56, 10.68s/it]32it [06:00, 10.68s/it]33it [06:06,  9.38s/it]33it [06:06,  9.38s/it]33it [06:06,  9.38s/it]33it [06:07,  9.38s/it]33it [06:06,  9.38s/it]33it [06:02,  9.38s/it]33it [06:07,  9.38s/it]33it [06:02,  9.38s/it]34it [06:10,  7.51s/it]34it [06:09,  7.51s/it]34it [06:10,  7.51s/it]34it [06:09,  7.51s/it]34it [06:09,  7.51s/it]34it [06:09,  7.51s/it]34it [06:05,  7.51s/it]34it [06:06,  7.51s/it]35it [06:16,  7.11s/it]35it [06:15,  7.11s/it]35it [06:15,  7.11s/it]35it [06:15,  7.11s/it]35it [06:16,  7.11s/it]35it [06:12,  7.11s/it]35it [06:11,  7.11s/it]35it [06:16,  7.11s/it]36it [06:28,  8.69s/it]36it [06:28,  8.69s/it]36it [06:29,  8.69s/it]36it [06:28,  8.69s/it]36it [06:28,  8.69s/it]36it [06:29,  8.69s/it]36it [06:24,  8.69s/it]36it [06:24,  8.69s/it]37it [06:44, 10.83s/it]37it [06:44, 10.83s/it]37it [06:44, 10.83s/it]37it [06:44, 10.83s/it]37it [06:40, 10.83s/it]37it [06:44, 10.83s/it]37it [06:44, 10.83s/it]37it [06:40, 10.83s/it]38it [06:53, 10.19s/it]38it [06:52, 10.19s/it]38it [06:53, 10.19s/it]38it [06:52, 10.19s/it]38it [06:48, 10.19s/it]38it [06:49, 10.19s/it]38it [06:52, 10.19s/it]38it [06:52, 10.19s/it]39it [07:02, 10.10s/it]39it [07:02, 10.10s/it]39it [07:03, 10.10s/it]39it [07:02, 10.10s/it]39it [06:59, 10.10s/it]39it [06:58, 10.10s/it]39it [07:03, 10.10s/it]39it [07:02, 10.10s/it]40it [07:06,  8.03s/it]40it [07:06,  8.03s/it]40it [07:05,  8.03s/it]40it [07:05,  8.03s/it]40it [07:05,  8.03s/it]40it [07:02,  8.03s/it]40it [07:01,  8.03s/it]40it [07:06,  8.03s/it]41it [07:22, 10.69s/it]41it [07:23, 10.69s/it]41it [07:22, 10.69s/it]41it [07:22, 10.69s/it]41it [07:18, 10.69s/it]41it [07:22, 10.69s/it]41it [07:23, 10.69s/it]41it [07:22, 10.80s/it]
41it [07:19, 10.69s/it]41it [07:23, 10.82s/it]41it [07:22, 10.80s/it]

41it [07:22, 10.80s/it]
41it [07:18, 10.70s/it]41it [07:22, 10.80s/it]

41it [07:23, 10.82s/it]
41it [07:19, 10.71s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
