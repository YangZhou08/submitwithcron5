Already on 'yangexp2threee'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-07-22:08:01:03,372 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:01:12,787 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:01:12,788 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:01:12,812 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:01:12,812 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 128}
2024-07-22:08:01:12,821 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.77s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:19<00:06,  6.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  4.53s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.27s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:01:36,520 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.78it/s] 10%|█         | 40/396 [00:00<00:01, 192.64it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.79it/s] 20%|██        | 80/396 [00:00<00:01, 193.40it/s] 25%|██▌       | 100/396 [00:00<00:01, 193.80it/s] 30%|███       | 120/396 [00:00<00:01, 194.12it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.21it/s] 40%|████      | 160/396 [00:00<00:01, 194.21it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.18it/s] 51%|█████     | 200/396 [00:01<00:01, 194.18it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.18it/s] 61%|██████    | 240/396 [00:01<00:00, 194.12it/s] 66%|██████▌   | 260/396 [00:01<00:00, 193.99it/s] 71%|███████   | 280/396 [00:01<00:00, 193.94it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.99it/s] 81%|████████  | 320/396 [00:01<00:00, 193.88it/s] 86%|████████▌ | 340/396 [00:01<00:00, 193.81it/s] 91%|█████████ | 360/396 [00:01<00:00, 193.72it/s] 96%|█████████▌| 380/396 [00:01<00:00, 193.11it/s]100%|██████████| 396/396 [00:02<00:00, 193.69it/s]
2024-07-22:08:01:38,585 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:20<?, ?it/s]
2024-07-22:08:02:09,079 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:02:16,325 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:02:16,326 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:02:16,333 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:02:16,333 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 128}
2024-07-22:08:02:16,341 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.98s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.93s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.10s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:03:13,148 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 188.79it/s] 10%|▉         | 39/396 [00:00<00:01, 190.37it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.82it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.59it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.11it/s] 30%|███       | 119/396 [00:00<00:01, 192.54it/s] 35%|███▌      | 139/396 [00:00<00:01, 131.42it/s] 40%|███▉      | 158/396 [00:00<00:01, 143.52it/s] 45%|████▍     | 178/396 [00:01<00:01, 156.11it/s] 50%|█████     | 198/396 [00:01<00:01, 165.90it/s] 55%|█████▌    | 218/396 [00:01<00:01, 173.43it/s] 60%|██████    | 238/396 [00:01<00:00, 178.85it/s] 65%|██████▌   | 258/396 [00:01<00:00, 182.81it/s] 70%|███████   | 278/396 [00:01<00:00, 185.69it/s] 75%|███████▌  | 298/396 [00:01<00:00, 187.70it/s] 80%|████████  | 318/396 [00:01<00:00, 189.13it/s] 85%|████████▌ | 338/396 [00:01<00:00, 189.99it/s] 90%|█████████ | 358/396 [00:02<00:00, 190.60it/s] 95%|█████████▌| 378/396 [00:02<00:00, 188.40it/s]100%|██████████| 396/396 [00:02<00:00, 178.44it/s]
2024-07-22:08:03:15,376 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:08:03:41,033 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:03:48,296 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:03:48,297 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:03:48,303 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:03:48,303 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 256}
2024-07-22:08:03:48,311 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.43s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.69s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:04:05,401 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.48it/s] 10%|█         | 40/396 [00:00<00:01, 191.94it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.03it/s] 20%|██        | 80/396 [00:00<00:01, 192.86it/s] 25%|██▌       | 100/396 [00:00<00:01, 193.33it/s] 30%|███       | 120/396 [00:00<00:01, 193.74it/s] 35%|███▌      | 140/396 [00:00<00:01, 193.88it/s] 40%|████      | 160/396 [00:00<00:01, 193.83it/s] 45%|████▌     | 180/396 [00:00<00:01, 193.83it/s] 51%|█████     | 200/396 [00:01<00:01, 193.78it/s] 56%|█████▌    | 220/396 [00:01<00:00, 193.76it/s] 61%|██████    | 240/396 [00:01<00:00, 193.70it/s] 66%|██████▌   | 260/396 [00:01<00:00, 193.59it/s] 71%|███████   | 280/396 [00:01<00:00, 193.53it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.51it/s] 81%|████████  | 320/396 [00:01<00:00, 193.45it/s] 86%|████████▌ | 340/396 [00:01<00:00, 192.82it/s] 91%|█████████ | 360/396 [00:01<00:00, 192.83it/s] 96%|█████████▌| 380/396 [00:01<00:00, 192.79it/s]100%|██████████| 396/396 [00:02<00:00, 193.21it/s]
2024-07-22:08:04:07,458 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:08:04:36,968 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:04:43,996 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:04:43,997 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:04:44,003 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:04:44,003 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 256}
2024-07-22:08:04:44,011 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.98s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.78s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.66s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.06s/it]
