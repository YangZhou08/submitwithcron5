Already on 'yangexp2threee'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
2024-07-22:08:01:03,372 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:01:12,787 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:01:12,788 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:01:12,812 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:01:12,812 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 128}
2024-07-22:08:01:12,821 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.77s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:19<00:06,  6.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  4.53s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.27s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:01:36,520 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.78it/s] 10%|█         | 40/396 [00:00<00:01, 192.64it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.79it/s] 20%|██        | 80/396 [00:00<00:01, 193.40it/s] 25%|██▌       | 100/396 [00:00<00:01, 193.80it/s] 30%|███       | 120/396 [00:00<00:01, 194.12it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.21it/s] 40%|████      | 160/396 [00:00<00:01, 194.21it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.18it/s] 51%|█████     | 200/396 [00:01<00:01, 194.18it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.18it/s] 61%|██████    | 240/396 [00:01<00:00, 194.12it/s] 66%|██████▌   | 260/396 [00:01<00:00, 193.99it/s] 71%|███████   | 280/396 [00:01<00:00, 193.94it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.99it/s] 81%|████████  | 320/396 [00:01<00:00, 193.88it/s] 86%|████████▌ | 340/396 [00:01<00:00, 193.81it/s] 91%|█████████ | 360/396 [00:01<00:00, 193.72it/s] 96%|█████████▌| 380/396 [00:01<00:00, 193.11it/s]100%|██████████| 396/396 [00:02<00:00, 193.69it/s]
2024-07-22:08:01:38,585 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:20<?, ?it/s]
2024-07-22:08:02:09,079 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:02:16,325 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:02:16,326 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:02:16,333 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:02:16,333 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 128}
2024-07-22:08:02:16,341 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.98s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.93s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.10s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:03:13,148 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 188.79it/s] 10%|▉         | 39/396 [00:00<00:01, 190.37it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.82it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.59it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.11it/s] 30%|███       | 119/396 [00:00<00:01, 192.54it/s] 35%|███▌      | 139/396 [00:00<00:01, 131.42it/s] 40%|███▉      | 158/396 [00:00<00:01, 143.52it/s] 45%|████▍     | 178/396 [00:01<00:01, 156.11it/s] 50%|█████     | 198/396 [00:01<00:01, 165.90it/s] 55%|█████▌    | 218/396 [00:01<00:01, 173.43it/s] 60%|██████    | 238/396 [00:01<00:00, 178.85it/s] 65%|██████▌   | 258/396 [00:01<00:00, 182.81it/s] 70%|███████   | 278/396 [00:01<00:00, 185.69it/s] 75%|███████▌  | 298/396 [00:01<00:00, 187.70it/s] 80%|████████  | 318/396 [00:01<00:00, 189.13it/s] 85%|████████▌ | 338/396 [00:01<00:00, 189.99it/s] 90%|█████████ | 358/396 [00:02<00:00, 190.60it/s] 95%|█████████▌| 378/396 [00:02<00:00, 188.40it/s]100%|██████████| 396/396 [00:02<00:00, 178.44it/s]
2024-07-22:08:03:15,376 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:08:03:41,033 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:03:48,296 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:03:48,297 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:03:48,303 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:03:48,303 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 256}
2024-07-22:08:03:48,311 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.43s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.69s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:04:05,401 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.48it/s] 10%|█         | 40/396 [00:00<00:01, 191.94it/s] 15%|█▌        | 60/396 [00:00<00:01, 192.03it/s] 20%|██        | 80/396 [00:00<00:01, 192.86it/s] 25%|██▌       | 100/396 [00:00<00:01, 193.33it/s] 30%|███       | 120/396 [00:00<00:01, 193.74it/s] 35%|███▌      | 140/396 [00:00<00:01, 193.88it/s] 40%|████      | 160/396 [00:00<00:01, 193.83it/s] 45%|████▌     | 180/396 [00:00<00:01, 193.83it/s] 51%|█████     | 200/396 [00:01<00:01, 193.78it/s] 56%|█████▌    | 220/396 [00:01<00:00, 193.76it/s] 61%|██████    | 240/396 [00:01<00:00, 193.70it/s] 66%|██████▌   | 260/396 [00:01<00:00, 193.59it/s] 71%|███████   | 280/396 [00:01<00:00, 193.53it/s] 76%|███████▌  | 300/396 [00:01<00:00, 193.51it/s] 81%|████████  | 320/396 [00:01<00:00, 193.45it/s] 86%|████████▌ | 340/396 [00:01<00:00, 192.82it/s] 91%|█████████ | 360/396 [00:01<00:00, 192.83it/s] 96%|█████████▌| 380/396 [00:01<00:00, 192.79it/s]100%|██████████| 396/396 [00:02<00:00, 193.21it/s]
2024-07-22:08:04:07,458 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:08:04:36,968 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:04:43,996 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:04:43,997 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:04:44,003 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:04:44,003 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 256}
2024-07-22:08:04:44,011 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.98s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.78s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.66s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.06s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:05:40,836 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 187.98it/s] 10%|▉         | 39/396 [00:00<00:01, 189.52it/s] 15%|█▍        | 58/396 [00:00<00:01, 189.70it/s] 20%|█▉        | 78/396 [00:00<00:01, 190.22it/s] 25%|██▍       | 98/396 [00:00<00:01, 191.72it/s] 30%|██▉       | 118/396 [00:00<00:01, 186.35it/s] 35%|███▍      | 137/396 [00:00<00:01, 187.27it/s] 39%|███▉      | 156/396 [00:00<00:01, 181.84it/s] 44%|████▍     | 176/396 [00:00<00:01, 185.58it/s] 49%|████▉     | 195/396 [00:01<00:01, 186.59it/s] 54%|█████▍    | 215/396 [00:01<00:00, 188.90it/s] 59%|█████▉    | 235/396 [00:01<00:00, 190.42it/s] 64%|██████▍   | 255/396 [00:01<00:00, 191.55it/s] 69%|██████▉   | 275/396 [00:01<00:00, 192.31it/s] 74%|███████▍  | 295/396 [00:01<00:00, 192.76it/s] 80%|███████▉  | 315/396 [00:01<00:00, 193.06it/s] 85%|████████▍ | 335/396 [00:01<00:00, 193.25it/s] 90%|████████▉ | 355/396 [00:01<00:00, 193.33it/s] 95%|█████████▍| 375/396 [00:01<00:00, 193.44it/s]100%|█████████▉| 395/396 [00:02<00:00, 193.44it/s]100%|██████████| 396/396 [00:02<00:00, 190.46it/s]
2024-07-22:08:05:42,923 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:08:06:08,905 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:06:16,009 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:06:16,010 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:06:16,016 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:06:16,016 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 512}
2024-07-22:08:06:16,025 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.68s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.97s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:06:30,174 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.33it/s] 10%|▉         | 39/396 [00:00<00:01, 190.40it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.61it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.23it/s] 25%|██▌       | 99/396 [00:00<00:01, 191.63it/s] 30%|███       | 119/396 [00:00<00:01, 191.99it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.14it/s] 40%|████      | 159/396 [00:00<00:01, 192.17it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.16it/s] 50%|█████     | 199/396 [00:01<00:01, 192.21it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.16it/s] 60%|██████    | 239/396 [00:01<00:00, 192.09it/s] 65%|██████▌   | 259/396 [00:01<00:00, 192.03it/s] 70%|███████   | 279/396 [00:01<00:00, 192.05it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.00it/s] 81%|████████  | 319/396 [00:01<00:00, 192.02it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.92it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.91it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.88it/s]100%|██████████| 396/396 [00:02<00:00, 191.83it/s]
2024-07-22:08:06:32,247 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
2024-07-22:08:07:02,150 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:07:09,136 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:07:09,137 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:07:09,143 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:07:09,143 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 512}
2024-07-22:08:07:09,151 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.38s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.73s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:08:04,131 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 188.54it/s] 10%|▉         | 39/396 [00:00<00:01, 190.04it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.46it/s] 20%|█▉        | 79/396 [00:00<00:01, 190.73it/s] 25%|██▌       | 99/396 [00:00<00:01, 191.48it/s] 30%|███       | 119/396 [00:00<00:01, 191.96it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.21it/s] 40%|████      | 159/396 [00:00<00:01, 192.34it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.40it/s] 50%|█████     | 199/396 [00:01<00:01, 192.40it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.43it/s] 60%|██████    | 239/396 [00:01<00:00, 192.32it/s] 65%|██████▌   | 259/396 [00:01<00:00, 192.20it/s] 70%|███████   | 279/396 [00:01<00:00, 192.19it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.21it/s] 81%|████████  | 319/396 [00:01<00:00, 192.10it/s] 86%|████████▌ | 339/396 [00:01<00:00, 192.00it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.97it/s] 96%|█████████▌| 379/396 [00:01<00:00, 189.77it/s]100%|██████████| 396/396 [00:02<00:00, 191.44it/s]
2024-07-22:08:08:06,208 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:15<?, ?it/s]
2024-07-22:08:08:32,109 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:08:39,178 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:08:39,178 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:08:39,184 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:08:39,184 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1024}
2024-07-22:08:08:39,193 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.62s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.56s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.56s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.96s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:08:53,039 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.91it/s] 10%|▉         | 39/396 [00:00<00:01, 191.68it/s] 15%|█▍        | 59/396 [00:00<00:01, 192.10it/s] 20%|█▉        | 79/396 [00:00<00:01, 192.51it/s] 25%|██▌       | 99/396 [00:00<00:01, 192.61it/s] 30%|███       | 119/396 [00:00<00:01, 192.92it/s] 35%|███▌      | 139/396 [00:00<00:01, 180.23it/s] 40%|████      | 159/396 [00:00<00:01, 184.01it/s] 45%|████▌     | 179/396 [00:00<00:01, 186.72it/s] 50%|█████     | 199/396 [00:01<00:01, 188.62it/s] 55%|█████▌    | 219/396 [00:01<00:00, 190.00it/s] 60%|██████    | 239/396 [00:01<00:00, 191.00it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.69it/s] 70%|███████   | 279/396 [00:01<00:00, 192.25it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.54it/s] 81%|████████  | 319/396 [00:01<00:00, 192.73it/s] 86%|████████▌ | 339/396 [00:01<00:00, 192.80it/s] 91%|█████████ | 359/396 [00:01<00:00, 192.89it/s] 96%|█████████▌| 379/396 [00:01<00:00, 192.98it/s]100%|██████████| 396/396 [00:02<00:00, 190.85it/s]
2024-07-22:08:08:55,123 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:20<?, ?it/s]
2024-07-22:08:09:25,204 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:09:32,345 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:09:32,346 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:09:32,352 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:09:32,352 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1024}
2024-07-22:08:09:32,361 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.85s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.66s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.63s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.54s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.96s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:10:28,184 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 186.84it/s] 10%|▉         | 38/396 [00:00<00:01, 188.25it/s] 14%|█▍        | 57/396 [00:00<00:01, 188.56it/s] 19%|█▉        | 77/396 [00:00<00:01, 189.25it/s] 24%|██▍       | 97/396 [00:00<00:01, 189.88it/s] 30%|██▉       | 117/396 [00:00<00:01, 190.20it/s] 35%|███▍      | 137/396 [00:00<00:01, 190.29it/s] 40%|███▉      | 157/396 [00:00<00:01, 190.31it/s] 45%|████▍     | 177/396 [00:00<00:01, 190.45it/s] 50%|████▉     | 197/396 [00:01<00:01, 190.30it/s] 55%|█████▍    | 217/396 [00:01<00:00, 190.31it/s] 60%|█████▉    | 237/396 [00:01<00:00, 190.15it/s] 65%|██████▍   | 257/396 [00:01<00:00, 189.96it/s] 70%|██████▉   | 276/396 [00:01<00:00, 189.90it/s] 75%|███████▍  | 296/396 [00:01<00:00, 189.90it/s] 80%|███████▉  | 316/396 [00:01<00:00, 189.96it/s] 85%|████████▍ | 335/396 [00:01<00:00, 189.88it/s] 89%|████████▉ | 354/396 [00:01<00:00, 189.73it/s] 94%|█████████▍| 373/396 [00:01<00:00, 189.70it/s] 99%|█████████▉| 392/396 [00:02<00:00, 189.60it/s]100%|██████████| 396/396 [00:02<00:00, 189.80it/s]
2024-07-22:08:10:30,278 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:16<?, ?it/s]
2024-07-22:08:10:58,039 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:11:05,231 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:11:05,232 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:11:05,240 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:11:05,241 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 1536}
2024-07-22:08:11:05,250 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:18,  6.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.78s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.59s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:11:21,788 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.83it/s] 10%|▉         | 39/396 [00:00<00:01, 190.77it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.12it/s] 20%|█▉        | 79/396 [00:00<00:01, 191.93it/s] 25%|██▌       | 99/396 [00:00<00:01, 191.36it/s] 30%|███       | 119/396 [00:00<00:01, 192.04it/s] 35%|███▌      | 139/396 [00:00<00:01, 192.33it/s] 40%|████      | 159/396 [00:00<00:01, 192.54it/s] 45%|████▌     | 179/396 [00:00<00:01, 192.53it/s] 50%|█████     | 199/396 [00:01<00:01, 192.54it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.66it/s] 60%|██████    | 239/396 [00:01<00:00, 192.56it/s] 65%|██████▌   | 259/396 [00:01<00:00, 192.55it/s] 70%|███████   | 279/396 [00:01<00:00, 192.49it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.46it/s] 81%|████████  | 319/396 [00:01<00:00, 192.42it/s] 86%|████████▌ | 339/396 [00:01<00:00, 192.28it/s] 91%|█████████ | 359/396 [00:01<00:00, 192.26it/s] 96%|█████████▌| 379/396 [00:01<00:00, 192.19it/s]100%|██████████| 396/396 [00:02<00:00, 192.19it/s]
2024-07-22:08:11:23,856 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:20<?, ?it/s]
2024-07-22:08:11:54,812 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:12:01,931 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:12:01,932 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:12:01,939 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:12:01,939 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 1536}
2024-07-22:08:12:01,948 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.82s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.49s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.91s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:12:57,496 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.06it/s] 10%|▉         | 39/396 [00:00<00:01, 190.48it/s] 15%|█▍        | 59/396 [00:00<00:01, 190.87it/s] 20%|█▉        | 79/396 [00:00<00:01, 189.37it/s] 25%|██▌       | 99/396 [00:00<00:01, 190.15it/s] 30%|███       | 119/396 [00:00<00:01, 190.67it/s] 35%|███▌      | 139/396 [00:00<00:01, 191.09it/s] 40%|████      | 159/396 [00:00<00:01, 191.48it/s] 45%|████▌     | 179/396 [00:00<00:01, 191.69it/s] 50%|█████     | 199/396 [00:01<00:01, 191.82it/s] 55%|█████▌    | 219/396 [00:01<00:00, 192.00it/s] 60%|██████    | 239/396 [00:01<00:00, 192.07it/s] 65%|██████▌   | 259/396 [00:01<00:00, 192.18it/s] 70%|███████   | 279/396 [00:01<00:00, 192.26it/s] 76%|███████▌  | 299/396 [00:01<00:00, 192.32it/s] 81%|████████  | 319/396 [00:01<00:00, 192.43it/s] 86%|████████▌ | 339/396 [00:01<00:00, 192.44it/s] 91%|█████████ | 359/396 [00:01<00:00, 192.44it/s] 96%|█████████▌| 379/396 [00:01<00:00, 192.37it/s]100%|██████████| 396/396 [00:02<00:00, 191.73it/s]
2024-07-22:08:12:59,570 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:16<?, ?it/s]
2024-07-22:08:13:26,558 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:13:33,681 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:13:33,682 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:13:33,688 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:13:33,688 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 2048}
2024-07-22:08:13:33,696 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.85s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.69s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.60s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.54s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.96s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:13:47,585 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 188.26it/s] 10%|▉         | 39/396 [00:00<00:01, 189.22it/s] 15%|█▍        | 59/396 [00:00<00:01, 189.57it/s] 20%|█▉        | 79/396 [00:00<00:01, 190.41it/s] 25%|██▌       | 99/396 [00:00<00:01, 190.87it/s] 30%|███       | 119/396 [00:00<00:01, 191.29it/s] 35%|███▌      | 139/396 [00:00<00:01, 191.45it/s] 40%|████      | 159/396 [00:00<00:01, 191.50it/s] 45%|████▌     | 179/396 [00:00<00:01, 191.38it/s] 50%|█████     | 199/396 [00:01<00:01, 191.44it/s] 55%|█████▌    | 219/396 [00:01<00:00, 191.47it/s] 60%|██████    | 239/396 [00:01<00:00, 191.43it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.41it/s] 70%|███████   | 279/396 [00:01<00:00, 191.41it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.39it/s] 81%|████████  | 319/396 [00:01<00:00, 191.39it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.25it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.03it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.06it/s]100%|██████████| 396/396 [00:02<00:00, 191.08it/s]
2024-07-22:08:13:49,666 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:22<?, ?it/s]
2024-07-22:08:14:22,472 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:14:29,619 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:14:29,620 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:14:29,626 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:14:29,626 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 2048}
2024-07-22:08:14:29,635 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.86s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.64s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.59s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.53s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.94s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:15:25,547 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:02, 187.70it/s] 10%|▉         | 39/396 [00:00<00:01, 189.28it/s] 15%|█▍        | 59/396 [00:00<00:01, 189.80it/s] 20%|█▉        | 79/396 [00:00<00:01, 190.69it/s] 25%|██▌       | 99/396 [00:00<00:01, 191.32it/s] 30%|███       | 119/396 [00:00<00:01, 191.27it/s] 35%|███▌      | 139/396 [00:00<00:01, 191.68it/s] 40%|████      | 159/396 [00:00<00:01, 191.87it/s] 45%|████▌     | 179/396 [00:00<00:01, 191.85it/s] 50%|█████     | 199/396 [00:01<00:01, 191.84it/s] 55%|█████▌    | 219/396 [00:01<00:00, 191.84it/s] 60%|██████    | 239/396 [00:01<00:00, 191.72it/s] 65%|██████▌   | 259/396 [00:01<00:00, 191.78it/s] 70%|███████   | 279/396 [00:01<00:00, 191.77it/s] 76%|███████▌  | 299/396 [00:01<00:00, 191.34it/s] 81%|████████  | 319/396 [00:01<00:00, 191.36it/s] 86%|████████▌ | 339/396 [00:01<00:00, 191.24it/s] 91%|█████████ | 359/396 [00:01<00:00, 191.22it/s] 96%|█████████▌| 379/396 [00:01<00:00, 191.04it/s]100%|██████████| 396/396 [00:02<00:00, 191.25it/s]
2024-07-22:08:15:27,627 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:18<?, ?it/s]
2024-07-22:08:15:56,387 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:16:03,545 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:16:03,546 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:16:03,552 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:16:03,552 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 3072}
2024-07-22:08:16:03,560 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.83s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.66s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.59s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.94s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:16:17,312 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.83it/s] 10%|█         | 40/396 [00:00<00:01, 192.81it/s] 15%|█▌        | 60/396 [00:00<00:01, 193.05it/s] 20%|██        | 80/396 [00:00<00:01, 193.71it/s] 25%|██▌       | 100/396 [00:00<00:01, 194.15it/s] 30%|███       | 120/396 [00:00<00:01, 194.61it/s] 35%|███▌      | 140/396 [00:00<00:01, 194.91it/s] 40%|████      | 160/396 [00:00<00:01, 194.91it/s] 45%|████▌     | 180/396 [00:00<00:01, 194.89it/s] 51%|█████     | 200/396 [00:01<00:01, 194.85it/s] 56%|█████▌    | 220/396 [00:01<00:00, 194.80it/s] 61%|██████    | 240/396 [00:01<00:00, 194.65it/s] 66%|██████▌   | 260/396 [00:01<00:00, 194.46it/s] 71%|███████   | 280/396 [00:01<00:00, 194.51it/s] 76%|███████▌  | 300/396 [00:01<00:00, 194.64it/s] 81%|████████  | 320/396 [00:01<00:00, 194.61it/s] 86%|████████▌ | 340/396 [00:01<00:00, 194.54it/s] 91%|█████████ | 360/396 [00:01<00:00, 194.54it/s] 96%|█████████▌| 380/396 [00:01<00:00, 194.54it/s]100%|██████████| 396/396 [00:02<00:00, 194.43it/s]
2024-07-22:08:16:19,357 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:22<?, ?it/s]
2024-07-22:08:16:51,775 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:16:58,894 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:16:58,895 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:16:58,902 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:16:58,902 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 3072}
2024-07-22:08:16:58,910 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.87s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.66s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.59s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.96s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:17:55,187 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▌         | 20/396 [00:00<00:01, 191.77it/s] 10%|█         | 40/396 [00:00<00:01, 193.41it/s] 15%|█▌        | 60/396 [00:00<00:01, 193.87it/s] 20%|██        | 80/396 [00:00<00:01, 194.55it/s] 25%|██▌       | 100/396 [00:00<00:01, 195.04it/s] 30%|███       | 120/396 [00:00<00:01, 195.32it/s] 35%|███▌      | 140/396 [00:00<00:01, 195.41it/s] 40%|████      | 160/396 [00:00<00:01, 194.98it/s] 45%|████▌     | 180/396 [00:00<00:01, 195.14it/s] 51%|█████     | 200/396 [00:01<00:01, 195.19it/s] 56%|█████▌    | 220/396 [00:01<00:00, 195.15it/s] 61%|██████    | 240/396 [00:01<00:00, 195.09it/s] 66%|██████▌   | 260/396 [00:01<00:00, 195.01it/s] 71%|███████   | 280/396 [00:01<00:00, 194.99it/s] 76%|███████▌  | 300/396 [00:01<00:00, 186.76it/s] 81%|████████  | 320/396 [00:01<00:00, 187.99it/s] 86%|████████▌ | 340/396 [00:01<00:00, 189.88it/s] 91%|█████████ | 360/396 [00:01<00:00, 191.23it/s] 96%|█████████▌| 380/396 [00:01<00:00, 192.18it/s]100%|██████████| 396/396 [00:02<00:00, 193.18it/s]
2024-07-22:08:17:57,244 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:18<?, ?it/s]
2024-07-22:08:18:25,701 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:18:32,759 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:18:32,759 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:18:32,766 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:18:32,766 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False, 'contextlength': 4096}
2024-07-22:08:18:32,776 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.82s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.62s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.92s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:18:46,478 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.79it/s] 10%|▉         | 39/396 [00:00<00:01, 191.22it/s] 15%|█▍        | 59/396 [00:00<00:01, 191.94it/s] 20%|█▉        | 79/396 [00:00<00:01, 192.90it/s] 25%|██▌       | 99/396 [00:00<00:01, 193.43it/s] 30%|███       | 119/396 [00:00<00:01, 193.65it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.84it/s] 40%|████      | 159/396 [00:00<00:01, 193.93it/s] 45%|████▌     | 179/396 [00:00<00:01, 193.86it/s] 50%|█████     | 199/396 [00:01<00:01, 193.85it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.79it/s] 60%|██████    | 239/396 [00:01<00:00, 193.65it/s] 65%|██████▌   | 259/396 [00:01<00:00, 193.70it/s] 70%|███████   | 279/396 [00:01<00:00, 193.72it/s] 76%|███████▌  | 299/396 [00:01<00:00, 193.72it/s] 81%|████████  | 319/396 [00:01<00:00, 193.68it/s] 86%|████████▌ | 339/396 [00:01<00:00, 193.54it/s] 91%|█████████ | 359/396 [00:01<00:00, 193.44it/s] 96%|█████████▌| 379/396 [00:01<00:00, 193.37it/s]100%|██████████| 396/396 [00:02<00:00, 193.41it/s]
2024-07-22:08:18:48,533 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:25<?, ?it/s]
2024-07-22:08:19:24,426 INFO     [main.py:288] Verbosity set to INFO
2024-07-22:08:19:31,572 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-07-22:08:19:31,573 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-07-22:08:19:31,579 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-22:08:19:31,579 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False, 'contextlength': 4096}
2024-07-22:08:19:31,588 INFO     [xhuggingface.py:166] Using device 'cuda'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.85s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.64s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.93s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-07-22:08:20:27,375 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/396 [00:00<?, ?it/s]  5%|▍         | 19/396 [00:00<00:01, 189.85it/s] 10%|▉         | 39/396 [00:00<00:01, 191.61it/s] 15%|█▍        | 59/396 [00:00<00:01, 192.00it/s] 20%|█▉        | 79/396 [00:00<00:01, 192.84it/s] 25%|██▌       | 99/396 [00:00<00:01, 193.24it/s] 30%|███       | 119/396 [00:00<00:01, 193.44it/s] 35%|███▌      | 139/396 [00:00<00:01, 193.52it/s] 40%|████      | 159/396 [00:00<00:01, 193.54it/s] 45%|████▌     | 179/396 [00:00<00:01, 193.63it/s] 50%|█████     | 199/396 [00:01<00:01, 193.58it/s] 55%|█████▌    | 219/396 [00:01<00:00, 193.53it/s] 60%|██████    | 239/396 [00:01<00:00, 193.39it/s] 65%|██████▌   | 259/396 [00:01<00:00, 193.37it/s] 70%|███████   | 279/396 [00:01<00:00, 193.32it/s] 76%|███████▌  | 299/396 [00:01<00:00, 193.33it/s] 81%|████████  | 319/396 [00:01<00:00, 193.27it/s] 86%|████████▌ | 339/396 [00:01<00:00, 193.17it/s] 91%|█████████ | 359/396 [00:01<00:00, 193.18it/s] 96%|█████████▌| 379/396 [00:01<00:00, 193.19it/s]100%|██████████| 396/396 [00:02<00:00, 193.18it/s]
2024-07-22:08:20:29,433 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/396 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 0/396 [00:19<?, ?it/s]
