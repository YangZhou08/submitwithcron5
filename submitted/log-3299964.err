Already on 'addinggriffin'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.76s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.20s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.19s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.22s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.98s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.25s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.24s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.27s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.09s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.71s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.70s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.70s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.72s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.78s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.77s/it]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/CommonSenseReasoning/main.py:403: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  promptids = torch.tensor(promptids, dtype = torch.long).to(args.device)
  0%|          | 0/32 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  3%|▎         | 1/32 [00:28<14:29, 28.05s/it]  3%|▎         | 1/32 [00:28<14:32, 28.15s/it]  3%|▎         | 1/32 [00:27<14:15, 27.60s/it]  3%|▎         | 1/32 [00:28<14:57, 28.94s/it]  3%|▎         | 1/32 [00:28<14:53, 28.81s/it]  3%|▎         | 1/32 [00:30<15:52, 30.72s/it]  3%|▎         | 1/32 [00:39<20:15, 39.20s/it]  3%|▎         | 1/32 [00:41<21:15, 41.14s/it]  6%|▋         | 2/32 [00:53<13:19, 26.64s/it]  6%|▋         | 2/32 [00:55<13:37, 27.25s/it]  6%|▋         | 2/32 [00:55<13:46, 27.57s/it]  6%|▋         | 2/32 [00:54<13:34, 27.15s/it]  6%|▋         | 2/32 [00:55<13:38, 27.27s/it]  6%|▋         | 2/32 [00:59<14:52, 29.74s/it]  9%|▉         | 3/32 [01:19<12:37, 26.13s/it]  9%|▉         | 3/32 [01:20<12:54, 26.69s/it]  9%|▉         | 3/32 [01:20<12:48, 26.49s/it]  6%|▋         | 2/32 [01:21<20:25, 40.85s/it]  9%|▉         | 3/32 [01:21<13:04, 27.04s/it]  6%|▋         | 2/32 [01:21<20:27, 40.92s/it]  9%|▉         | 3/32 [01:21<12:56, 26.76s/it]  9%|▉         | 3/32 [01:25<13:32, 28.02s/it] 12%|█▎        | 4/32 [01:44<12:05, 25.92s/it] 12%|█▎        | 4/32 [01:45<12:14, 26.24s/it] 12%|█▎        | 4/32 [01:47<12:24, 26.57s/it] 12%|█▎        | 4/32 [01:47<12:27, 26.69s/it] 12%|█▎        | 4/32 [01:48<12:30, 26.82s/it] 12%|█▎        | 4/32 [01:51<12:41, 27.18s/it]  9%|▉         | 3/32 [02:02<19:47, 40.96s/it]  9%|▉         | 3/32 [02:02<19:47, 40.94s/it] 16%|█▌        | 5/32 [02:11<11:43, 26.04s/it] 16%|█▌        | 5/32 [02:12<11:48, 26.22s/it] 16%|█▌        | 5/32 [02:13<11:53, 26.43s/it] 16%|█▌        | 5/32 [02:13<12:00, 26.68s/it] 16%|█▌        | 5/32 [02:14<11:58, 26.60s/it] 16%|█▌        | 5/32 [02:18<12:09, 27.03s/it] 19%|█▉        | 6/32 [02:37<11:19, 26.14s/it] 19%|█▉        | 6/32 [02:38<11:17, 26.05s/it] 19%|█▉        | 6/32 [02:40<11:24, 26.33s/it] 19%|█▉        | 6/32 [02:39<11:24, 26.33s/it] 12%|█▎        | 4/32 [02:43<19:04, 40.89s/it] 19%|█▉        | 6/32 [02:44<12:06, 27.96s/it] 12%|█▎        | 4/32 [02:45<19:33, 41.93s/it] 19%|█▉        | 6/32 [02:44<11:34, 26.72s/it] 22%|██▏       | 7/32 [03:03<10:49, 25.99s/it] 22%|██▏       | 7/32 [03:05<10:55, 26.21s/it] 22%|██▏       | 7/32 [03:04<10:54, 26.17s/it] 22%|██▏       | 7/32 [03:06<11:02, 26.51s/it] 22%|██▏       | 7/32 [03:10<11:01, 26.45s/it] 22%|██▏       | 7/32 [03:17<12:15, 29.42s/it] 16%|█▌        | 5/32 [03:24<18:22, 40.83s/it] 16%|█▌        | 5/32 [03:27<18:54, 42.01s/it] 25%|██▌       | 8/32 [03:30<10:33, 26.39s/it] 25%|██▌       | 8/32 [03:30<10:24, 26.03s/it] 25%|██▌       | 8/32 [03:31<10:27, 26.14s/it] 25%|██▌       | 8/32 [03:33<10:38, 26.61s/it] 25%|██▌       | 8/32 [03:36<10:32, 26.36s/it] 25%|██▌       | 8/32 [03:50<12:16, 30.71s/it] 28%|██▊       | 9/32 [03:56<10:01, 26.16s/it] 28%|██▊       | 9/32 [03:57<10:01, 26.16s/it] 28%|██▊       | 9/32 [03:58<10:10, 26.55s/it] 28%|██▊       | 9/32 [04:03<10:37, 27.72s/it] 28%|██▊       | 9/32 [04:04<10:18, 26.87s/it] 19%|█▉        | 6/32 [04:06<17:52, 41.27s/it] 19%|█▉        | 6/32 [04:10<18:15, 42.13s/it] 31%|███▏      | 10/32 [04:21<09:31, 25.99s/it] 31%|███▏      | 10/32 [04:23<09:32, 26.04s/it] 28%|██▊       | 9/32 [04:23<11:59, 31.26s/it] 31%|███▏      | 10/32 [04:24<09:40, 26.37s/it] 31%|███▏      | 10/32 [04:31<10:08, 27.67s/it] 31%|███▏      | 10/32 [04:32<09:56, 27.14s/it] 34%|███▍      | 11/32 [04:47<09:02, 25.84s/it] 34%|███▍      | 11/32 [04:48<09:04, 25.95s/it] 22%|██▏       | 7/32 [04:51<17:38, 42.36s/it] 34%|███▍      | 11/32 [04:52<09:25, 26.95s/it] 22%|██▏       | 7/32 [04:57<18:15, 43.83s/it] 31%|███▏      | 10/32 [04:56<11:43, 31.99s/it] 34%|███▍      | 11/32 [04:58<09:34, 27.36s/it] 34%|███▍      | 11/32 [05:01<09:43, 27.80s/it] 38%|███▊      | 12/32 [05:16<08:59, 26.96s/it] 38%|███▊      | 12/32 [05:17<08:56, 26.81s/it] 38%|███▊      | 12/32 [05:19<08:58, 26.90s/it] 38%|███▊      | 12/32 [05:24<09:03, 27.17s/it] 38%|███▊      | 12/32 [05:28<09:10, 27.52s/it] 34%|███▍      | 11/32 [05:29<11:14, 32.14s/it] 25%|██▌       | 8/32 [05:37<17:23, 43.50s/it] 25%|██▌       | 8/32 [05:39<17:20, 43.36s/it] 41%|████      | 13/32 [05:44<08:28, 26.74s/it] 41%|████      | 13/32 [05:44<08:37, 27.22s/it] 41%|████      | 13/32 [05:45<08:25, 26.59s/it] 41%|████      | 13/32 [05:50<08:29, 26.81s/it] 41%|████      | 13/32 [05:54<08:35, 27.14s/it] 38%|███▊      | 12/32 [06:01<10:44, 32.21s/it] 44%|████▍     | 14/32 [06:09<07:55, 26.39s/it] 44%|████▍     | 14/32 [06:10<08:01, 26.72s/it] 44%|████▍     | 14/32 [06:11<07:55, 26.39s/it] 44%|████▍     | 14/32 [06:16<07:57, 26.55s/it] 28%|██▊       | 9/32 [06:17<16:20, 42.61s/it] 28%|██▊       | 9/32 [06:22<16:28, 42.99s/it] 44%|████▍     | 14/32 [06:20<08:02, 26.80s/it] 47%|████▋     | 15/32 [06:35<07:28, 26.36s/it] 47%|████▋     | 15/32 [06:36<07:31, 26.57s/it] 41%|████      | 13/32 [06:36<10:24, 32.88s/it] 47%|████▋     | 15/32 [06:37<07:29, 26.44s/it] 47%|████▋     | 15/32 [06:42<07:28, 26.40s/it] 47%|████▋     | 15/32 [06:46<07:32, 26.63s/it] 31%|███▏      | 10/32 [06:58<15:26, 42.12s/it] 50%|█████     | 16/32 [07:01<06:57, 26.12s/it] 50%|█████     | 16/32 [07:03<07:04, 26.54s/it] 50%|█████     | 16/32 [07:03<07:00, 26.29s/it] 31%|███▏      | 10/32 [07:09<16:16, 44.40s/it] 50%|█████     | 16/32 [07:10<07:07, 26.74s/it] 44%|████▍     | 14/32 [07:11<10:05, 33.63s/it] 50%|█████     | 16/32 [07:20<07:38, 28.63s/it] 53%|█████▎    | 17/32 [07:26<06:29, 26.00s/it] 53%|█████▎    | 17/32 [07:29<06:37, 26.50s/it] 53%|█████▎    | 17/32 [07:30<06:35, 26.39s/it] 53%|█████▎    | 17/32 [07:36<06:37, 26.50s/it] 34%|███▍      | 11/32 [07:40<14:43, 42.09s/it] 47%|████▋     | 15/32 [07:44<09:26, 33.31s/it] 53%|█████▎    | 17/32 [07:47<07:02, 28.19s/it] 34%|███▍      | 11/32 [07:50<15:10, 43.36s/it] 56%|█████▋    | 18/32 [07:53<06:06, 26.16s/it] 56%|█████▋    | 18/32 [07:57<06:17, 26.98s/it] 56%|█████▋    | 18/32 [07:56<06:10, 26.44s/it] 56%|█████▋    | 18/32 [08:02<06:08, 26.35s/it] 50%|█████     | 16/32 [08:16<08:49, 33.09s/it] 59%|█████▉    | 19/32 [08:18<05:37, 25.97s/it] 56%|█████▋    | 18/32 [08:17<06:42, 28.75s/it] 59%|█████▉    | 19/32 [08:23<05:45, 26.58s/it] 59%|█████▉    | 19/32 [08:23<05:44, 26.48s/it] 38%|███▊      | 12/32 [08:27<14:30, 43.51s/it] 59%|█████▉    | 19/32 [08:28<05:40, 26.19s/it] 38%|███▊      | 12/32 [08:35<14:35, 43.76s/it] 59%|█████▉    | 19/32 [08:43<06:04, 28.03s/it] 62%|██████▎   | 20/32 [08:46<05:15, 26.32s/it] 62%|██████▎   | 20/32 [08:49<05:16, 26.42s/it] 53%|█████▎    | 17/32 [08:49<08:13, 32.92s/it] 62%|██████▎   | 20/32 [08:49<05:16, 26.39s/it] 62%|██████▎   | 20/32 [08:58<05:28, 27.38s/it] 41%|████      | 13/32 [09:08<13:32, 42.76s/it] 66%|██████▌   | 21/32 [09:11<04:47, 26.12s/it] 62%|██████▎   | 20/32 [09:10<05:32, 27.73s/it] 66%|██████▌   | 21/32 [09:15<04:48, 26.19s/it] 66%|██████▌   | 21/32 [09:17<04:56, 26.93s/it] 41%|████      | 13/32 [09:21<14:05, 44.50s/it] 66%|██████▌   | 21/32 [09:24<04:56, 26.93s/it] 56%|█████▋    | 18/32 [09:25<07:56, 34.00s/it] 69%|██████▉   | 22/32 [09:38<04:24, 26.41s/it] 66%|██████▌   | 21/32 [09:37<05:01, 27.45s/it] 69%|██████▉   | 22/32 [09:40<04:20, 26.03s/it] 69%|██████▉   | 22/32 [09:43<04:26, 26.62s/it] 44%|████▍     | 14/32 [09:49<12:39, 42.20s/it] 69%|██████▉   | 22/32 [09:50<04:27, 26.73s/it] 59%|█████▉    | 19/32 [09:59<07:19, 33.82s/it] 44%|████▍     | 14/32 [10:02<13:03, 43.51s/it] 72%|███████▏  | 23/32 [10:04<03:55, 26.19s/it] 72%|███████▏  | 23/32 [10:06<03:53, 25.90s/it] 69%|██████▉   | 22/32 [10:06<04:40, 28.01s/it] 72%|███████▏  | 23/32 [10:09<03:57, 26.42s/it] 72%|███████▏  | 23/32 [10:16<03:58, 26.47s/it] 75%|███████▌  | 24/32 [10:30<03:28, 26.00s/it] 47%|████▋     | 15/32 [10:31<11:55, 42.11s/it] 78%|███████▊  | 25/32 [10:31<02:19, 19.87s/it] 62%|██████▎   | 20/32 [10:32<06:45, 33.75s/it] 72%|███████▏  | 23/32 [10:33<04:07, 27.46s/it] 75%|███████▌  | 24/32 [10:35<03:30, 26.32s/it] 75%|███████▌  | 24/32 [10:42<03:32, 26.54s/it] 47%|████▋     | 15/32 [10:44<12:08, 42.84s/it] 78%|███████▊  | 25/32 [10:57<03:04, 26.33s/it] 81%|████████▏ | 26/32 [10:58<02:09, 21.51s/it] 75%|███████▌  | 24/32 [11:00<03:40, 27.52s/it] 78%|███████▊  | 25/32 [11:01<03:03, 26.22s/it] 66%|██████▌   | 21/32 [11:06<06:09, 33.64s/it] 78%|███████▊  | 25/32 [11:09<03:06, 26.58s/it] 50%|█████     | 16/32 [11:14<11:20, 42.51s/it] 81%|████████▏ | 26/32 [11:23<02:38, 26.36s/it] 84%|████████▍ | 27/32 [11:24<01:53, 22.79s/it] 50%|█████     | 16/32 [11:26<11:22, 42.67s/it] 78%|███████▊  | 25/32 [11:26<03:09, 27.04s/it] 81%|████████▏ | 26/32 [11:27<02:36, 26.07s/it] 81%|████████▏ | 26/32 [11:35<02:38, 26.36s/it] 69%|██████▉   | 22/32 [11:38<05:32, 33.27s/it] 84%|████████▍ | 27/32 [11:49<02:10, 26.14s/it] 88%|████████▊ | 28/32 [11:50<01:34, 23.60s/it] 81%|████████▏ | 26/32 [11:52<02:40, 26.75s/it] 84%|████████▍ | 27/32 [11:54<02:11, 26.30s/it] 53%|█████▎    | 17/32 [11:56<10:35, 42.37s/it] 84%|████████▍ | 27/32 [12:01<02:11, 26.21s/it] 53%|█████▎    | 17/32 [12:12<10:55, 43.68s/it] 72%|███████▏  | 23/32 [12:11<04:59, 33.31s/it] 88%|████████▊ | 28/32 [12:14<01:43, 25.95s/it] 91%|█████████ | 29/32 [12:17<01:13, 24.63s/it] 84%|████████▍ | 27/32 [12:18<02:12, 26.54s/it] 88%|████████▊ | 28/32 [12:20<01:45, 26.38s/it] 88%|████████▊ | 28/32 [12:26<01:44, 26.03s/it] 56%|█████▋    | 18/32 [12:40<09:56, 42.62s/it] 94%|█████████▍| 30/32 [12:40<00:39, 19.87s/it] 94%|█████████▍| 30/32 [12:44<00:50, 25.26s/it] 88%|████████▊ | 28/32 [12:45<01:45, 26.44s/it] 75%|███████▌  | 24/32 [12:47<04:31, 33.93s/it] 91%|█████████ | 29/32 [12:48<01:20, 26.70s/it] 91%|█████████ | 29/32 [12:53<01:18, 26.24s/it] 56%|█████▋    | 18/32 [12:54<10:05, 43.27s/it] 97%|█████████▋| 31/32 [13:08<00:21, 21.91s/it] 97%|█████████▋| 31/32 [13:11<00:25, 25.64s/it] 91%|█████████ | 29/32 [13:11<01:19, 26.39s/it]