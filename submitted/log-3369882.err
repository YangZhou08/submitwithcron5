wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:08<01:08, 68.50s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.85s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.34s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:09<01:09, 69.95s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:09<01:09, 69.95s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.01s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.58s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:09<01:09, 69.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:24<00:00, 37.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:24<00:00, 42.41s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 37.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.78s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 38.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.90s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 37.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.59s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 38.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.62s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 37.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.60s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 37.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.62s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 38.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 43.05s/it]
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/utils.py:119: UserWarning: n_copies (n_samples/batch_size) was changed from 1 to 2 because n_tasks isn't proportional to num devices
  warnings.warn(
  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]  0%|          | 0/21 [00:00<?, ?it/s]/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/fsx-storygen/beidic/anaconda3/envs/griffin/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  5%|▍         | 1/21 [00:38<12:42, 38.14s/it]  5%|▍         | 1/21 [00:38<12:49, 38.50s/it]  5%|▍         | 1/21 [00:38<12:50, 38.53s/it]  5%|▍         | 1/21 [00:38<12:50, 38.54s/it]  5%|▍         | 1/21 [00:38<12:48, 38.41s/it]  5%|▍         | 1/21 [00:38<12:50, 38.54s/it]  5%|▍         | 1/21 [00:37<12:32, 37.64s/it]  5%|▍         | 1/21 [00:38<12:50, 38.51s/it] 10%|▉         | 2/21 [00:58<08:46, 27.71s/it] 10%|▉         | 2/21 [00:58<08:47, 27.74s/it] 10%|▉         | 2/21 [00:58<08:47, 27.76s/it] 10%|▉         | 2/21 [00:58<08:44, 27.60s/it] 10%|▉         | 2/21 [00:58<08:47, 27.76s/it] 10%|▉         | 2/21 [00:57<08:40, 27.39s/it] 10%|▉         | 2/21 [00:58<08:47, 27.75s/it] 10%|▉         | 2/21 [00:58<08:47, 27.76s/it] 14%|█▍        | 3/21 [01:17<07:05, 23.62s/it] 14%|█▍        | 3/21 [01:17<07:05, 23.62s/it] 14%|█▍        | 3/21 [01:17<07:03, 23.54s/it] 14%|█▍        | 3/21 [01:17<07:05, 23.63s/it] 14%|█▍        | 3/21 [01:16<07:01, 23.42s/it] 14%|█▍        | 3/21 [01:17<07:05, 23.62s/it] 14%|█▍        | 3/21 [01:17<07:04, 23.60s/it] 14%|█▍        | 3/21 [01:17<07:05, 23.63s/it] 19%|█▉        | 4/21 [01:50<07:43, 27.28s/it] 19%|█▉        | 4/21 [01:50<07:43, 27.29s/it] 19%|█▉        | 4/21 [01:50<07:43, 27.28s/it] 19%|█▉        | 4/21 [01:49<07:42, 27.23s/it] 19%|█▉        | 4/21 [01:49<07:41, 27.16s/it] 19%|█▉        | 4/21 [01:50<07:43, 27.29s/it] 19%|█▉        | 4/21 [01:50<07:43, 27.28s/it] 19%|█▉        | 4/21 [01:50<07:43, 27.27s/it] 24%|██▍       | 5/21 [02:19<07:26, 27.88s/it] 24%|██▍       | 5/21 [02:19<07:25, 27.87s/it] 24%|██▍       | 5/21 [02:18<07:25, 27.84s/it] 24%|██▍       | 5/21 [02:19<07:26, 27.88s/it] 24%|██▍       | 5/21 [02:19<07:26, 27.88s/it] 24%|██▍       | 5/21 [02:18<07:24, 27.80s/it] 24%|██▍       | 5/21 [02:19<07:25, 27.87s/it] 24%|██▍       | 5/21 [02:19<07:26, 27.88s/it] 29%|██▊       | 6/21 [02:52<07:27, 29.81s/it] 29%|██▊       | 6/21 [02:52<07:27, 29.81s/it] 29%|██▊       | 6/21 [02:52<07:27, 29.81s/it] 29%|██▊       | 6/21 [02:52<07:26, 29.79s/it] 29%|██▊       | 6/21 [02:52<07:27, 29.81s/it] 29%|██▊       | 6/21 [02:52<07:27, 29.81s/it] 29%|██▊       | 6/21 [02:51<07:26, 29.76s/it] 29%|██▊       | 6/21 [02:52<07:27, 29.81s/it] 33%|███▎      | 7/21 [03:26<07:14, 31.06s/it] 33%|███▎      | 7/21 [03:26<07:14, 31.05s/it] 33%|███▎      | 7/21 [03:26<07:14, 31.04s/it] 33%|███▎      | 7/21 [03:26<07:14, 31.06s/it] 33%|███▎      | 7/21 [03:26<07:14, 31.06s/it] 33%|███▎      | 7/21 [03:26<07:14, 31.05s/it] 33%|███▎      | 7/21 [03:25<07:14, 31.02s/it] 33%|███▎      | 7/21 [03:26<07:14, 31.05s/it] 38%|███▊      | 8/21 [03:57<06:43, 31.07s/it] 38%|███▊      | 8/21 [03:57<06:43, 31.07s/it] 38%|███▊      | 8/21 [03:56<06:43, 31.05s/it] 38%|███▊      | 8/21 [03:57<06:43, 31.06s/it] 38%|███▊      | 8/21 [03:57<06:43, 31.07s/it] 38%|███▊      | 8/21 [03:57<06:43, 31.07s/it] 38%|███▊      | 8/21 [03:57<06:43, 31.07s/it] 38%|███▊      | 8/21 [03:57<06:43, 31.07s/it] 43%|████▎     | 9/21 [04:27<06:09, 30.75s/it] 43%|████▎     | 9/21 [04:27<06:09, 30.75s/it] 43%|████▎     | 9/21 [04:27<06:09, 30.75s/it] 43%|████▎     | 9/21 [04:27<06:09, 30.75s/it] 43%|████▎     | 9/21 [04:27<06:09, 30.75s/it] 43%|████▎     | 9/21 [04:27<06:08, 30.75s/it] 43%|████▎     | 9/21 [04:27<06:09, 30.75s/it] 43%|████▎     | 9/21 [04:26<06:08, 30.74s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.31s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.31s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.31s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.31s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.31s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.31s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.30s/it] 48%|████▊     | 10/21 [04:56<05:33, 30.31s/it] 52%|█████▏    | 11/21 [05:23<04:52, 29.24s/it] 52%|█████▏    | 11/21 [05:23<04:52, 29.24s/it] 52%|█████▏    | 11/21 [05:23<04:52, 29.24s/it] 52%|█████▏    | 11/21 [05:23<04:52, 29.24s/it] 52%|█████▏    | 11/21 [05:23<04:52, 29.24s/it] 52%|█████▏    | 11/21 [05:23<04:52, 29.24s/it] 52%|█████▏    | 11/21 [05:23<04:52, 29.24s/it] 52%|█████▏    | 11/21 [05:22<04:52, 29.23s/it] 57%|█████▋    | 12/21 [06:00<04:42, 31.43s/it] 57%|█████▋    | 12/21 [06:00<04:42, 31.43s/it] 57%|█████▋    | 12/21 [06:00<04:42, 31.43s/it] 57%|█████▋    | 12/21 [06:00<04:42, 31.43s/it] 57%|█████▋    | 12/21 [05:59<04:42, 31.42s/it] 57%|█████▋    | 12/21 [06:00<04:42, 31.43s/it] 57%|█████▋    | 12/21 [05:59<04:42, 31.43s/it] 57%|█████▋    | 12/21 [06:00<04:42, 31.43s/it] 62%|██████▏   | 13/21 [06:28<04:04, 30.53s/it] 62%|██████▏   | 13/21 [06:28<04:04, 30.53s/it] 62%|██████▏   | 13/21 [06:28<04:04, 30.53s/it] 62%|██████▏   | 13/21 [06:28<04:04, 30.53s/it] 62%|██████▏   | 13/21 [06:28<04:04, 30.53s/it] 62%|██████▏   | 13/21 [06:28<04:04, 30.53s/it] 62%|██████▏   | 13/21 [06:27<04:04, 30.53s/it] 62%|██████▏   | 13/21 [06:28<04:04, 30.53s/it] 67%|██████▋   | 14/21 [07:01<03:39, 31.33s/it] 67%|██████▋   | 14/21 [07:01<03:39, 31.33s/it] 67%|██████▋   | 14/21 [07:01<03:39, 31.33s/it] 67%|██████▋   | 14/21 [07:01<03:39, 31.33s/it] 67%|██████▋   | 14/21 [07:01<03:39, 31.33s/it] 67%|██████▋   | 14/21 [07:01<03:39, 31.33s/it] 67%|██████▋   | 14/21 [07:01<03:39, 31.33s/it] 67%|██████▋   | 14/21 [07:00<03:39, 31.33s/it] 71%|███████▏  | 15/21 [07:33<03:09, 31.58s/it] 71%|███████▏  | 15/21 [07:33<03:09, 31.58s/it] 71%|███████▏  | 15/21 [07:33<03:09, 31.58s/it] 71%|███████▏  | 15/21 [07:34<03:09, 31.58s/it] 71%|███████▏  | 15/21 [07:33<03:09, 31.58s/it] 71%|███████▏  | 15/21 [07:34<03:09, 31.58s/it] 71%|███████▏  | 15/21 [07:33<03:09, 31.58s/it] 71%|███████▏  | 15/21 [07:34<03:09, 31.58s/it] 76%|███████▌  | 16/21 [08:02<02:34, 30.85s/it] 76%|███████▌  | 16/21 [08:03<02:34, 30.85s/it] 76%|███████▌  | 16/21 [08:02<02:34, 30.85s/it] 76%|███████▌  | 16/21 [08:03<02:34, 30.85s/it] 76%|███████▌  | 16/21 [08:03<02:34, 30.85s/it] 76%|███████▌  | 16/21 [08:03<02:34, 30.85s/it] 76%|███████▌  | 16/21 [08:03<02:34, 30.85s/it] 76%|███████▌  | 16/21 [08:03<02:34, 30.85s/it] 81%|████████  | 17/21 [08:31<02:00, 30.07s/it] 81%|████████  | 17/21 [08:31<02:00, 30.07s/it] 81%|████████  | 17/21 [08:30<02:00, 30.07s/it] 81%|████████  | 17/21 [08:31<02:00, 30.07s/it] 81%|████████  | 17/21 [08:31<02:00, 30.07s/it] 81%|████████  | 17/21 [08:31<02:00, 30.07s/it] 81%|████████  | 17/21 [08:31<02:00, 30.07s/it] 81%|████████  | 17/21 [08:31<02:00, 30.07s/it] 86%|████████▌ | 18/21 [09:00<01:29, 29.84s/it] 86%|████████▌ | 18/21 [08:59<01:29, 29.84s/it] 86%|████████▌ | 18/21 [09:00<01:29, 29.84s/it] 86%|████████▌ | 18/21 [09:00<01:29, 29.84s/it] 86%|████████▌ | 18/21 [09:00<01:29, 29.84s/it] 86%|████████▌ | 18/21 [09:00<01:29, 29.84s/it] 86%|████████▌ | 18/21 [09:00<01:29, 29.84s/it] 86%|████████▌ | 18/21 [09:00<01:29, 29.84s/it] 90%|█████████ | 19/21 [09:30<00:59, 29.86s/it] 90%|█████████ | 19/21 [09:30<00:59, 29.86s/it] 90%|█████████ | 19/21 [09:30<00:59, 29.86s/it] 90%|█████████ | 19/21 [09:30<00:59, 29.86s/it] 90%|█████████ | 19/21 [09:30<00:59, 29.86s/it] 90%|█████████ | 19/21 [09:30<00:59, 29.86s/it] 90%|█████████ | 19/21 [09:29<00:59, 29.86s/it] 90%|█████████ | 19/21 [09:30<00:59, 29.86s/it] 95%|█████████▌| 20/21 [09:57<00:29, 29.34s/it] 95%|█████████▌| 20/21 [09:58<00:29, 29.34s/it] 95%|█████████▌| 20/21 [09:58<00:29, 29.34s/it] 95%|█████████▌| 20/21 [09:58<00:29, 29.34s/it] 95%|█████████▌| 20/21 [09:58<00:29, 29.34s/it] 95%|█████████▌| 20/21 [09:58<00:29, 29.34s/it] 95%|█████████▌| 20/21 [09:58<00:29, 29.34s/it] 95%|█████████▌| 20/21 [09:58<00:29, 29.34s/it]100%|██████████| 21/21 [10:29<00:00, 29.64s/it]100%|██████████| 21/21 [10:29<00:00, 29.64s/it]100%|██████████| 21/21 [10:29<00:00, 29.64s/it]100%|██████████| 21/21 [10:29<00:00, 29.64s/it]100%|██████████| 21/21 [10:28<00:00, 29.64s/it]100%|██████████| 21/21 [10:29<00:00, 29.64s/it]100%|██████████| 21/21 [10:28<00:00, 29.64s/it]100%|██████████| 21/21 [10:28<00:00, 29.64s/it]22it [10:58, 29.85s/it]                        22it [10:59, 29.85s/it]                        22it [10:59, 29.85s/it]                        22it [10:59, 29.85s/it]                        22it [10:59, 29.85s/it]                        22it [10:59, 29.85s/it]                        22it [10:59, 29.85s/it]                        22it [10:59, 29.85s/it]                        23it [11:29, 29.79s/it]23it [11:29, 29.79s/it]23it [11:29, 29.79s/it]23it [11:29, 29.79s/it]23it [11:28, 29.79s/it]23it [11:28, 29.79s/it]23it [11:28, 29.79s/it]23it [11:29, 29.79s/it]24it [11:56, 28.96s/it]24it [11:55, 28.96s/it]24it [11:56, 28.96s/it]24it [11:56, 28.96s/it]24it [11:56, 28.96s/it]24it [11:55, 28.96s/it]24it [11:56, 28.96s/it]24it [11:55, 28.96s/it]25it [12:28, 29.85s/it]25it [12:28, 29.85s/it]25it [12:28, 29.85s/it]25it [12:28, 29.85s/it]25it [12:27, 29.85s/it]25it [12:27, 29.85s/it]25it [12:27, 29.85s/it]25it [12:28, 29.85s/it]26it [12:55, 29.25s/it]26it [12:55, 29.25s/it]26it [12:55, 29.25s/it]26it [12:55, 29.25s/it]26it [12:55, 29.25s/it]26it [12:55, 29.25s/it]26it [12:55, 29.25s/it]26it [12:55, 29.25s/it]27it [13:17, 27.06s/it]27it [13:17, 27.06s/it]27it [13:17, 27.06s/it]27it [13:17, 27.06s/it]27it [13:17, 27.06s/it]27it [13:17, 27.06s/it]27it [13:17, 27.06s/it]27it [13:16, 27.06s/it]28it [13:40, 25.69s/it]28it [13:40, 25.69s/it]28it [13:39, 25.69s/it]28it [13:40, 25.69s/it]28it [13:40, 25.69s/it]28it [13:40, 25.69s/it]28it [13:40, 25.69s/it]28it [13:39, 25.69s/it]29it [14:03, 24.79s/it]29it [14:02, 24.79s/it]29it [14:03, 24.79s/it]29it [14:03, 24.79s/it]29it [14:02, 24.79s/it]29it [14:02, 24.79s/it]29it [14:02, 24.79s/it]29it [14:03, 24.79s/it]30it [14:26, 24.52s/it]30it [14:26, 24.52s/it]30it [14:26, 24.52s/it]30it [14:26, 24.52s/it]30it [14:26, 24.52s/it]30it [14:26, 24.52s/it]30it [14:26, 24.52s/it]30it [14:26, 24.52s/it]31it [14:53, 25.36s/it]31it [14:53, 25.36s/it]31it [14:54, 25.36s/it]31it [14:54, 25.36s/it]31it [14:54, 25.36s/it]31it [14:54, 25.36s/it]31it [14:54, 25.36s/it]31it [14:54, 25.36s/it]32it [15:18, 25.11s/it]32it [15:18, 25.11s/it]32it [15:18, 25.11s/it]32it [15:18, 25.11s/it]32it [15:18, 25.11s/it]32it [15:18, 25.11s/it]32it [15:17, 25.11s/it]32it [15:18, 25.11s/it]33it [15:45, 25.92s/it]33it [15:46, 25.92s/it]33it [15:46, 25.92s/it]33it [15:46, 25.92s/it]33it [15:46, 25.92s/it]33it [15:46, 25.92s/it]33it [15:46, 25.92s/it]33it [15:46, 25.92s/it]34it [16:16, 27.04s/it]34it [16:15, 27.04s/it]34it [16:16, 27.04s/it]34it [16:16, 27.04s/it]34it [16:16, 27.04s/it]34it [16:16, 27.04s/it]34it [16:16, 27.04s/it]34it [16:15, 27.04s/it]35it [16:44, 27.81s/it]35it [16:45, 27.81s/it]35it [16:45, 27.81s/it]35it [16:45, 27.81s/it]35it [16:45, 27.81s/it]35it [16:45, 27.81s/it]35it [16:45, 27.81s/it]35it [16:45, 27.81s/it]36it [17:10, 26.89s/it]36it [17:10, 26.89s/it]36it [17:10, 26.89s/it]36it [17:10, 26.89s/it]36it [17:10, 26.89s/it]36it [17:10, 26.89s/it]36it [17:10, 26.89s/it]36it [17:09, 26.89s/it]37it [17:37, 27.10s/it]37it [17:38, 27.10s/it]37it [17:38, 27.10s/it]37it [17:38, 27.10s/it]37it [17:38, 27.10s/it]37it [17:38, 27.10s/it]37it [17:38, 27.10s/it]37it [17:37, 27.10s/it]38it [18:05, 27.17s/it]38it [18:05, 27.17s/it]38it [18:05, 27.17s/it]38it [18:05, 27.17s/it]38it [18:05, 27.17s/it]38it [18:05, 27.17s/it]38it [18:05, 27.17s/it]38it [18:04, 27.17s/it]39it [18:34, 27.77s/it]39it [18:33, 27.77s/it]39it [18:34, 27.77s/it]39it [18:34, 27.77s/it]39it [18:34, 27.77s/it]39it [18:34, 27.77s/it]39it [18:34, 27.77s/it]39it [18:34, 27.77s/it]40it [19:00, 27.13s/it]40it [18:59, 27.13s/it]40it [19:00, 27.13s/it]40it [19:00, 27.13s/it]40it [18:59, 27.13s/it]40it [19:00, 27.13s/it]40it [19:00, 27.13s/it]40it [19:00, 27.13s/it]41it [19:32, 28.65s/it]41it [19:32, 28.65s/it]41it [19:31, 28.65s/it]41it [19:32, 28.60s/it]41it [19:32, 28.65s/it]41it [19:32, 28.65s/it]41it [19:32, 28.65s/it]
41it [19:32, 28.65s/it]41it [19:32, 28.65s/it]41it [19:32, 28.60s/it]
41it [19:31, 28.58s/it]41it [19:32, 28.59s/it]

41it [19:32, 28.60s/it]41it [19:32, 28.60s/it]

41it [19:32, 28.60s/it]
41it [19:32, 28.59s/it]
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
/opt/hpcaas/.mounts/fs-03efe25c053395d1f/beidic/yang/bigcode-evaluation-harness/bigcode_eval/evaluator.py:141: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=1
  warnings.warn(
